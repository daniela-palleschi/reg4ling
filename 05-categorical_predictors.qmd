---
title: "Categorical predictors"
subtitle: "Regression for Linguists"
author: "Daniela Palleschi"
institute: Humboldt-Universit√§t zu Berlin
# footer: "Lecture 1.1 - R und RStudio"
lang: en
date: "`r Sys.Date()`"
format:
  html:
    number-sections: true
    number-depth: 3
    toc: true
    code-overflow: wrap
    code-tools: true
    self-contained: true
bibliography: references.bib
csl: apa.csl
execute:
  eval: true
  echo: true
  message: false
  error: false
  warning: false
  fig-align: "center"
  fig-asp: .618
---

## Learning Objectives {.unnumbered .unlisted}

Today we will learn...

- about cateogorical predictors
- how to interpret different contrast coding

## Set-up environment  {.unnumbered}

```{r}
# suppress scientific notation
options(scipen=999)
```

We'll also need to load in our required packages. 

```{r}
# load libraries
pacman::p_load(
               tidyverse,
               here,
               broom,
               lme4,
               janitor,
               languageR)
```

```{r}
#| echo: false

# extra packages for the lecture notes/slides
pacman::p_load(
               patchwork,
               knitr,
               kableExtra)
```

### Load data {.unnumbered .unlisted}

Let's continue working with the `english` dataset from the `languageR` package. Let's just call it `df_freq_eng`.

```{r}
df_freq_eng <-
  as.data.frame(english) |> 
  dplyr::select(RTlexdec, RTnaming, Word, LengthInLetters, AgeSubject, WrittenFrequency) |> 
  rename(rt_lexdec = RTlexdec,
         rt_naming = RTnaming,
         freq_written = WrittenFrequency) |> 
  clean_names() |> 
  # standardize continuous predictors
  mutate(
    freq_z = scale(freq_written),
    length_z = scale(length_in_letters)
  ) |> 
  relocate(word) |> 
  arrange(word)
```

In your exploratory data analysis, you might've noticed a *bimodal* distribution.


```{r}
#| echo: false
fig_hist_log <- 
  df_freq_eng |> 
  ggplot() +
  aes(x = rt_lexdec) +
  geom_histogram() 

fig_dens_log <- 
  df_freq_eng |> 
  ggplot() +
  aes(x = rt_lexdec) +
  geom_density() 


fig_hist <-
  df_freq_eng |> 
  ggplot() +
  aes(x = rt_lexdec, fill = age_subject) +
  geom_histogram(alpha = .5, position = "stack") +
  # facet_grid(.~age_subject) +
  theme(legend.position = "none")

fig_dens <-
  df_freq_eng |> 
  ggplot() +
  aes(x = rt_lexdec, colour = age_subject, fill = age_subject) +
  stat_density(alpha = .4) +
  theme(legend.position = "bottom")



  (fig_hist_log + fig_dens_log) /
  (fig_hist + fig_dens)
```

This looks like a *bimodal* distribution, i.e., there are two *modes* (most frequent value, i.e., peak in a histogram). What might be driving this? We know that there were two subject groups: old and young. How does the distribution of these two groups look?

Running our model of the log reaction times as predicted by frequency and length, we see:

```{r}
fit_freq_length <-
  lm(rt_lexdec ~ freq_z*length_z,
     data = df_freq_eng)
```

```{r}
glance(fit_freq_length)$r.squared
glance(fit_freq_length)$adj.r.squared
```

Seems like we don't have any overfitting in our model ($R^2$ and adjusted $R^2$ are comparable). Let's look at our coeffiecients.

```{r}
tidy(fit_freq_length) |> select(term, estimate)
```

There is a negative slope for frequency, indicating shorter reaction times for words with higher frequency (when holding length constant). There is a positive slope for length, indicating longer reaction times for longer words (holding frequency constant). There is also a negative interaction estimate, indicating that when both length and frequency increase, reaction times decrease. This seems similar to the dataset we explored in the previous sections. But, this bimodal distribution is suggesting we should include age group as a predictor, since the two groups seem to pattern differently in their reading times. Could it be that the effect of frequency and length also differ as a function of age group?

## Categorical predictors

In linguistic research we often want to compare the effect of *groups* or categories, such as native or non-native speakers, or grammatical or ungrammatical stimuli. We might expect longer reading times for non-native (compared to native) speakers of a language, or for ungrammatical (versus grammatical) sentences. With our current dataset, we'd predict longer reading times for older participants than younger participants (although we should hypothesise *before* collecting and visualising our data!). How might these age effects interact with effects of word frequency and length?

### Including a categorical predictor

What would happen if we just include `age_subject` in our model?

```{r}
fit_age <-
  lm(rt_lexdec ~ freq_z*length_z + age_subject,
     data = df_freq_eng)
```

First, we see that adding age to our model results in a large increase in variance explained, and that the $R^2$ and adjusted $R^2$ values are comparable. In addition, the VIF values for all coefficients are near 1. This indicates that our predictors all contribute to the variance explained by the model and are not correlated.

```{r}
glance(fit_age)$r.squared
glance(fit_age)$adj.r.squared
```

```{r}
car::vif(fit_age)
```

Now that we see that our model is not overfit and that our predictors are not correlatd, let's take a look at our model estimates.

```{r}
tidy(fit_age) |> select(term,estimate)
```

In addition to the effects we observed in our earlier model, we see that there is a negative slope for `age_subjectyoung`, indicating that reaction times decrease when...what? How do we interpret a slope for a categorical variable? Regression works with numerical values, so how does a categorical variable get fit to a line? If we feed a categorical variable into the `lm()` function, the factor levels (i.e., the categories in a categorical variable) are given numerical values. We need to know what these values are in order to know how to interpret our model estimates. We call these numerical values mapped onto factor levels contrast coding, and we can check the contrasts of a given factor using the function `contrasts()`.

```{r}
contrasts(df_freq_eng$age_subject)
```

We see that `old` was coded at $0$ and `young` as $1$. This means that our slope for `age_subjectyoung` represents the change in reaction times when we move from `old` to `young`, which corresponds to a 1-unit change in our predictor (because the difference between 0 and 1 is 1). This is called treatment coding, or dummy coding, where one factor level is coded as 0 and the other as 1. Let's remove the continuous variable for now and focus on `age_subject`. Let's also look at raw reaction times, to more easily interpret the results.

```{r}
fit_age <-
  lm(exp(rt_lexdec) ~ age_subject,
     data = df_freq_eng)
```

```{r}
glance(fit_age)$r.squared
```

Our $R^2$ value is lower than when we included frequency and length, but higher still than our model with frequeny and length but no age.

```{r}
tidy(fit_age) |> select(term, estimate)
```

We see that there is an estimated decrease in reaction times of 157ms for the young group compared to the old group. But what does the intercept represent here? Let's look at our data again.

```{r}
df_freq_eng |> 
  select(rt_lexdec, age_subject) |> 
  mutate(rt_lexdec = exp(rt_lexdec)) |> 
  summary()
```

And how does `rt_lexdec` differ between the groups?

```{r}
df_freq_eng |> 
  select(rt_lexdec, age_subject) |> 
  mutate(rt_lexdec = exp(rt_lexdec)) |> 
  summarise(mean = mean(rt_lexdec),
            min = min(rt_lexdec),
            max = max(rt_lexdec),
    .by = "age_subject"
  )
```

We see here that the intercept for our model actually corresponds to the mean reaction time for the old group. Why is this? Recall that the intercept corresponds to the $y$ value (reaction time) when $x$ is $0$. In treatment/dummy coding, one factor level is coded as $0$. In our case this was `old`, and so the intercept corresponds to the mean reaction time for participants in the old group. How does R choose which variable to code as $0$? It simply takes the first level name alphabetically: `old` comes before `young`, so `old` was automatically taken as the 'baseline' to which `young` was compared.

And if we were to add the slope to the intercept, we would get the mean for the $young$ group. Why is this?

```{r}
coef(fit_age)['(Intercept)'] + coef(fit_age)['age_subjectyoung']
```

Why are the means for the two groups used? The mean is the value closest to all values in a univariate dataset, and regression aims to inimise residuals (recall the line of best fit). So, a line is fit between the means of these two factor levels to achieve minimal residuals. This actually is the same thing as a *t*-test:

```{r}
t.test(exp(rt_lexdec) ~ age_subject, data = df_freq_eng)
```

If we compare this to our model, we see that the *t*- and *p*-values are identical (more on these later).

```{r}
tidy(fit_age)
```

```{r}


fig_nocontrasts <-
df_freq_eng |> 
  ggplot() +
  aes(x = age_subject, y = exp(rt_lexdec)) +
  labs(title = "No contrasts") +
  # geom_vline(xintercept = 0, linetype="dashed", size = .5) +  
  geom_point(position = position_dodge(.6)) + 
  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +
  theme_bw()

fig_treatment <-
df_freq_eng |> 
  mutate(age_subject = if_else(age_subject=="young",1,0)) |>
  ggplot() +
  aes(x = age_subject, y = exp(rt_lexdec)) +
  labs(title = "Treatment contrasts") +
  geom_vline(xintercept = 0, linetype="dashed", size = .5) +
  geom_point(position = position_dodge(.6)) + 
  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +
  theme_bw()

fig_nocontrasts + fig_treatment
```


## Sum contrasts

Treatment/dummy coding is the default contrast coding scheme. Sum coding is another frequently used coding scheme, which is essentially centring categorical variables. Just as with continuous variables, the motivation for sum contrast coding mainly lies in the interpretation of interaction effects. How can we tell R we want to use sum contrast coding, and not dummy coding? There are different ways to do this:

```{r}
# first, make sure your variable is a factor
df_freq_eng$age_subject <- as.factor(df_freq_eng$age_subject)
# check
class(df_freq_eng$age_subject)
```

```{r}
# next, you could use the contr.sum() function
contrasts(df_freq_eng$age_subject) <- contr.sum(2) # where 2 means we have 2 levels
contrasts(df_freq_eng$age_subject)
```

Here we see that `old` is coded as $-1$ and `young` as $+1$. I prefer to use +/-0.5 for reasons we don't need to go into here. I would also prefer to have `young` coded in the negative value, and `old` in the positive value. This aids in the way I interpret the slope: a change in reaction times for the older group compared to the younger group.

```{r}
#or, you could manually control the sum contrasts
## check the order of the levels
levels(df_freq_eng$age_subject)

## code 'old' as +.5 and 'young' as -.5
contrasts(df_freq_eng$age_subject) <- c(+0.5, -0.5)
contrasts(df_freq_eng$age_subject)
```

You could also choose to store the contrast values in their own variable.

```{r}
df_freq_eng <- 
  df_freq_eng |> 
  mutate(age_numeric = ifelse(age_subject == "young", -0.5, +0.5))
```

```{r}
df_freq_eng |> 
  select(age_subject, age_numeric) |> 
  head()
```

Now, we can run our model using either `age_subject` or `age_numeric`.

```{r}
fit_age_sum <-
  lm(exp(rt_lexdec) ~ age_subject,
     data = df_freq_eng)
```

```{r}
glance(fit_age_sum)$r.squared
glance(fit_age)$r.squared
```

No difference in variance account for by our model.

```{r}
tidy(fit_age_sum) |> select(term,estimate)
```

But there is a difference in the intercept, and a change in sign in our slope. Why is this?

```{r}
#| label: fig-contrasts
#| fig-cap: The difference in slope corresponds to which level is coded as 0 (dummy coding) or -5/-1 (sum coding)
fig_sum1 <-
df_freq_eng |> 
  mutate(age_subject = if_else(age_subject=="young",-1,1)) |>
  ggplot() +
  aes(x = age_subject, y = exp(rt_lexdec)) +
  labs(title = "Sum contrasts") +
  geom_vline(xintercept = 0, linetype="dashed", size = .5) +
  geom_point(position = position_dodge(.6)) + 
  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +
  theme_bw()

fig_sum5 <-
df_freq_eng |> 
  mutate(age_subject = if_else(age_subject=="young",-.5,.5)) |>
  ggplot() +
  aes(x = age_subject, y = exp(rt_lexdec)) +
  labs(title = "Sum contrasts") +
  geom_vline(xintercept = 0, linetype="dashed", size = .5) +
  geom_point(position = position_dodge(.6)) + 
  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +
  theme_bw()

fig_treatment + fig_sum5 + plot_annotation(tag_levels = "A")
```

As we see in @fig-contrasts, the sign of the slope depends on how we've contrast coded our factor levels. In @fig-contrasts A, the `old` group is coded as $0$ and `young` as $1$. In @fig-contrasts B, the `young` group is coded as $-.5$ and the `old` group as $+.5$.

The intercept value is also now the overall mean of all observed reaction times, because now the $y$ value when $x$ equals zero lies in the middle of the two groups. The slope magnitude (i.e., size of the value) hasn't changed, because the difference betwen the two group means has not changed.

```{r}
mean(exp(df_freq_eng$rt_lexdec))
```


### Exploring predicted values

Let's also explore the predicted values of our model with a categorical variable.

```{r}
head(fitted(fit_age), n = 10)
```

We see that there are only 2 values, 630 and 787. These correspond to the means for each group that we saw above. They also seem to be in a pattern: young-mean, old-mean, young-mean, old-mean, etc. How does this correspond to the age group of the participant for the first ten observations?

```{r}
head(df_freq_eng$age_subject, n = 10)
```

The first ten observations in our data are in young-old pairs. What are the first values in the raw data?

```{r}
head(exp(df_freq_eng$rt_lexdec), n = 10)
```

And what is the difference between these reaction times and the fitted values?

```{r}
head(exp(df_freq_eng$rt_lexdec), n = 10) - head(fitted(fit_age), n = 10)
```

```{r}
head(residuals(fit_age))
```














## Summary

-   we saw that the equation for a straight line boils down to its intercept and slope

-   we fit our first linear model with a categorical predictor

### Important terms {.unnumbered .smaller}

```{r}
#| echo: false
tribble(
 ~"term", ~"description/other terms",
 
) %>% kable() %>% kable_styling()
```


## Learning Objectives {.unnumbered .unlisted}

Today we learned...


## Task



## Literaturverzeichnis {.unlisted .unnumbered visibility="uncounted"}

::: {#refs custom-style="Bibliography"}
:::


