[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Regression for Linguists",
    "section": "",
    "text": "Course overview\nThis course fast tracks through different types of regression most relevant to linguistic research. These materials are by no means exhaustive, and should be supplemented by reading textbook length treatments. The majority of my materials lean heavily on Winter (2019), which I highly recommend. I also took inspiration from Sonderegger (2023), which came out this year and I haven’t fully explored yet. So far, it looks like a very thorough textbook that I would also recommend you check out.\nBefore you begin the course, I would like to paraphrase something Prof. Shravan Vasishth said in the opening remarks for the annual summer school for Statistcal Methods for Linguistics and Psychology back in 2020 which has stuck with me: get comfortable with partial knowledge. We are not trained statisticians, and likely never will be (Vasishth himself is a certified statistician, in addition to professor of psycholinguistics). So get comfortable with partial understanding of the math behind these models, and focus on their application and interpretation."
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "Regression for Linguists",
    "section": "Materials",
    "text": "Materials\nThis website is a work-in-progress. Materials will be updated/brushed up throughout the semester, with the binding course materials available on the course Moodle for those enrolled in the winter semester 2023/24.\nThis website was created to be viewed in HTML format. The accompanying (PDF) book version can be accessed by clicking on the PDF icon at the top right, but is not optimally formatted. Tables formatted for HTML output are particularly oddly formatted in PDF, as is the order of printed elements in relation to their accompanying text. For this reason, I strongly encourse to follow the web book.\n\n\n\n\n\n\nSonderegger, M. (2023). Regression Modeling for Linguistic Data.\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Meeting\n      Lecture\n      Topic\n      Vorbereitung\n    \n  \n  \n    2023-10-10\n1\nEquation of a line\n\n📚 Winter (2019): Ch. 1-3\n\n    2023-10-11\n2\nLinear regression\n\n📚 Winter (2019): Ch. 4\n📚 Winter (2013)\n\n    2023-10-12\n3\nContinuous predictors\n\n📚 Winter (2019): Ch. 5\n📚 Winter (2013)\n\n    2023-10-10\n4\nMultiple linear regression\n\n📚 Winter (2019): Ch. 6\n📚 Winter (2013)\n\n    2023-10-11\n5\nCategorical predictors\n\n📚 Winter (2019): Ch. 7\n📚 Winter (2013)\n\n    2023-10-12\n6\nModel assumptions\n\n\n    2023-10-10\n7\nLogistic regression\n\n📚 Winter (2019): Ch. 12\n\n    2023-10-11\n8\nLog odds, logits, and odds ratio\n\n\n    2023-10-12\n9\nFoundational Ideas\n\nVasishth & Nicenboim (2016)\n\n    2024-01-12\n10\nIndependence assumption\n\n📚 Winter (2019): Ch. 14\nWinter & Grice (2021); until Section 3\n\n    2024-01-12\n11\nLMMs 1: random intercepts\n\n📚 Winter (2019): Ch. 14\n\n    2024-01-26\n12\nGLMMs\n\n\n    2024-01-26\n13\nLMMs 2: random slopes\n\n\n    2024-02-09\n14\nTBD\n\n\n    2024-02-09\n15\nTBD"
  },
  {
    "objectID": "00-course_overview.html",
    "href": "00-course_overview.html",
    "title": "Resources and Set-up",
    "section": "",
    "text": "Resources\nThis course is mainly based on Winter (2019), which is an excellent introduction into regression for linguists. For even more introductory tutorials, I recommend going through Winter (2013) and Winter (2014) For a more intermediate textbook, I’d recommend Sonderegger (2023).\nIf you’re interested in the foundational writings on the topic of (frequentist) linear mixed models in (psycho)linguistic research, I’d recommend reading Baayen (2008); Baayen et al. (2008);Barr et al. (2013); Bates et al. (2015); Jaeger (2008); Matuschek et al. (2017); Vasishth (2022); Vasishth & Nicenboim (2016).\nFor this course, I assume that you are familiar with more classical statistical tests, such as the t-test, Chi-square test, etc. I also assume you are familiar with measures of central tendency (mean, median, mode) measures dispersion/spread (standard deviation), and with the concept of a normal distribution. Lacking this knowledge will not impeded your progress in the course, but is an important foundation on which we’ll be building. We can review these concepts in-class as needed."
  },
  {
    "objectID": "00-course_overview.html#install-r",
    "href": "00-course_overview.html#install-r",
    "title": "Resources and Set-up",
    "section": "Install R",
    "text": "Install R\n\nwe need the free and open source statistical software R to analyze our data\ndownload and install R: https://www.r-project.org"
  },
  {
    "objectID": "00-course_overview.html#install-rstudio",
    "href": "00-course_overview.html#install-rstudio",
    "title": "Resources and Set-up",
    "section": "Install RStudio",
    "text": "Install RStudio\n\nwe need RStudio to work with R more easily\nDownload and install RStudio: https://rstudio.com\nit can be helpful to keep English as language in RStudio\n\nwe will find more helpful information if we search error messages in English on the internet\n\nIf you have problems installing R or RStudio, check out this help page (in German): http://methods-berlin.com/wp-content/uploads/Installation.html"
  },
  {
    "objectID": "00-course_overview.html#install-latex",
    "href": "00-course_overview.html#install-latex",
    "title": "Resources and Set-up",
    "section": "Install LaTeX",
    "text": "Install LaTeX\n\nwe will not work with LaTeX directly, but it is needed in the background\nDownload and install LaTeX: https://www.latex-project.org/get/"
  },
  {
    "objectID": "00-course_overview.html#troubleshooting-en-troubleshooting",
    "href": "00-course_overview.html#troubleshooting-en-troubleshooting",
    "title": "Resources and Set-up",
    "section": "Troubleshooting (EN: Troubleshooting)",
    "text": "Troubleshooting (EN: Troubleshooting)\n\nError messages are very common in programming, at all levels.\nHow to find solutions for these error messages is an art in itself\nGoogle is your friend! If possible, google in English to get more information"
  },
  {
    "objectID": "00-course_overview.html#session-information",
    "href": "00-course_overview.html#session-information",
    "title": "Resources and Set-up",
    "section": "Session Information",
    "text": "Session Information\nThe current version of this Quarto book was developed using R version 4.3.0 (2023-04-21) (Already Tomorrow) in RStudioversion 2023.3.0.386 (Cherry Blossom). At the bottom of each chapter is a list of the packages (and version info) used in that chapter (under Session Information). I highly recommend you do the same at the bottom of each script that you write. You can easily do this by writing the following at the bottom of any Rmarkdown (.Rmd) or Quarto (.qmd) script:\n# Session Info\n\n```{r}\nsessionInfo()\n```"
  },
  {
    "objectID": "01-equation_of_a_line.html#learning-objectives",
    "href": "01-equation_of_a_line.html#learning-objectives",
    "title": "1  Understanding straight lines",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we will learn…\n\nthe equation of a line\nabout intercepts, slopes, and residuals"
  },
  {
    "objectID": "01-equation_of_a_line.html#resources",
    "href": "01-equation_of_a_line.html#resources",
    "title": "1  Understanding straight lines",
    "section": "Resources",
    "text": "Resources\nThis lecture is based on the readings for today’s session: Winter (2013) and Winter (2019) (Ch. 3), and to a lesser extent (debruine_understanding_2021?); Winter (2014)."
  },
  {
    "objectID": "01-equation_of_a_line.html#when-to-model-your-data",
    "href": "01-equation_of_a_line.html#when-to-model-your-data",
    "title": "1  Understanding straight lines",
    "section": "1.1 When to model your data",
    "text": "1.1 When to model your data\nBy the time we get to the point of wanting to model our data, we should have a pretty good idea of how our data look. We achieve this through running an exploratory data analysis (EDA), which consists of visualising your data and determining outliers (a question for another day: what is an outlier?), generating summary (i.e., descriptive) statistics, and just overall getting to know your data, without making any claims beyond your data.\nHowever, an understanding of the data design and collection procedure is incredibly important and is necessary in order to appropriately fit a model to our data. In fact, planning out your analyses when designing your experiment is highly recommended in order to ensure your data will have the appropriate structure and that the assumptions made by your chosen analyses are taken into consideration before data collection.\nThe next step after conducting an EDA is to model your data, i.e., run inferential statistics, this is where we try to generalise beyond our data.\n\n1.1.1 Statistical tests versus models\nMany statistical courses and textbooks still put undue emphasis on classical statistical tests. However, these common statistical tests are simplified linear models, without the added benefits of linear models. In essence, statistical tests tell us something about our data, whereas statistical models can be used to make predictions about hypothetical future observations."
  },
  {
    "objectID": "01-equation_of_a_line.html#linear-regression",
    "href": "01-equation_of_a_line.html#linear-regression",
    "title": "1  Understanding straight lines",
    "section": "1.2 (Linear) Regression",
    "text": "1.2 (Linear) Regression\nData exploration gives us an idea about what our data look like, but if we want to be able to make predictions about hypothetical observations, i.e., to predict values of our DV based on one (or more) IV(s), we need to fit a model to our data. This model can then predict values of our DV based on one (or more) IV(s), i.e., predicting an outcome variable (dependent variable, DV) from one or more predictors (independent variable, IV). Because we’re making predictions, we need to take into account the variability (i.e., error) in our data.\n\n1.2.1 Types of regression\n\n\n\n\n\nregression type\npredictor\noutcome\n\n\n\n\nsimple regression\nSingle predictor\ncontinuous (numerical)\n\n\nmultiple regression\nmultiple predictor\ncontinuous (numerical)\n\n\nhierarchical/linear mixed models/linear mixed effect models\ninclude random effect\ncontinuous (numerical)\n\n\ngeneralised linear (mixed) models: logistic regression\nas above\nbinary/binomial data\n\n\ngeneralised linear (mixed) models: poisson regression\nas above\ncount data"
  },
  {
    "objectID": "01-equation_of_a_line.html#sec-straight-lines",
    "href": "01-equation_of_a_line.html#sec-straight-lines",
    "title": "1  Understanding straight lines",
    "section": "1.3 Straight lines",
    "text": "1.3 Straight lines\n\nlinear regression summarises the data with a straight line\n\nwe model our data as/fit our data to a straight line\n\nstraight lines can be defined by\n\nIntercept (\\(b_0\\))\n\nvalue of \\(Y\\) when \\(X = 0\\)\n\nSlope (\\(b_1\\))\n\ngradient (slope) of the regression line\ndirection/strength of relationship between \\(x\\) and \\(y\\)\nregression coefficient for the predictor\n\n\nso we need to define an intercept and a slope\n\n\n1.3.1 A line = intercept and slope\n\na line is defined by its intercept and slope\n\nin a regression model, these two are called coefficients\n\n\n\n\n\n\n\nFigure 1.1: Image source: Winter (2019) (all rights reserved)\n\n\n\n\n\n\n\n\n\n\nEquation of a line\n\n\n\n\\[\\begin{align}\ny & = mx + c\\\\\nY_i &= (b_0 + b_1X_i) \\\\\noutcome_i & = (model) \\\\\ny_i & = (intercept + slope*x_i)\n\\end{align}\\]\n\n\n\n\n1.3.2 Intercept (\\(b_0\\))\n\nthe value of \\(y\\) when \\(x = 0\\)\n\n\n\n\n\n\n\n\n1.3.3 Slopes (\\(b_1\\))\nA slope describes a change in \\(y\\) (\\(\\Delta y\\)) over a change in \\(x\\) (\\(\\Delta x\\)), where \\(\\Delta\\) (the Greek letter delta) can be read as ‘difference’. So a slope’s value equals the difference in \\(x\\) for a difference of 1 unit in \\(y\\). Positive slopes indicate that as \\(x\\) increases, \\(y\\) increases. A negative slope value indicates that as \\(x\\) increases, \\(y\\) decreases (or vice versa). A slope of 0 indicates there is no change in \\(y\\) as a function of \\(x\\), or: there is no change in \\(y\\) when the value of \\(x\\) changes.\n\\[\\begin{align}\nslope = \\frac{\\Delta y}{\\Delta x}\n\\end{align}\\]\nThis relationship between \\(x\\) and \\(y\\) is sometimes referred to as “rise over run”: how do you ‘rise’ in \\(y\\) for a given ‘run’ in \\(x\\)? For example, if we were to measure children’s heights and ages, we would expect to find an increase in height for every increase in age. Or, for a linguistic example, we would expect to find longer whole-sentence reading times (a measure variable) for longer texts: if a sentence has 9 words (I find straight lines to be really interesting and fun.), we would expect longer reading times than a sentence with 3 words (I love lines.).\n\n\nwhat is the intercept of this line?\nwhat is the slope of this line?"
  },
  {
    "objectID": "01-equation_of_a_line.html#error-and-residuals",
    "href": "01-equation_of_a_line.html#error-and-residuals",
    "title": "1  Understanding straight lines",
    "section": "1.4 Error and residuals",
    "text": "1.4 Error and residuals\n\nfixed effects (IV/predictors): things we can understand/measure\nerror (random effects): things we cannot understand/measure\n\nin biology, social sciences (and linguistic research), there will always sources of random error that we cannot account for\nrandom error is less an issue in e.g., physics (e.g., measuring gravitational pull)\n\nresiduals: the difference (vertical difference) between observed data and the fitted values (predicted values)\n\n\n\n\n\n\n\nEquation of a line\n\n\n\n\\[\\begin{align}\ny & = mx + c\\\\\nY_i &= (b_0 + b_1X_i) + \\epsilon_i\\\\\noutcome_i & = (model) + error_i\\\\\ny_i & = (intercept + slope*x_i) + error_i\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.4.1 Method of least squares\n\nso how is any given line chosen to fit any given data?\nthe method of least squares\n\ntake a given line, and square all the residuals (i.e., \\(residual^2\\))\nthe line with the lowest sum of squares is the line with the best fit to the given data\nwhy do we square the residuals before summing them up?\n\nso all values are positive (i.e., so that negative values don’t cancel out positive values)\n\n\nthis is how we find the line of best fit\n\nR fits many lines to find the one with the best fit\n\n\n\n\n\n\n\n\nFigure 1.2: Observed values (A), Residuals for line of best fit (B), A line of worse fit with larger residuals (C)"
  },
  {
    "objectID": "01-equation_of_a_line.html#learning-objectives-1",
    "href": "01-equation_of_a_line.html#learning-objectives-1",
    "title": "1  Understanding straight lines",
    "section": "Learning Objectives 🏁",
    "text": "Learning Objectives 🏁\nToday we learned…\n\nthe equation of a line\nabout intercepts, slopes, and residuals"
  },
  {
    "objectID": "01-equation_of_a_line.html#important-terms",
    "href": "01-equation_of_a_line.html#important-terms",
    "title": "1  Understanding straight lines",
    "section": "Important terms",
    "text": "Important terms\n\n\n\n\n\n\n  \n    \n    \n      Term\n      Definition\n      Equation/Code\n    \n  \n  \n    Intercept\nValue of y for x=0\nb0\n    Slope\na change in x over a change in y; regression coefficient for the predictor. Positive as x increases, y increases. \nNegative slopes, as x increases y decreases.\nb1\n    residuals/error\ndifference between observed data and the fitted values\ntidy(model_name)$.resid\n    interaction term\nused to describe how effects of one predictor may be influenced by changes in another predictor\nlm(response ~ predictor1*predictor2, data = data)"
  },
  {
    "objectID": "01-equation_of_a_line.html#tasks",
    "href": "01-equation_of_a_line.html#tasks",
    "title": "1  Understanding straight lines",
    "section": "1.5 Tasks",
    "text": "1.5 Tasks\n\n1.5.1 Task 1: pen-and-paper\nYou will receive a piece of paper with several grids on it. Follow the instructions, which include drawing some lines. If you aren’t in-class, this is the paper we are using:\n\n\n1.5.2 Task 2: simulating data\nAll of the figures we just saw (except Figure 1.1, which is from Winter (2019)) were generated in R. Simulating data and plotting is a great way to understand concepts, or even to map out our hypotheses. Let’s use R for the first time to try to simulate some data in order to plot lines. Our goal will be to produce a line that has the following:\n\nintercept = 4.5\nslope = 3\n\n\n1.5.2.1 Planning\nFirst, think about what steps will be required to create such plots. Can you come up with a workflow plan (without peaking at the next tasks)?\n\n\n1.5.2.2 Producing our line\n\nx &lt;- c(0,1)\ny &lt;- c(4.5,3)\ndata &lt;- cbind(x,y) |&gt; as.data.frame()\nggplot(data = data) +\n  aes(x = x, y = y) +\n  geom_line() +\n  geom_point()"
  },
  {
    "objectID": "01-equation_of_a_line.html#session-info",
    "href": "01-equation_of_a_line.html#session-info",
    "title": "1  Understanding straight lines",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] googlesheets4_1.1.0 gt_0.9.0            kableExtra_1.3.4   \n [4] knitr_1.44          patchwork_1.1.3     broom_1.0.5        \n [7] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0      \n[10] dplyr_1.1.3         purrr_1.0.2         readr_2.1.4        \n[13] tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3      \n[16] tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      xfun_0.39         htmlwidgets_1.6.2 lattice_0.21-8   \n [5] gargle_1.4.0      tzdb_0.4.0        vctrs_0.6.3       tools_4.3.0      \n [9] generics_0.1.3    curl_5.0.1        fansi_1.0.4       highr_0.10       \n[13] pacman_0.5.1      pkgconfig_2.0.3   Matrix_1.5-4      webshot_0.5.4    \n[17] lifecycle_1.0.3   farver_2.1.1      compiler_4.3.0    munsell_0.5.0    \n[21] sass_0.4.6        htmltools_0.5.5   yaml_2.3.7        pillar_1.9.0     \n[25] magick_2.7.4      nlme_3.1-162      tidyselect_1.2.0  rvest_1.0.3      \n[29] digest_0.6.33     stringi_1.7.12    splines_4.3.0     labeling_0.4.3   \n[33] rprojroot_2.0.3   fastmap_1.1.1     grid_4.3.0        here_1.0.1       \n[37] colorspace_2.1-0  cli_3.6.1         magrittr_2.0.3    utf8_1.2.3       \n[41] withr_2.5.0       scales_1.2.1      backports_1.4.1   googledrive_2.1.0\n[45] timechange_0.2.0  rmarkdown_2.22    httr_1.4.6        cellranger_1.1.0 \n[49] png_0.1-8         hms_1.1.3         evaluate_0.21     viridisLite_0.4.2\n[53] mgcv_1.8-42       rlang_1.1.1       Rcpp_1.0.11       glue_1.6.2       \n[57] xml2_1.3.4        svglite_2.1.1     rstudioapi_0.14   jsonlite_1.8.7   \n[61] R6_2.5.1          systemfonts_1.0.4 fs_1.6.2"
  },
  {
    "objectID": "01-equation_of_a_line.html#literaturverzeichnis",
    "href": "01-equation_of_a_line.html#literaturverzeichnis",
    "title": "1  Understanding straight lines",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nWinter, B. (2013). Linear models and linear mixed effects models in R: Tutorial 1.\n\n\nWinter, B. (2014). A very basic tutorial for performing linear mixed effects analyses (Tutorial 2).\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "02-simple_linear_regression.html#learning-objectives",
    "href": "02-simple_linear_regression.html#learning-objectives",
    "title": "2  Simple linear regression",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we will learn…\n\nhow to fit a simple linear model with the lm() function\nhow to interpret our model output"
  },
  {
    "objectID": "02-simple_linear_regression.html#set-up-environment",
    "href": "02-simple_linear_regression.html#set-up-environment",
    "title": "2  Simple linear regression",
    "section": "Set-up environment",
    "text": "Set-up environment\nMake sure you always start with a clean R Environment (Session &gt; Restart R). This means you should have no objects stored in your Environment, and no packages loaded. To ensure this, you can go to the Session tab (up where you’ll find File, Help, etc.), and select Restart R. You can also use the keyboard shortcut Cmd/Ctrl+Shift+0 (that’s a zero, not an ‘oh’).\nIn addition, I often prefer to run options(scipen=999) in order to supress scientific notation, which writes very large or very small numbers in an unintuitive way. For example, 0.000005 is written 5e-06 in scientific notation.\n\n# suppress scientific notation\noptions(scipen=999)\n\nWe’ll also need to load in our required packages. Hopefully you’ve already install the required packages (if not, go to Chapter 3).\n\n# load libraries\npacman::p_load(\n               tidyverse,\n               here,\n               broom,\n               lme4,\n               janitor,\n               languageR)"
  },
  {
    "objectID": "02-simple_linear_regression.html#simple-linear-model-rt-frequency",
    "href": "02-simple_linear_regression.html#simple-linear-model-rt-frequency",
    "title": "2  Simple linear regression",
    "section": "2.1 Simple linear model: RT ~ frequency",
    "text": "2.1 Simple linear model: RT ~ frequency\nRecall that \\(y \\sim x\\) can be read as “y as a function of x”, or “y predicted by x”. Following Winter (2019), we will first model some word frequency data. In this experiment, Our first model is given in equation \\(\\ref{eq-rt}\\):\n\\[\\begin{equation}\nRT \\sim frequency \\label{eq-rt}\n\\end{equation}\\]\nLet’s load our data using the read_csv() function from readr. I also use the clean_names() function from the janitor package, which tidies up variable names (e.g., no spaces, all lower case).\n\n# load ELP_frequency.csv\ndf_freq &lt;- read_csv(here(\"data\", \"ELP_frequency.csv\")) |&gt; \n  clean_names()\n\n\n2.1.1 Mini-EDA\nLet’s explore the data a little bit, which is what we would normally do before fitting any models. First, let’s see how the data is structured.\n\n# print head of df_freq\nhead(df_freq)\n\n# A tibble: 6 × 3\n  word      freq    rt\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 thing    55522  622.\n2 life     40629  520.\n3 door     14895  507.\n4 angel     3992  637.\n5 beer      3850  587.\n6 disgrace   409  705 \n\n\nLooks like there are only 3 columns: word, freq, and rt. We can assume that they correspond to the word, its frequency, and the reaction time, respectively. We can also see in our global environment that there are 12 observations, meaning 12 rows.\nThe summary() function provides summaries of each variable in a dataframe. For numeric variables, it will provide descriptive statistics for the centre and spread of the data (mean, median, quartiles). For categorical data, it will provide the count per category. For character variables, simply lists the number of observations.\n\nsummary(df_freq)\n\n     word                freq               rt       \n Length:12          Min.   :    4.0   Min.   :507.4  \n Class :character   1st Qu.:   57.5   1st Qu.:605.2  \n Mode  :character   Median :  325.0   Median :670.8  \n                    Mean   : 9990.2   Mean   :679.9  \n                    3rd Qu.: 6717.8   3rd Qu.:771.2  \n                    Max.   :55522.0   Max.   :877.5  \n\n\nWe see freq has a pretty big range, from 4 to 55522. rt has a range of 507.38 to 877.53, with an average reaction time of 679.9. Let’s now get an overview of the relationship between freq and rt.\n\nplot(df_freq$freq, df_freq$rt)\n\n\n\n\nWe see there are a lot of frequency values below roughly 400, and these seem to have higher reaction times than those with a higher frequency value. Let’s fit these data to our first linear model to explore this effect of frequency on reaction times.\n\n\n2.1.2 lm()\nThe the lm() function fits simple linear models. As arguments it takes a formula and a dataset, at minimum, as in equation \\(\\ref{eq-lm}\\).\n\\[\\begin{equation}\nlm(outcome \\sim 1 + predictor,\\;data\\;=\\;df\\_name) \\label{eq-lm}\n\\end{equation}\\]\nThe lm() function formula syntax can be read as: outcome predicted by the intercept (1 is a placeholder for the intercept) and predictor. The intercept is included by default, so if you omit the 1 the intercept is still included in the formula. If you wanted to remove the intercept (which you often don’t), you could replace 1 with 0.\n\n2.1.2.1 Running a model\nBefore we add our predictor freq, let’s see what our model looks like without it. We can write it as:\n\nlm(rt ~ 1, data = df_freq) \n\nBut it’s useful to save the model as an object so that we can call on it later. It’s often a good idea to have informative prefixes to your objects\n\nfit_rt_1 &lt;- lm(rt ~ 1, data = df_freq) \n\n\n\n\n\n\n\nObject naming\n\n\n\nYou may have wondered what the letters df are for when loading in our data set as df_freq. These letters stand for ‘data frame’, and serve as a reminder of what exactly that object in our environment is. We might also have wanted to plot the frequency data, in which case we could call save the plot as fig_freq or plot_freq. Here we are saving our model as fit_rt_1, using ‘fit’ to signal that this object is a model fit. You could also save it as mod_freq_1, lm_freq_1, or whatever you see fit. This simply helps keep our environment structured, which will become useful when you begin working with multiple datasets at a time.\n\n\n\n\n2.1.2.2 Model ouput\nNow that we’ve saved our model in our Enrivonement, we can call it by name. Printing just the model gives us the formula and the coefficients.\n\n# print model\nfit_rt_1\n\n\nCall:\nlm(formula = rt ~ 1, data = df_freq)\n\nCoefficients:\n(Intercept)  \n      679.9  \n\n\nRecall that the intercept and slope are called coefficients. Why do we only see Intercept? Because we didn’t include any predictors in our model. This output isn’t very dense, however. We typically use the summary() function to print full model outputs.\n\nsummary(fit_rt_1)\n\n\nCall:\nlm(formula = rt ~ 1, data = df_freq)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-172.537  -74.677   -9.137   91.296  197.613 \n\nCoefficients:\n            Estimate Std. Error t value       Pr(&gt;|t|)    \n(Intercept)   679.92      34.02   19.99 0.000000000538 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 117.8 on 11 degrees of freedom\n\n\nWe see a lot more information here.\n\n\n\n\n\n\nbroom package\n\n\n\nThe broom package has some useful functions for printing model outputs\n\ntidy() produces a tibble (type of dataframe) of the coefficients\nglance() produces goodness of fit measures (which we won’t discuss)\n\nThe outputs from tidy() and glance() can be fed into kable and/or kable_styling() to create formatted tables\n\ntidy(fit_rt_1)\n\n# A tibble: 1 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     680.      34.0      20.0 5.38e-10\n\n\n\nglance(fit_rt_1)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         0             0  118.        NA      NA    NA  -73.7  151.  152.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\naugment() adds model values as columns to your dataframe (e.g., useful for plotting observed vs. fitted values).\n\naugment(fit_rt_1, data = df_freq) %&gt;% summary()"
  },
  {
    "objectID": "02-simple_linear_regression.html#interpreting-model-output",
    "href": "02-simple_linear_regression.html#interpreting-model-output",
    "title": "2  Simple linear regression",
    "section": "2.2 Interpreting model output",
    "text": "2.2 Interpreting model output\n\nlet’s take a closer look at our model summary\n\n\nsummary(fit_rt_1)\n\n\nCall:\n1lm(formula = rt ~ 1, data = df_freq)\n\nResiduals:\n     Min       1Q   Median       3Q      Max\n2-172.537  -74.677   -9.137   91.296  197.613\n\nCoefficients:\n3            Estimate Std. Error t value       Pr(&gt;|t|)\n4(Intercept)   679.92      34.02   19.99 0.000000000538 ***\n---\n5Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n6Residual standard error: 117.8 on 11 degrees of freedom\n\n\n1\n\nformula repetition\n\n2\n\nresiduals: differences between observed values and those predicted by the model\n\n3\n\nnames for columns Estimates, standard error, t-value, p-value (Pr(&gt;|t|))\n\n4\n\nIntercept (\\(b_0\\))\n\n5\n\nSignificance codes\n\n6\n\nR\\(^2\\), a measure of model fit (squared residuals); percentage of variance in the data shared with the predictor (higher numbers are better…this is pretty low)\n\n\n\n\n\n2.2.0.1 Intercept\nOur intercept is roughly 679.9 milliseconds; what does this number represent?\n\n# print model intercept?\ncoef(fit_rt_1)['(Intercept)']\n\n(Intercept) \n   679.9167 \n\n\n\n# print data mean\nmean(df_freq$rt)\n\n[1] 679.9167\n\n\nThe intercept corresponds to the mean reaction time value. Let’s explore this.\n\n2.2.0.1.1 Intercept significance\nIn the model output, the intercept seems to be significant (indicated with a low p-value, and ***). What does this mean? Significance pretty much tells us if a number is equal to (or not statistically significantly different from) 0. So this tells us that the intercept (i.e., the mean reaction time) is different from 0. How do we interpret this? In most cases we don’t. Whether or not the intercept is significantly different from 0 this isn’t interesting or even theoretically relevant, as reaction times shouldn’t be near 0, so neither should their mean. This is also true for formant frequencies, reading times, and other types of continuous linguistic data.\n\n\n\n2.2.0.2 Standard Error\nStandard error takes both the variability in our data and the sample size into account. The equation for standard error is:\n\\[\\begin{equation}\nSE = \\frac{\\hat{\\sigma}}{\\sqrt{n}} \\label{eq-se}\n\\end{equation}\\]\nwhere \\(\\sigma\\) is the standard deviation, and \\(n\\) is the sample size. As a refresher, the equation for standard deviation (\\(\\ref{eq-sd}\\)) is the square root of the sum of all squared deviances from the mean (\\(\\sum^n_{i=1}(x_i - \\hat{\\mu})^2\\)) divided by the sample size -1. Don’t stress about the math for now, but it’s helpful to try to understand where there values come from and what they represent.\n\\[\\begin{equation}\n\\hat{\\sigma} = \\sqrt{\\frac{\\sum^n_{i=1}(x_i - \\hat{\\mu})^2}{n-1}} \\label{eq-sd}\n\\end{equation}\\]\n\n\n2.2.0.3 t-values\nSimple linear regression is equivalent to a t-test. The one-sample t-test corresponds to an intercept-only.\n\ndf_freq %&gt;% \nt.test(rt ~ 1, data = .)\n\n\n    One Sample t-test\n\ndata:  rt\nt = 19.988, df = 11, p-value = 0.000000000538\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 605.0461 754.7872\nsample estimates:\nmean of x \n 679.9167 \n\n\n\ndf_freq %&gt;% \nlm(rt ~ 1, data = .) %&gt;% \n  tidy() %&gt;%\n  mutate_if(is.numeric, round, 10)\n\n# A tibble: 1 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)     680.      34.0      20.0 0.0000000005\n\n\nThe real power of linear regression is coming tomorrow and in January…multiple regression and mixed models. But for now, it’s important to remember that the larger the t-value, the smaller the p-value. But more important is to not rely too heavily on p-values, as such black-and-white classifications have proven a poor substitute for understanding our data and our models.\n\n\n2.2.0.4 p-values\n\n\n\n\n\n\nA word on t-values and p-values\n\n\n\nt-values quantify the difference between population means.\np-values quantify the probability of obtaining a result equal to or greater than what was observed, given the assumption of no effect (the null hypothesis).\nIf the null hypothesis were true, we would expect no effect (a flat line). If we have a lot of evidence/are confidence that there is an effect (the line (slope) is in fact not flat), then it would be unlikely that we would find such a result under the assumption that there is no effect (the line actually is flat) i.e., the null hypothesis. This is reflected in a small p-value.\n\n\n\n\n2.2.0.5 Plotting rt ~ 1\n\nFigure 2.1 shows the intercept (red dot) amongst the observed data (black dots)\n\nalong the x-axis we have abstract numerical units (the values don’t mean anything)\nwhat would the values of the intercept be?\n\n\n\n\n\n\n\nFigure 2.1: Visualisation of ‘rt ~ 1’: observed values (black) and mean (intercept; red). Residuals would be the distance from each black dot to the y-value of the read dot"
  },
  {
    "objectID": "02-simple_linear_regression.html#adding-a-fixed-effect-slope",
    "href": "02-simple_linear_regression.html#adding-a-fixed-effect-slope",
    "title": "2  Simple linear regression",
    "section": "2.3 Adding a fixed effect (slope)",
    "text": "2.3 Adding a fixed effect (slope)\nNow let’s include a predictor, which will give us a slope. The slope represents the change in \\(y\\) (DV: rt) when we move 1-unit along \\(y\\) (IV: freq). In other words, it tells us the effect our IV has on the DV. Let’s first plot the data:\n\ndf_freq |&gt; \n  ggplot() +\n  aes(x = freq, y = rt) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n2.3.1 Fit model (treatment contrasts)\n\n# fit simple linear model\nfit_rt_freq &lt;- lm(rt ~ freq, data = df_freq)\n\n\n2.3.1.1 Model summary\n\nsummary(fit_rt_freq)\n\n\nCall:\nlm(formula = rt ~ freq, data = df_freq)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-155.947  -73.141    2.117   85.050  163.837 \n\nCoefficients:\n              Estimate Std. Error t value     Pr(&gt;|t|)    \n(Intercept) 713.706298  34.639105   20.60 0.0000000016 ***\nfreq         -0.003382   0.001699   -1.99       0.0746 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 104.6 on 10 degrees of freedom\nMultiple R-squared:  0.2838,    Adjusted R-squared:  0.2121 \nF-statistic: 3.962 on 1 and 10 DF,  p-value: 0.07457\n\n\n\n\n2.3.1.2 Intercept\nThe intercept in our last model was the mean reaction time. But now it’s a different value.\n\n# print model intercept\ncoef(fit_rt_freq)['(Intercept)']\n\n(Intercept) \n   713.7063 \n\n\n\n# print data mean\nmean(df_freq$rt)\n\n[1] 679.9167\n\n\nOur intercept is no longer the grand mean of first-pass reading times…what is it?\n\n\n2.3.1.3 Slope\nOur slope was our slope -0.0033823. What does this correspond to?\n\n# print slope\ncoef(fit_rt_freq)['freq']\n\n        freq \n-0.003382289 \n\n\nThis is the change in \\(y\\) (our DV rt) for a 1-unit change in \\(x\\) (our IV: freq). So when we move up 1 unit in frequency, reaction times decrease by -0.0033823. Whether or not it makes sense to consider this number depends on the measurement unit your data is in, e.g., a unit change from one millimeter or one meter will have a drastically different slope value (say, for age), but the actual slope will be the exact same.\n\nheights_m &lt;- c(1.71, 1.56, .9, 2.06, 1.63)\nheights_cm &lt;- c(171, 156, 90, 206, 163)\nheights_mm &lt;- c(1710, 1560, 900, 2060, 1630)\nyear &lt;- c(22,15,10,26,18)\nmonths &lt;- c(22,15,10,26,18)*12\ndays &lt;- c(22,15,10,26,18)*365\n\ndf_heights_age &lt;- cbind(year, months, days, heights_mm, heights_cm, heights_m) |&gt; as.data.frame() |&gt; \n  pivot_longer(\n    cols = c(heights_mm, heights_cm, heights_m),\n    names_to = \"unit\",\n    values_to = \"height\"\n  ) |&gt; \n  pivot_longer(\n    cols = c(year, months, days),\n    names_to = \"unit_age\",\n    values_to = \"age\"\n  )\n\n\n\n\nlm(heights_mm ~ year)\n\n\nCall:\nlm(formula = heights_mm ~ year)\n\nCoefficients:\n(Intercept)         year  \n     396.62        64.58  \n\nlm(heights_cm ~ days)\n\n\nCall:\nlm(formula = heights_cm ~ days)\n\nCoefficients:\n(Intercept)         days  \n   39.66230      0.01769  \n\nlm(heights_m ~ months)\n\n\nCall:\nlm(formula = heights_m ~ months)\n\nCoefficients:\n(Intercept)       months  \n   0.396623     0.005382  \n\nlm(heights_mm ~ year)\n\n\nCall:\nlm(formula = heights_mm ~ year)\n\nCoefficients:\n(Intercept)         year  \n     396.62        64.58  \n\nlm(heights_cm ~ year)\n\n\nCall:\nlm(formula = heights_cm ~ year)\n\nCoefficients:\n(Intercept)         year  \n     39.662        6.458  \n\nlm(heights_m ~ year)\n\n\nCall:\nlm(formula = heights_m ~ year)\n\nCoefficients:\n(Intercept)         year  \n    0.39662      0.06458  \n\n\n\nggplot(data = df_heights_age) +\n  aes(x = height, y = age) +\n  facet_wrap(unit ~ unit_age, scales = \"free\") +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  theme_bw()"
  },
  {
    "objectID": "02-simple_linear_regression.html#model-assumptions",
    "href": "02-simple_linear_regression.html#model-assumptions",
    "title": "2  Simple linear regression",
    "section": "2.4 Model assumptions",
    "text": "2.4 Model assumptions\nNow that we’ve fit a model and understand the output, it’s time to think about whether this model is a good fit for our data. We first have to understand some assumptions that need to met in regression modelling. Importantly, these assumptions reate to the residuals of our model, not the raw data points themselves. The two assumptions we’ll focus on for now are the assumptions of normality of the residuals, and the constant variance of the residuals. Both assumptions are often diagnosed visually, so it takes some practice to learn what looks right.\n\n2.4.1 Normality\nWhen a model satisfies the normalit assumption, its residuals (i.e., the difference between the fitted and observed values) will be approximately normally distributed. Normality is typically visualised using a histogram (Figure 2.2 A) and/or a quantile-quantile (Q-Q) plot (Figure 2.2 B).\n\n\n\n\n\nFigure 2.2: Image source: Winter (2019) (all rights reserved)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWinter (2019)’s description of how QQ plots are generated (p. 110):\nTo create this plot, every residual is transformed into a percentile (or quantile) […] The question the Q-Q plot answers is: what is the corresponding numerical value of the 13.8th percentile on the normal distribution? If the values are the same, they will fit on a straight line, which indicates that the two distributions (the distribution of the residuals and the theoretical normal distribution) are very similar.\n\n\n\n\n2.4.2 Constant variance\nWhen a model satisfies the constant variance assumption (also called homoscedasticity, or the absence of heteroscedasticity), the spread of residuals will be equal across the regression line. This is typically visualised using a residual plot, which should look like a blob (Figure 2.2 C).\n\n\n2.4.3 Visualising model assumptions\nLet’s plot our residuals to assess whether our model satisfies the assumptions of normality and constant variance.\n\n2.4.3.1 Histogram\nWe can do this how it’s done in Winter (2019) (in Ch. 6, p. 110-111), by first extracting the residuals from the model and then fitting them them using the base R function hist().\n\n# extract residuals\nres &lt;- residuals(fit_rt_freq)\n\n\n# plot histogram\nhist(res)\n\n\n\n\nOr, we can use the augment() function from broom to append model values to our original data frame, and then feed this into ggplot() from ggplot2 (or even feed it into hist()).\n\n# or, add to df\ndf_freq &lt;- broom::augment(fit_rt_freq, df_freq)\n\n\n# and create ggplot\ndf_freq |&gt; \n  ggplot() +\n  aes(x = .resid) +\n  geom_histogram(bins = 8, fill = \"grey\", colour = \"black\") +\n  theme_bw()\n\n\n\n\n\n\n2.4.3.2 Q-Q plot\nAgain, we can do it Bodo’s way:\n\nqqnorm(res)\nqqline(res)\n\n\n\n\nOr using augment() and ggplot().\n\ndf_freq |&gt; \n  ggplot() +\n  aes(sample = .resid) +\n  geom_qq(colour = \"red\") +\n  geom_qq_line() \n\n\n\n\n\n\n2.4.3.3 Residual plot\nBodo’s way:\n\nplot(fitted(fit_rt_freq), res)\n\n\n\n\nOr with ggplot:\n\ndf_freq |&gt; \n  ggplot() +\n  aes(x = .fitted, y = .resid) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n2.4.4 performance package\nI like to use the performance package to visualise model fit (Lüdecke et al., 2021).\n\nperformance::check_normality(fit_rt_freq)\n\nOK: residuals appear as normally distributed (p = 0.702).\n\n\n\nperformance::check_heteroscedasticity(fit_rt_freq)\n\nOK: Error variance appears to be homoscedastic (p = 0.980).\n\n\n\nperformance::check_model(fit_rt_freq)\n\n\n\n\n\n2.4.4.1 Coefficients table with summary()\n\n\n&gt; summary(fit_rt_freq)\n\nCall:\n1lm(formula = rt ~ lifetime, data = df_freq, subset = rt &gt; 0)\n\n2Residuals:\n    Min      1Q  Median      3Q     Max \n-228.99 -109.29  -26.99   58.86  777.71 \n\nCoefficients:\n3             Estimate Std. Error t value Pr(&gt;|t|)\n4(Intercept)  309.142      6.259  49.394 &lt;0.0000000000000002 ***\n5lifetime1     31.701     12.517   2.533              0.0116 *\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 57.46 on 541 degrees of freedom\n6Multiple R-squared:  0.01172,   Adjusted R-squared:  0.00989\nF-statistic: 6.414 on 1 and 541 DF,  p-value: 0.0116\n\n\n1\n\nformula\n\n2\n\nResiduals: differences between observed values and those predicted by the model\n\n3\n\nNames for columns Estimates, SE, t-value, p-value\n\n4\n\nIntercept (\\(b_0\\)), i.e., value of \\(y\\) (first-pass) with a move of one unit of \\(x\\) (lifetime)\n\n5\n\nSlope (\\(b_1\\)), i.e., change in first fixation going from dead to living\n\n6\n\nOutput from an ANOVA\n\n\n\n\n\n\n\nwhat is the intercept?\nis the slope positive or negative?\n\nwhat is it’s value?\n\nthis is what the slope would look like:\n\n\n\n\n\nExploring the model\n\n# how many observed values did we enter into the model?\ndf_freq |&gt; \n  nrow()\n\n[1] 12\n\n\n\n# how many observed values did we enter into the model?\nlength(fitted(fit_rt_freq))\n\n[1] 12\n\n\n\n\nExploring the model: residuals\n\n# what do our FITTED values look like?\nhead(fitted(fit_rt_freq))\n\n       1        2        3        4        5        6 \n525.9148 576.2873 663.3271 700.2042 700.6845 712.3229 \n\n\n\n# what do our OBSERVED values look like?\nhead(df_freq$rt)\n\n[1] 621.77 519.56 507.38 636.56 587.18 705.00\n\n\n\n# what is the difference between the FITTED and OBSERVED values?\nhead(df_freq$rt) - head(fitted(fit_rt_freq))\n\n          1           2           3           4           5           6 \n  95.855154  -56.727276 -155.947103  -63.644200 -113.504485   -7.322942 \n\n\n\n# what are our RESIDUALS?\nhead(residuals(fit_rt_freq))\n\n          1           2           3           4           5           6 \n  95.855154  -56.727276 -155.947103  -63.644200 -113.504485   -7.322942 \n\n\n\n\nExploring the model\n\nwhat were our coefficients?\n\n\ncoef(fit_rt_freq)\n\n  (Intercept)          freq \n713.706297951  -0.003382289 \n\n\n\nwhat would be our predicted reaction time for a word with frequency of 0?\n\n\ncoef(fit_rt_freq)['(Intercept)'] + coef(fit_rt_freq)['freq'] * 0\n\n(Intercept) \n   713.7063 \n\n\n\nignore the (Intercept) label here, R just takes the first label when performing an operation on 2 vectors\nwhat is the mean of our predictor coded as +0.5?\n\n\ncoef(fit_rt_freq)['(Intercept)'] + coef(fit_rt_freq)['freq'] * 5000\n\n(Intercept) \n   696.7949 \n\n\n\n\n\n\n\n\nImage source: Winter (2019) (all rights reserved)"
  },
  {
    "objectID": "02-simple_linear_regression.html#reporting-your-model",
    "href": "02-simple_linear_regression.html#reporting-your-model",
    "title": "2  Simple linear regression",
    "section": "2.5 Reporting your model",
    "text": "2.5 Reporting your model\nSection"
  },
  {
    "objectID": "02-simple_linear_regression.html#summary",
    "href": "02-simple_linear_regression.html#summary",
    "title": "2  Simple linear regression",
    "section": "2.6 Summary",
    "text": "2.6 Summary\n\nwe saw that the equation for a straight line boils down to its intercept and slope\nwe fit our first linear model with a categorical predictor"
  },
  {
    "objectID": "02-simple_linear_regression.html#important-terms",
    "href": "02-simple_linear_regression.html#important-terms",
    "title": "2  Simple linear regression",
    "section": "Important terms",
    "text": "Important terms\n\n\n\n\n\n\n  \n    \n    \n      Term\n      Definition\n      Equation/Code\n    \n  \n  \n    Coefficients\nthe slope and the intercept are coefficiens\nNA\n    Simple linear regression\nlinear regression with a single predictor and a continuous outcome variable\n`lm(response ~ predictor, data = data)`\n    fitted values\npredicted values\npredict(model_name)\n    continuous variable\na variable that can have an infinite number of values (an example would be reading time in ms)\nNA\n    dependent variable\nwhat we measure; a.k.a. measure/outcome/response variable\nNA\n    independent variable\nour predictor; a.k.a., predictor variable, fixed effects\nNA\n    coefficients\nvalues of the intercept and slope of a lm() model\ncoef()\n    equation of a line\nvalue of y = intercept + (slope*value of x)\ny=b0+b1*xi"
  },
  {
    "objectID": "02-simple_linear_regression.html#learning-objectives-1",
    "href": "02-simple_linear_regression.html#learning-objectives-1",
    "title": "2  Simple linear regression",
    "section": "Learning Objectives 🏁",
    "text": "Learning Objectives 🏁\nToday we learned…\n\nhow to fit a simple linear model with the lm() function\nhow to interpret our model output"
  },
  {
    "objectID": "02-simple_linear_regression.html#task",
    "href": "02-simple_linear_regression.html#task",
    "title": "2  Simple linear regression",
    "section": "2.7 Task",
    "text": "2.7 Task\nNow it’s your turn. Try to run the following lm() models:\n\ntotal reading time at the verb region\ntotal reading time at the verb+1 region."
  },
  {
    "objectID": "02-simple_linear_regression.html#session-info",
    "href": "02-simple_linear_regression.html#session-info",
    "title": "2  Simple linear regression",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] magick_2.7.4        googlesheets4_1.1.0 gt_0.9.0           \n [4] kableExtra_1.3.4    knitr_1.44          patchwork_1.1.3    \n [7] languageR_1.5.0     janitor_2.2.0       lme4_1.1-33        \n[10] Matrix_1.5-4        broom_1.0.5         here_1.0.1         \n[13] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0      \n[16] dplyr_1.1.3         purrr_1.0.2         readr_2.1.4        \n[19] tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3      \n[22] tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0   viridisLite_0.4.2  farver_2.1.1       fastmap_1.1.1     \n [5] bayestestR_0.13.1  pacman_0.5.1       digest_0.6.33      timechange_0.2.0  \n [9] lifecycle_1.0.3    magrittr_2.0.3     compiler_4.3.0     sass_0.4.6        \n[13] rlang_1.1.1        tools_4.3.0        utf8_1.2.3         yaml_2.3.7        \n[17] labeling_0.4.3     htmlwidgets_1.6.2  curl_5.0.1         bit_4.0.5         \n[21] xml2_1.3.4         withr_2.5.0        datawizard_0.7.1   grid_4.3.0        \n[25] googledrive_2.1.0  fansi_1.0.4        colorspace_2.1-0   scales_1.2.1      \n[29] MASS_7.3-58.4      insight_0.19.3     cli_3.6.1          rmarkdown_2.22    \n[33] crayon_1.5.2       generics_0.1.3     performance_0.10.4 rstudioapi_0.14   \n[37] httr_1.4.6         tzdb_0.4.0         minqa_1.2.5        splines_4.3.0     \n[41] rvest_1.0.3        parallel_4.3.0     cellranger_1.1.0   vctrs_0.6.3       \n[45] boot_1.3-28.1      webshot_0.5.4      jsonlite_1.8.7     hms_1.1.3         \n[49] ggrepel_0.9.3      bit64_4.0.5        systemfonts_1.0.4  see_0.8.0         \n[53] glue_1.6.2         nloptr_2.0.3       stringi_1.7.12     gtable_0.3.4      \n[57] munsell_0.5.0      pillar_1.9.0       htmltools_0.5.5    R6_2.5.1          \n[61] rprojroot_2.0.3    vroom_1.6.3        evaluate_0.21      lattice_0.21-8    \n[65] png_0.1-8          backports_1.4.1    snakecase_0.11.0   gargle_1.4.0      \n[69] Rcpp_1.0.11        svglite_2.1.1      nlme_3.1-162       mgcv_1.8-42       \n[73] xfun_0.39          fs_1.6.2           pkgconfig_2.0.3"
  },
  {
    "objectID": "02-simple_linear_regression.html#references",
    "href": "02-simple_linear_regression.html#references",
    "title": "2  Simple linear regression",
    "section": "References",
    "text": "References\n\n\nLüdecke, D., Ben-Shachar, M. S., Patil, I., Waggoner, P., & Makowski, D. (2021). performance: An R package for assessment, comparison and testing of statistical models. Journal of Open Source Software, 6(60), 3139. https://doi.org/10.21105/joss.03139\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "03-continuous_predictors.html#learning-objectives",
    "href": "03-continuous_predictors.html#learning-objectives",
    "title": "3  Continuous predictors",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we will learn…\n\nwhy and how to centre continuous predictors\nwhen and how to standardize continuous predictors\nwhy and how to log-transform continuous variables"
  },
  {
    "objectID": "03-continuous_predictors.html#set-up-environment",
    "href": "03-continuous_predictors.html#set-up-environment",
    "title": "3  Continuous predictors",
    "section": "Set-up environment",
    "text": "Set-up environment\n\n# suppress scientific notation\noptions(scipen=999)\n\nWe’ll also need to load in our required packages. Hopefully you’ve already install the required packages (if not, go to Chapter 3).\n\n# load libraries\npacman::p_load(\n               tidyverse,\n               here,\n               broom,\n               lme4,\n               janitor,\n               languageR)\n\n\nLoad data\n\ndf_freq &lt;- read_csv(here(\"data\", \"ELP_frequency.csv\")) |&gt; \n  clean_names()\n\nReminder of our variables:\n\nsummary(df_freq)\n\n     word                freq               rt       \n Length:12          Min.   :    4.0   Min.   :507.4  \n Class :character   1st Qu.:   57.5   1st Qu.:605.2  \n Mode  :character   Median :  325.0   Median :670.8  \n                    Mean   : 9990.2   Mean   :679.9  \n                    3rd Qu.: 6717.8   3rd Qu.:771.2  \n                    Max.   :55522.0   Max.   :877.5"
  },
  {
    "objectID": "03-continuous_predictors.html#summary",
    "href": "03-continuous_predictors.html#summary",
    "title": "3  Continuous predictors",
    "section": "Summary",
    "text": "Summary\nIn the last lectures we saw that the equation for a straight line boils down to its intercept and slope, and that linear regression fits a line to our data. This line results in predicted/fitted values, which fall along the line, and residuals, which are the difference between our observed values and the fitted values.\nWe also learned about two model assumptions: normality of residuals, and constant variance of residuals. We learned that we can plot these with histograms or Q-Q plots (normality), and residual plots (constant variance).\nNow that we understand what a simple linear does, we can take a step back and focus on what we put into the model. So far we’ve looked at reaction times (milliseconds) as a function of word frequency. However, we don’t typically feed raw continuous data into a model, because most continuous linguistic variables are not normally distributed, and so a straight line will not fit it very well (because there will be some large variance for higher values)."
  },
  {
    "objectID": "03-continuous_predictors.html#linear-transformations",
    "href": "03-continuous_predictors.html#linear-transformations",
    "title": "3  Continuous predictors",
    "section": "3.1 Linear transformations",
    "text": "3.1 Linear transformations\nLinear transformations refer to constant changes across values that do not alter the relationship between these values. For example, adding, subtracting, or multiplying by a constant value will not alter the difference between values. Think of the example in the last lecture on the relationship between heights and ages as a function of the measurement unit: the relationship between all the values did not alter, because the difference between heights millimeters, centimeters, and meters is constant, as is the difference between ages in days, months, or years. We’ll now look at some common ways of linearly transforming our data, and the reasons behind doing so.\n\n3.1.1 Centering\nCentering is typically applied to predictor variables. Centering refers to subtracting the mean of a variable from each value, resulting in each centered value representing the original value’s deviance from the mean (i.e., a mean-deviation score). What would a centered value of \\(0\\) represent in terms of the original values?\nLet’s try centering our frequency values. To create a new variable (or alter an existing variable), we can use the mutate() function from dplyr.\n\n# add centered variable\ndf_freq &lt;- \n  df_freq |&gt; \n  mutate(freq_c = freq-mean(freq))\n\nThis can also be done with base R, but it’s a lot more verbose.\n\n# add centered variable with base R\ndf_freq$freq_c &lt;- df_freq$freq-mean(df_freq$freq)\n\nNow let’s fit our models.\n\n# run our model with the original predictor\nfit_rt_freq &lt;- \n  lm(rt ~ freq, data = df_freq)\n\n\n# run our model with the centered predictor\nfit_rt_freq_c &lt;- \n  lm(rt ~ freq_c, data = df_freq)\n\nIf we compare the coefficients from fit_rt_freq and fit_rt_freq_c, what do we see? The only difference is the intercept values: 713.706298 (uncentered) and 679.9166667 (centered).\n\nmean(df_freq$rt)\n\n[1] 679.9167\n\n\nThe intercept for a centered continuous predictor variable corresponds to the mean of a continuous response variable. This is crucial in interpreting interaction effects, which we will discuss tomorrow. For more detail on interpreting interactions, see Chapter 8 in Winter (2019) (we won’t be discussing this chapter as a whole).\n\n\n\n\n\n\nCentering interval data\n\n\n\nIf you have interval data with a specific upper and lower bound, you could alternatively subtract the median value. In linguistic research, this is most typically rating scale data. For example, if you have a dataset consisting of ratings from 1-7, you can centre these ratings by subtracting 4 from all responses. A centred response of -3 would correspond to the lowest rating (1), and of +3 to the highest rating (7), which 0 would correspond to a medial rating (4). This can also be helpful in plotting, as there is no question as to whether 1 or 7 was high or low, because all ratings are now centred around 0 (and negative numbers correspond to our intuition of low-ratings).\n\n\n\n\n3.1.2 Standardizing (z-scoring)\nWe can also standardize continuous predictors by dividing centered values by the standard deviation of the sample. Let’s look at our frequency/reaction time data again.\nFirst, what are our mean and standard deviation? This will help us understand the changes to our variables as we center and stardardize them.\n\nmean(df_freq$freq)\n\n[1] 9990.167\n\n\n\nsd(df_freq$freq)\n\n[1] 18558.69\n\n\nWhat are the first six values of freq in the original scale?\n\ndf_freq$freq[1:6]\n\n[1] 55522 40629 14895  3992  3850   409\n\n\nWhat are the first six values of freq_c in the centered scale? These should be the values of freq minus the mean of freq (which we saw above is 9990.1666667).\n\ndf_freq$freq_c[1:6]\n\n[1] 45531.833 30638.833  4904.833 -5998.167 -6140.167 -9581.167\n\n\nNow, let’s create our standardised z-scores for frequency by dividing these centered values by the standard deviation of freq (which will be the same as the standard deviation of freq_c), and which we saw is 18558.6881679. Again, this can be done with mutate() from dplyr, or by using base R syntax.\n\n# standardise using the tidyverse\ndf_freq &lt;- \n  df_freq |&gt; \n  mutate(freq_z = freq_c/sd(freq))\n\n\n# standardize with base R\ndf_freq$freq_z &lt;- df_freq$freq_c/sd(df_freq$freq)\n\n\nhead(df_freq)\n\n# A tibble: 6 × 5\n  word      freq    rt freq_c freq_z\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 thing    55522  622. 45532.  2.45 \n2 life     40629  520. 30639.  1.65 \n3 door     14895  507.  4905.  0.264\n4 angel     3992  637. -5998. -0.323\n5 beer      3850  587. -6140. -0.331\n6 disgrace   409  705  -9581. -0.516\n\n\n\n\n\n\n\n\nCorrelation"
  },
  {
    "objectID": "03-continuous_predictors.html#non-linear-transformations",
    "href": "03-continuous_predictors.html#non-linear-transformations",
    "title": "3  Continuous predictors",
    "section": "3.2 Non-linear transformations",
    "text": "3.2 Non-linear transformations\nThis is really the meat and potates of dealing with continuous variables (depending on your subfield). In linguistic research, and especially experimental research, we often deal with continuous variables truncated/bound at 0. Reaction times, reading times and formant frequencies are all examples of such types of data: there is no such thing as a negative reading time or fundamental frequency. The problem with these types of data is that they are almost never normally distributed, which has implications for the normality of residuals for any line that tries to fit to these data. Very often, this type of data will have a ‘positive skew’, or a long tail off to the right (assuming larger values are plotting to the right). This shape is not symmetrical, meaning that the residuals tend to be much larger for larger values. It is also often the case that these very large, exceptional values will have a stronger influence on the line of best fit, leading to the coefficient estimates that are “suboptimal for the majority of data points” [@Baayen (2008); p. 92]. How do we deal with this nonnormality? We use non-linear transformations, the most common of which is the log-transformation.\n\n3.2.1 Log-transformation\nLet’s look at our reaction time data again. We’ll log-transform our reaction time data and frequency data. Note that in Winter (2019), frequency is transformed using log to the base 10 for interpretability, but we’ll stick to the natural logarithm.\n\ndf_freq |&gt; \n  ggplot() +\n  aes(x = log(freq)) +\n  geom_density()\n\n\n\n\n\ndf_freq &lt;-\n  df_freq |&gt; \n    mutate(rt_log = log(rt),\n           freq_log = log(freq))\n\n\nlm(rt_log ~ freq_log, data = df_freq) |&gt; tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   6.79     0.0611     111.   8.56e-17\n2 freq_log     -0.0453   0.00871     -5.20 4.03e- 4\n\n\n\n# or, log-transform directly in the model syntax\nlm(log(rt) ~ log(freq), data = df_freq) |&gt; tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   6.79     0.0611     111.   8.56e-17\n2 log(freq)    -0.0453   0.00871     -5.20 4.03e- 4"
  },
  {
    "objectID": "03-continuous_predictors.html#learning-objectives-1",
    "href": "03-continuous_predictors.html#learning-objectives-1",
    "title": "3  Continuous predictors",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we learned…\n\nwhy and how to centre continuous predictors\nwhen and how to standardize continuous predictors\nwhy and how to log-transform continuous variables"
  },
  {
    "objectID": "03-continuous_predictors.html#important-terms",
    "href": "03-continuous_predictors.html#important-terms",
    "title": "3  Continuous predictors",
    "section": "Important terms",
    "text": "Important terms\n\n\n\n\n\n\n  \n    \n    \n      Term\n      Definition\n      Equation/Code\n    \n  \n  \n    Centering\ntype of linear transformation\n`dplyr::mutate(variable = variable - mean(variable))`\n    standardizing\nlinear transformation (applied for multiple continuous predictors)\ndf_freq$freq_z &lt;- df_freq$freq_c/sd(df_freq$freq)\n    log-transformation\nnon-linear transformation for positively skewed continuous variables\nlog()\n    Error (random effects)\nhings we cannot understand/measure. There are always sources of random error.\nNA"
  },
  {
    "objectID": "03-continuous_predictors.html#take-home-messages",
    "href": "03-continuous_predictors.html#take-home-messages",
    "title": "3  Continuous predictors",
    "section": "Take-home messages",
    "text": "Take-home messages\nContinuous data are often transformed before fitting a model to this data. Linear transformations, like adding or multiplying all values by a single value, are often performed on continuous predictors by means of centring and standardizing (when there are multiple continuous predictors). Non-linear transformations are often performed on continuous data with a positive skew (a few values much larger than the majority) in order to satisfy the normality assumption. Although the normality assumption refers to the normality of residuals, the distribution of the data will have implications for the distribution of the residuals. The most common non-linear transformation is the log-transformation (the inverse of the exponential), which shrinks values, especially making big numbers smaller. This has the result of squeezing big numbers towards smaller numbers, reducing the spread in the distribution (e.g., the log of 3 is 1.0986123, the log of 30 is 3.4011974, and the log of 30 is 5.7037825).\nWhat to do with this information? If you have continuous data truncated at 0 (with no upperbound, e.g., reaction time data or fundamental frequency), visualise the data (histogram and Q-Q plot) in order to check its distribution. If it is not normally distributed, you will likely want to log-transform it. Is this data your response variable? Then that is all you will likely want to do. Is this data a predictor variable? Then you will want to centre it (subtract the mean of this variable from all values). Do you have more than one continuous predictor variable? Then standardizing these variables will facilitate the interpretation of interaction effects (we’ll talk about these soon)."
  },
  {
    "objectID": "03-continuous_predictors.html#task",
    "href": "03-continuous_predictors.html#task",
    "title": "3  Continuous predictors",
    "section": "3.3 Task",
    "text": "3.3 Task"
  },
  {
    "objectID": "03-continuous_predictors.html#assessing-assumptions",
    "href": "03-continuous_predictors.html#assessing-assumptions",
    "title": "3  Continuous predictors",
    "section": "3.4 Assessing assumptions",
    "text": "3.4 Assessing assumptions\n\nRe-run the models fit_rt_freq, fit_rt_freq_c, and fit_log\nProduce diagnostic plots for each of them (histograms, Q-Q plots, residual plots)\nInterpret the plots"
  },
  {
    "objectID": "03-continuous_predictors.html#model-comparison",
    "href": "03-continuous_predictors.html#model-comparison",
    "title": "3  Continuous predictors",
    "section": "3.5 Model comparison",
    "text": "3.5 Model comparison\n\nUse the glance() function to inspect the \\(R^2\\), AIC, and BIC of each model.\nWhich is the best fit? Why?"
  },
  {
    "objectID": "03-continuous_predictors.html#session-info",
    "href": "03-continuous_predictors.html#session-info",
    "title": "3  Continuous predictors",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] googlesheets4_1.1.0 gt_0.9.0            kableExtra_1.3.4   \n [4] knitr_1.44          patchwork_1.1.3     languageR_1.5.0    \n [7] janitor_2.2.0       lme4_1.1-33         Matrix_1.5-4       \n[10] broom_1.0.5         here_1.0.1          lubridate_1.9.2    \n[13] forcats_1.0.0       stringr_1.5.0       dplyr_1.1.3        \n[16] purrr_1.0.2         readr_2.1.4         tidyr_1.3.0        \n[19] tibble_3.2.1        ggplot2_3.4.3       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      xfun_0.39         htmlwidgets_1.6.2 gargle_1.4.0     \n [5] lattice_0.21-8    tzdb_0.4.0        vctrs_0.6.3       tools_4.3.0      \n [9] generics_0.1.3    curl_5.0.1        parallel_4.3.0    fansi_1.0.4      \n[13] pacman_0.5.1      pkgconfig_2.0.3   webshot_0.5.4     lifecycle_1.0.3  \n[17] farver_2.1.1      compiler_4.3.0    munsell_0.5.0     snakecase_0.11.0 \n[21] sass_0.4.6        htmltools_0.5.5   yaml_2.3.7        crayon_1.5.2     \n[25] pillar_1.9.0      nloptr_2.0.3      MASS_7.3-58.4     boot_1.3-28.1    \n[29] nlme_3.1-162      tidyselect_1.2.0  rvest_1.0.3       digest_0.6.33    \n[33] stringi_1.7.12    labeling_0.4.3    splines_4.3.0     rprojroot_2.0.3  \n[37] fastmap_1.1.1     grid_4.3.0        colorspace_2.1-0  cli_3.6.1        \n[41] magrittr_2.0.3    utf8_1.2.3        withr_2.5.0       scales_1.2.1     \n[45] backports_1.4.1   bit64_4.0.5       googledrive_2.1.0 timechange_0.2.0 \n[49] rmarkdown_2.22    httr_1.4.6        bit_4.0.5         cellranger_1.1.0 \n[53] hms_1.1.3         evaluate_0.21     viridisLite_0.4.2 rlang_1.1.1      \n[57] Rcpp_1.0.11       glue_1.6.2        xml2_1.3.4        vroom_1.6.3      \n[61] svglite_2.1.1     rstudioapi_0.14   minqa_1.2.5       jsonlite_1.8.7   \n[65] R6_2.5.1          fs_1.6.2          systemfonts_1.0.4"
  },
  {
    "objectID": "03-continuous_predictors.html#references",
    "href": "03-continuous_predictors.html#references",
    "title": "3  Continuous predictors",
    "section": "References",
    "text": "References\n\n\nBaayen, R. H. (2008). Analyzing Linguistic Data: A Practical Introduction to Statistics using R.\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "04-multiple_regression.html#summary",
    "href": "04-multiple_regression.html#summary",
    "title": "4  Multiple Regression",
    "section": "Summary",
    "text": "Summary\n\nwe saw that the equation for a straight line boils down to its intercept and slope\nwe fit our first linear model with a continuous predictor"
  },
  {
    "objectID": "04-multiple_regression.html#learning-objectives",
    "href": "04-multiple_regression.html#learning-objectives",
    "title": "4  Multiple Regression",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we will learn…\n\nwhat multiple regression is\nhow to include multiple predictor variables\nhow to interpret slopes in multiple regression\nhow to interpret interaction effects\nabout the assumption of the absence of collinearity"
  },
  {
    "objectID": "04-multiple_regression.html#set-up-environment",
    "href": "04-multiple_regression.html#set-up-environment",
    "title": "4  Multiple Regression",
    "section": "Set-up environment",
    "text": "Set-up environment\n\n# suppress scientific notation\noptions(scipen=999)\n\nWe’ll also need to load in our required packages. Hopefully you’ve already install the required packages (if not, go to Chapter 3).\n\n# load libraries\npacman::p_load(\n               tidyverse,\n               here,\n               broom,\n               janitor,\n               languageR)\n\n\nLoad data\nWe’ll use the full dataset of the frequency data.\n\ndf_freq_full &lt;-\n  read_csv(here(\"data\", \"ELP_full_length_frequency.csv\")) |&gt; \n  clean_names() |&gt; \n  mutate(freq = 10^(log10freq), # inverse log10\n         freq_log = log(freq)) |&gt;  # use natural logarithm\n  relocate(word, rt, length, freq, freq_log)\n\nWe have 4 variables:\n\nword\nlength\nrt\nfreq\nfreq_log\nlog10freq"
  },
  {
    "objectID": "04-multiple_regression.html#multiple-regression",
    "href": "04-multiple_regression.html#multiple-regression",
    "title": "4  Multiple Regression",
    "section": "4.1 Multiple regression",
    "text": "4.1 Multiple regression\nSo far we’ve worked with simple linear models, which fit a model to a predictor and response variable. These models do not differ so greatly from a one- or two-sample t-test (for a categorical predictor) or Pearson’s r (for a standardised continuous predictor). You might be wondering then we would bother with linear regression. One reason is that it allows us to include multiple predictors in our models, which still boils down to modeling the mean, but while condintioning the mean on multiple variables at once.\nRecall the equation of a line (\\(\\ref{eq-simple-lin-2}\\)), which states that any value of \\(y\\) equals the intercept (\\(b_0\\)) plus the corresponding value of \\(x\\) multiplied by the slope (\\(b_1x\\)), plus the error, which are our residuals (\\(e\\)). In multiple regression, we can include more than one slope (\\(\\ref{eq-multiple-reg}\\)).\n\\[\\begin{align}\ny &= b_0 + b_1x + e \\label{eq-simple-lin-2} \\\\\ny &= b_0 + b_1x + b_2x + ... + e \\label{eq-multiple-reg}\n\\end{align}\\]\n\n\n\n\n\nflowchart LR\n  A[Continuous variable] \n  A --&gt; F[Zero-truncated with positive skew \\n e.g., reaction times]\n  A --&gt; H[Interval i.e., lower and upperbound \\n e.g., rating scale]\n  H --&gt; I[Centre on median value]\n  I --&gt; E(Response)\n  E --&gt; Z[Done]\n  F --&gt; G[Non-linear transformation \\n e.g., log-transform]\n  G --&gt; B(Predictor)\n  I --&gt; B(Predictor)\n  B --&gt; C{One predictor}\n  C --&gt; X[Centre]\n  D --&gt; Y[Centre and standardise]\n  B --&gt; D{Two predictor}\n  G --&gt; E(Response)\n  \n  \n\n\nFigure 4.1: Flowchart of common steps for linear and non-linear transformations of continuous variables. Such decision trees are not a one-size-fits-all solution and cannot replace critical thinking and understanding of your data.\n\n\n\n\n\n4.1.1 One predictor\nLet’s re-run our simple model with this dataset. Let’s keep reaction times in the raw milliseconds for now for interpretability.\n\nfit_freq_full &lt;-\n  lm(rt ~ log(freq), data = df_freq_full)\n\n\ntidy(fit_freq_full)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    907.      1.09       828.       0\n2 log(freq)      -37.5     0.262     -143.       0\n\n\nWe see there is a decrease in reaction times (-37.5 milliseconds) for a 1-unit increase in log frequency. Let’s look at the model fit using glance().\n\nglance(fit_freq_full)$r.squared\n\n[1] 0.3834186\n\n\nWe see that the R-squared is 0.383, meaning our model describes 38% of the variance in response times. We can’t be sure that this described variance is due solely to frequency, however. Our models only know what we tell them! Other effects that are correlated with frequency might be conflating the frequency effect, e.g., more frequent words tend to be shorter (zipf_1949?). Let’s expand our model to include word length [\\(\\ref{eq-freq-length}\\)].\n\\[\\begin{equation}\ny = b_0 + b_1*log frequency + b_2*word length \\label{eq-freq-length}\n\\end{equation}\\]\n\n\n4.1.2 Adding a predictor\nLet’s add length as a predictor to our model.\n\nfit_freq_mult &lt;-\n  lm(rt ~ log(freq) + length, data = df_freq_full)\n\n\ntidy(fit_freq_mult) |&gt; select(term, estimate)\n\n# A tibble: 3 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    748. \n2 log(freq)      -29.5\n3 length          19.5\n\n\nWe see that length is also a significant predictor of reaction times, with an increase in word length (+1 letter) corresponds to a 20ms increase in reaction times. Our intercept is also now 748ms, instead of 907ms. The 907ms intercept corresponds to the prediction for reaction times to a word with 0 log frequency and 0 word length, but this is not very interpretable. If we were to center both prdictors, the intercept would be the reaction time for a wrd with average frequency and average length.\nThe slope for log frequency has also changed: from -37.5 to -29.5. This change tells us that some of the effect in our first model was confounded with length, as controlling for length weakens the effect of frequency.\n\nglance(fit_freq_mult)$r.squared\n\n[1] 0.4872977\n\n\nWe also see that including length increases the variance described by our model, reflected in the R-squared values (0.4872977 instead of 0.3834186."
  },
  {
    "objectID": "04-multiple_regression.html#standardising-our-predictors",
    "href": "04-multiple_regression.html#standardising-our-predictors",
    "title": "4  Multiple Regression",
    "section": "4.2 Standardising our predictors",
    "text": "4.2 Standardising our predictors\nRecall that, when we have multiple continuous predictors, standardising them can help their interpretation, as their slopes are comparable. We could achieve this by centering each variable and then dividing by the standard deviation, or we could use the scale() function, which does just this.\n\n# centre and then standardize\ndf_freq_full |&gt; \n  mutate(\n         freq_z1 = (freq-mean(freq))/sd(freq),\n         freq_z2 = scale(freq)) |&gt; \n  select(freq_z1, freq_z2) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  freq_z1 freq_z2[,1]\n    &lt;dbl&gt;       &lt;dbl&gt;\n1 -0.0902     -0.0902\n2 -0.0864     -0.0864\n3 -0.0905     -0.0905\n4 -0.0864     -0.0864\n5 -0.0885     -0.0885\n6 -0.0901     -0.0901\n\n\nLet’s use scale() for freq and length.\n\ndf_freq_full &lt;-\n  df_freq_full |&gt; \n  mutate(freq_z = scale(freq_log),\n         length_z = scale(length))\n\n\nfit_freq_z &lt;-\n  lm(rt ~ freq_z + length_z, data = df_freq_full)\n\nFirst, let’s check the \\(R^2\\):\n\nglance(fit_freq_z)$r.squared\n\n[1] 0.4872977\n\n\nWe see that our \\(R^2\\) value is 0.4872977, just like above. This serves as a reminder that the predictors still represent the same variance in the underlying model, their units and scales have simply changed. What about our coefficients:\n\ntidy(fit_freq_z) |&gt; select(term, estimate)\n\n# A tibble: 3 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    770. \n2 freq_z         -60.6\n3 length_z        43.3\n\n\nHere, a 1-unit change always corresponds to a change of 1 standard deviation. Now we see that frequency has a larger magnitude than the effect of length. So, for each instease in frequency by 1 standard deviation (holiding length constant), reaction times decrease by 29.5 ms.\n\n4.2.1 Adding an interaction term\nWe won’t spent much time talking about interactions, but please check out Ch. 8 (Interations and nonlinear effects) in Winter (2019) for a more in-depth treatment. For now, what’s important to know is that interactions describe how effects of one predictor may be influenced by changes in another predictor. We can add interactin terms of two predictors by connecting them with a colon (:).\n\nlm(rt ~ freq_z + length_z + freq_z:length_z, \n   data = df_freq_full) |&gt; \n  tidy() |&gt; select(term, estimate)\n\n# A tibble: 4 × 2\n  term            estimate\n  &lt;chr&gt;              &lt;dbl&gt;\n1 (Intercept)        766. \n2 freq_z             -63.9\n3 length_z            41.8\n4 freq_z:length_z    -11.4\n\n\nOr, we can simply connect the two predictors with an asterisk (*) to indicate that we want to look at both predictors and their interaction.\n\nlm(rt ~ freq_z*length_z, \n   data = df_freq_full) |&gt; \n  tidy() |&gt; select(term, estimate)\n\n# A tibble: 4 × 2\n  term            estimate\n  &lt;chr&gt;              &lt;dbl&gt;\n1 (Intercept)        766. \n2 freq_z             -63.9\n3 length_z            41.8\n4 freq_z:length_z    -11.4\n\n\nThe model estimates are the same for both models. The intercept is the predicted reaction time for a word with the mean length and mean frequency. Notice that the interaction slope is negative, meaning when both freq and length increase, reaction times will decrease."
  },
  {
    "objectID": "04-multiple_regression.html#model-assumptions",
    "href": "04-multiple_regression.html#model-assumptions",
    "title": "4  Multiple Regression",
    "section": "4.3 Model assumptions",
    "text": "4.3 Model assumptions\nWe’ve already discussed the assumptions of normality and homoscedasticity (constant variance), which both refer to the residuals of a model. We typically assess these assumptions visually, with histogram and Q-Q plots.\n\n4.3.1 Normality and Homoscedasticity\nFor our model\n\nfig_hist &lt;-\nfit_freq_z |&gt; \n  ggplot() +\n  aes(x = .resid) +\n  geom_histogram(bins = 20, fill = \"grey\", colour = \"black\") +\n  theme_bw() +\n  labs(title='Histogram', x='Residuals', y='Count')\n\nfig_qq &lt;-\nfit_freq_z |&gt; \n  ggplot() +\n  aes(sample = .resid) +\n  geom_qq(colour = \"red\") +\n  geom_qq_line() +\n  labs(title='Q-Q Plot', x='Theoretical quantiles', y='Sample quantiles')\n\nfig_res &lt;-\n  fit_freq_z |&gt; \n  ggplot() +\n  aes(x = .fitted, y = .resid) +\n  geom_point() +\n  geom_hline(yintercept = 0, colour = \"blue\") +\n  labs(title='Residual vs. Fitted Values Plot', x='Fitted Values', y='Residuals')\n\nfig_hist + fig_qq + fig_res\n\n\n\n\nThe histogram looks approximately normally distributed, with a bit of a positive skew. The Q-Q plot suggests a less-normal distribution, with the model estimates fitting larger reaction times more poorly. The residual plot also shows that the variance of the residuals is not constant, with much larger residual variance for larger fitted values. This tells us we should probably log reaction times. Let’s try it all again, with log-transformed reaction times.\n\n\n4.3.2 Log-transformed response variable\n\nfit_freq_log_z &lt;-\n  lm(log(rt) ~ freq_z*length_z,\n     data = df_freq_full)\n\n\nglance(fit_freq_log_z)$r.squared\n\n[1] 0.5176913\n\n\n\ntidy(fit_freq_log_z) |&gt; select(term, estimate)\n\n# A tibble: 4 × 2\n  term            estimate\n  &lt;chr&gt;              &lt;dbl&gt;\n1 (Intercept)      6.63   \n2 freq_z          -0.0826 \n3 length_z         0.0524 \n4 freq_z:length_z -0.00779\n\n\nWe see now that our values are much smaller, because they’re on the log-scale.\n\nexp(6.63 + -0.0826*5 + 0.0524*2)\n\n[1] 556.5739\n\nexp(6.63 + -0.0826*4 + 0.0524*2)\n\n[1] 604.499\n\nexp(6.63 + -0.0826*1 + 0.0524*6)\n\n[1] 955.0847\n\ntidy(fit_freq_log_z)\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic  p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)      6.63     0.000636   10428.  0       \n2 freq_z          -0.0826   0.000666    -124.  0       \n3 length_z         0.0524   0.000649      80.7 0       \n4 freq_z:length_z -0.00779  0.000581     -13.4 8.51e-41\n\n\n\nfig_hist &lt;-\nfit_freq_log_z |&gt; \n  ggplot() +\n  aes(x = .resid) +\n  geom_histogram(bins = 20, fill = \"grey\", colour = \"black\") +\n  theme_bw() +\n  labs(title='Histogram', x='Residuals', y='Count')\n\nfig_qq &lt;-\nfit_freq_log_z |&gt; \n  ggplot() +\n  aes(sample = .resid) +\n  geom_qq(colour = \"red\") +\n  geom_qq_line() +\n  labs(title='Q-Q Plot', x='Theoretical quantiles', y='Sample quantiles')\n\nfig_res &lt;-\n  fit_freq_log_z |&gt; \n  ggplot() +\n  aes(x = .fitted, y = .resid) +\n  geom_point() +\n  geom_hline(yintercept = 0, colour = \"blue\") +\n  labs(title='Residual vs. Fitted Values Plot', x='Fitted Values', y='Residuals')\n\nfig_hist + fig_qq + fig_res\n\n\n\n\nLooks much better.\n\n\n4.3.3 Collinearity\nCollinearity refers to when continuous predictor variables are correlated, which can make the interpretation of their coefficients difficult, and the results spurious. Regression assumes there is an absence of collinearity, i.e., our predictor variables are not correlatded.\nTo assess collinearity, you can use the vif() function from the car package to compare variance inflation factors. VIF values close to 1 indicates there is not a high degree of collinearity between your variables.\n\ncar::vif(fit_freq_log_z)\n\n         freq_z        length_z freq_z:length_z \n       1.246509        1.184641        1.068283 \n\n\nCollinearity is a conceptual problem, and is something that you need to consider in the planning stage. Typically, we want to include predictors that we have specific predictions or research questions about. Shoving a bunch of predictors in a model to see what comes out significant is bad practice. Rather, we should have a principled approach to model building and variable selection. This is not to say that exploratory analyses should be avoided, but that this comes with caveats.\n\n\n4.3.4 Adjusted \\(R^2\\)\nAlthough we should avoid throwing any old predictor into our model, adjusted \\(R^2\\) is a more conservative version of \\(R^2\\) that takes into account the number of predictors in a model. For each additional predictor, adjusted \\(R^2\\) includes the number of predictors (\\(k\\)) in its denominator (bottom half of a division), which means that the more predictors there are, the smaller \\(R^2\\) will be, unless each additional predictor explains sufficient variance to counteract this penalisation.\n\nglance(fit_freq_log_z)$adj.r.squared\n\n[1] 0.5176475\n\n\nIf we were to look at the (adjusted) \\(R^2\\) of our simple linear regression model, where log reaction times are predicted by standardised log frequency, we see that there is a large increase in our model which includes length and its interaction. This suggests that our model is not overfit, and that length contributes to the variance explained by the model.\n\nglance(lm(log(rt) ~ freq_z, data = df_freq_full))$adj.r.squared\n\n[1] 0.4148675\n\n\nIf we likewise compare to the same model without an interaction term (log reaction times ~ frequency * length), we see that the adjusted \\(R^2\\) is not very different. If the adjusted \\(R^2\\) were much lower, this would indicate that including the interaction term leads to overfitting.\n\nglance(lm(log(rt) ~ freq_z + length_z, data = df_freq_full))$adj.r.squared\n\n[1] 0.5150461"
  },
  {
    "objectID": "04-multiple_regression.html#important-terms",
    "href": "04-multiple_regression.html#important-terms",
    "title": "4  Multiple Regression",
    "section": "Important terms",
    "text": "Important terms\n\n\n\n\n\n\n  \n    \n    \n      Term\n      Definition\n      Equation/Code\n    \n  \n  \n    Collinearity\nCorrelation between two predictors (linear model assumes non-collinearity)\ncar::vif(model)"
  },
  {
    "objectID": "04-multiple_regression.html#learning-objectives-1",
    "href": "04-multiple_regression.html#learning-objectives-1",
    "title": "4  Multiple Regression",
    "section": "Learning Objectives 🏁",
    "text": "Learning Objectives 🏁\nToday we learned…\n\nwhat multiple regression is\nhow to include multiple predictor variables\nhow to interpret slopes in multiple regression\nhow to interpret interaction effects\nabout the assumption of the absence of collinearity"
  },
  {
    "objectID": "04-multiple_regression.html#task",
    "href": "04-multiple_regression.html#task",
    "title": "4  Multiple Regression",
    "section": "4.4 Task",
    "text": "4.4 Task\nLoad in the english dataset from the languageR package (Baayen & Shafaei-Bajestan, 2019) (code below). You don’t need to load in any CSV file, because this dataset is available if you have the package loaded. From the manual:\n\nThis data set gives mean visual lexical decision latencies and word naming latencies to 2284 monomorphemic English nouns and verbs, averaged for old and young subjects, with various predictor variables.\n\n(languageR manual, p. 29)\n\n# load in 'english' dataset from languageR\ndf_freq_eng &lt;-\n  as.data.frame(english) |&gt; \n  dplyr::select(RTlexdec, RTnaming, Word, LengthInLetters, AgeSubject, WrittenFrequency) |&gt; \n  rename(rt_lexdec = RTlexdec,\n         rt_naming = RTnaming,\n         freq_written = WrittenFrequency) |&gt; \n  clean_names() |&gt; \n  relocate(word)\n\nWe’re keeping five variables:\n\nword: a factor with 2284 words\nrt_lexdec: numeric vector of log RT in visual lexical decision\nrt_naming: numeric vector of log RT in word naming\nlength_in_letters: numeric vector with length of the word in letters\nAgeSubject: a factor with as levels the age group of the subject: young versus old.\nfreq_written: numeric vector with log frequency in the CELEX lexical database\n\nTake the following steps:\n\nPerform an exploratory data analysis to understand the data (produce plots, tables, whatever you think necessary and can do).\nModel the data, with back-transformed (raw) reaction times as a response variable and written frequency and length in letters as predictors. Perform any tranformations you think necessary. Run model diagnostic checks and assess model fit.\n\n\nRe-run the model with log reaction times as a response variable and written frequency and length in letters as predictors. Perform any tranformations you think necessary. Run model diagnostic checks and assess model fit.\n\n\nRemove length in letters as a predictor. How is model fit affected? What can you conclude?"
  },
  {
    "objectID": "04-multiple_regression.html#session-info",
    "href": "04-multiple_regression.html#session-info",
    "title": "4  Multiple Regression",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] googlesheets4_1.1.0 gt_0.9.0            kableExtra_1.3.4   \n [4] knitr_1.44          patchwork_1.1.3     languageR_1.5.0    \n [7] janitor_2.2.0       broom_1.0.5         here_1.0.1         \n[10] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0      \n[13] dplyr_1.1.3         purrr_1.0.2         readr_2.1.4        \n[16] tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3      \n[19] tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      xfun_0.39         htmlwidgets_1.6.2 gargle_1.4.0     \n [5] tzdb_0.4.0        vctrs_0.6.3       tools_4.3.0       generics_0.1.3   \n [9] curl_5.0.1        parallel_4.3.0    fansi_1.0.4       pacman_0.5.1     \n[13] pkgconfig_2.0.3   webshot_0.5.4     lifecycle_1.0.3   farver_2.1.1     \n[17] compiler_4.3.0    munsell_0.5.0     carData_3.0-5     snakecase_0.11.0 \n[21] sass_0.4.6        htmltools_0.5.5   yaml_2.3.7        car_3.1-2        \n[25] crayon_1.5.2      pillar_1.9.0      abind_1.4-5       tidyselect_1.2.0 \n[29] rvest_1.0.3       digest_0.6.33     stringi_1.7.12    labeling_0.4.3   \n[33] rprojroot_2.0.3   fastmap_1.1.1     grid_4.3.0        colorspace_2.1-0 \n[37] cli_3.6.1         magrittr_2.0.3    utf8_1.2.3        withr_2.5.0      \n[41] scales_1.2.1      backports_1.4.1   bit64_4.0.5       googledrive_2.1.0\n[45] timechange_0.2.0  rmarkdown_2.22    httr_1.4.6        bit_4.0.5        \n[49] cellranger_1.1.0  hms_1.1.3         evaluate_0.21     viridisLite_0.4.2\n[53] rlang_1.1.1       glue_1.6.2        xml2_1.3.4        svglite_2.1.1    \n[57] rstudioapi_0.14   vroom_1.6.3       jsonlite_1.8.7    R6_2.5.1         \n[61] systemfonts_1.0.4 fs_1.6.2"
  },
  {
    "objectID": "04-multiple_regression.html#references",
    "href": "04-multiple_regression.html#references",
    "title": "4  Multiple Regression",
    "section": "References",
    "text": "References\n\n\nBaayen, R. H., & Shafaei-Bajestan, E. (2019). languageR: Analyzing linguistic data: A practical introduction to statistics. https://CRAN.R-project.org/package=languageR\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "05-categorical_predictors.html#learning-objectives",
    "href": "05-categorical_predictors.html#learning-objectives",
    "title": "5  Categorical predictors",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we will learn…\n\nabout cateogorical predictors\nhow to interpret different contrast coding"
  },
  {
    "objectID": "05-categorical_predictors.html#set-up-environment",
    "href": "05-categorical_predictors.html#set-up-environment",
    "title": "5  Categorical predictors",
    "section": "Set-up environment",
    "text": "Set-up environment\n\n# suppress scientific notation\noptions(scipen=999)\n\nWe’ll also need to load in our required packages.\n\n# load libraries\npacman::p_load(\n               tidyverse,\n               here,\n               broom,\n               lme4,\n               janitor,\n               languageR)\n\n\nLoad data\nLet’s continue working with the english dataset from the languageR package. Let’s just call it df_freq_eng.\n\ndf_freq_eng &lt;-\n  as.data.frame(english) |&gt; \n  dplyr::select(RTlexdec, RTnaming, Word, LengthInLetters, AgeSubject, WrittenFrequency) |&gt; \n  rename(rt_lexdec = RTlexdec,\n         rt_naming = RTnaming,\n         freq_written = WrittenFrequency) |&gt; \n  clean_names() |&gt; \n  # standardize continuous predictors\n  mutate(\n    freq_z = scale(freq_written),\n    length_z = scale(length_in_letters)\n  ) |&gt; \n  relocate(word) |&gt; \n  arrange(word)\n\nIn your exploratory data analysis, you might’ve noticed a bimodal distribution.\n\n\n\n\n\nThis looks like a bimodal distribution, i.e., there are two modes (most frequent value, i.e., peak in a histogram). What might be driving this? We know that there were two subject groups: old and young. How does the distribution of these two groups look?\nRunning our model of the log reaction times as predicted by frequency and length, we see:\n\nfit_freq_length &lt;-\n  lm(rt_lexdec ~ freq_z*length_z,\n     data = df_freq_eng)\n\n\nglance(fit_freq_length)$r.squared\n\n[1] 0.1896649\n\nglance(fit_freq_length)$adj.r.squared\n\n[1] 0.1891323\n\n\nSeems like we don’t have any overfitting in our model (\\(R^2\\) and adjusted \\(R^2\\) are comparable). Let’s look at our coeffiecients.\n\ntidy(fit_freq_length) |&gt; select(term, estimate)\n\n# A tibble: 4 × 2\n  term            estimate\n  &lt;chr&gt;              &lt;dbl&gt;\n1 (Intercept)      6.55   \n2 freq_z          -0.0682 \n3 length_z         0.00328\n4 freq_z:length_z -0.00196\n\n\nThere is a negative slope for frequency, indicating shorter reaction times for words with higher frequency (when holding length constant). There is a positive slope for length, indicating longer reaction times for longer words (holding frequency constant). There is also a negative interaction estimate, indicating that when both length and frequency increase, reaction times decrease. This seems similar to the dataset we explored in the previous sections. But, this bimodal distribution is suggesting we should include age group as a predictor, since the two groups seem to pattern differently in their reading times. Could it be that the effect of frequency and length also differ as a function of age group?"
  },
  {
    "objectID": "05-categorical_predictors.html#categorical-predictors",
    "href": "05-categorical_predictors.html#categorical-predictors",
    "title": "5  Categorical predictors",
    "section": "5.1 Categorical predictors",
    "text": "5.1 Categorical predictors\nIn linguistic research we often want to compare the effect of groups or categories, such as native or non-native speakers, or grammatical or ungrammatical stimuli. We might expect longer reading times for non-native (compared to native) speakers of a language, or for ungrammatical (versus grammatical) sentences. With our current dataset, we’d predict longer reading times for older participants than younger participants (although we should hypothesise before collecting and visualising our data!). How might these age effects interact with effects of word frequency and length?\n\n5.1.1 Including a categorical predictor\nWhat would happen if we just include age_subject in our model?\n\nfit_age &lt;-\n  lm(rt_lexdec ~ freq_z*length_z + age_subject,\n     data = df_freq_eng)\n\nFirst, we see that adding age to our model results in a large increase in variance explained, and that the \\(R^2\\) and adjusted \\(R^2\\) values are comparable. In addition, the VIF values for all coefficients are near 1. This indicates that our predictors all contribute to the variance explained by the model and are not correlated.\n\nglance(fit_age)$r.squared\n\n[1] 0.6888949\n\nglance(fit_age)$adj.r.squared\n\n[1] 0.6886222\n\n\n\ncar::vif(fit_age)\n\n         freq_z        length_z     age_subject freq_z:length_z \n       1.012553        1.004461        1.000000        1.008108 \n\n\nNow that we see that our model is not overfit and that our predictors are not correlatd, let’s take a look at our model estimates.\n\ntidy(fit_age) |&gt; select(term,estimate)\n\n# A tibble: 5 × 2\n  term             estimate\n  &lt;chr&gt;               &lt;dbl&gt;\n1 (Intercept)       6.66   \n2 freq_z           -0.0682 \n3 length_z          0.00328\n4 age_subjectyoung -0.222  \n5 freq_z:length_z  -0.00196\n\n\nIn addition to the effects we observed in our earlier model, we see that there is a negative slope for age_subjectyoung, indicating that reaction times decrease when…what? How do we interpret a slope for a categorical variable? Regression works with numerical values, so how does a categorical variable get fit to a line? If we feed a categorical variable into the lm() function, the factor levels (i.e., the categories in a categorical variable) are given numerical values. We need to know what these values are in order to know how to interpret our model estimates. We call these numerical values mapped onto factor levels contrast coding, and we can check the contrasts of a given factor using the function contrasts().\n\ncontrasts(df_freq_eng$age_subject)\n\n      young\nold       0\nyoung     1\n\n\nWe see that old was coded at \\(0\\) and young as \\(1\\). This means that our slope for age_subjectyoung represents the change in reaction times when we move from old to young, which corresponds to a 1-unit change in our predictor (because the difference between 0 and 1 is 1). This is called treatment coding, or dummy coding, where one factor level is coded as 0 and the other as 1. Let’s remove the continuous variable for now and focus on age_subject. Let’s also look at raw reaction times, to more easily interpret the results.\n\nfit_age &lt;-\n  lm(exp(rt_lexdec) ~ age_subject,\n     data = df_freq_eng)\n\n\nglance(fit_age)$r.squared\n\n[1] 0.4682224\n\n\nOur \\(R^2\\) value is lower than when we included frequency and length, but higher still than our model with frequeny and length but no age.\n\ntidy(fit_age) |&gt; select(term, estimate)\n\n# A tibble: 2 × 2\n  term             estimate\n  &lt;chr&gt;               &lt;dbl&gt;\n1 (Intercept)          787.\n2 age_subjectyoung    -157.\n\n\nWe see that there is an estimated decrease in reaction times of 157ms for the young group compared to the old group. But what does the intercept represent here? Let’s look at our data again.\n\ndf_freq_eng |&gt; \n  select(rt_lexdec, age_subject) |&gt; \n  mutate(rt_lexdec = exp(rt_lexdec)) |&gt; \n  summary()\n\n   rt_lexdec      age_subject \n Min.   : 495.4   old  :2284  \n 1st Qu.: 617.4   young:2284  \n Median : 699.6               \n Mean   : 708.1               \n 3rd Qu.: 775.3               \n Max.   :1323.2               \n\n\nAnd how does rt_lexdec differ between the groups?\n\ndf_freq_eng |&gt; \n  select(rt_lexdec, age_subject) |&gt; \n  mutate(rt_lexdec = exp(rt_lexdec)) |&gt; \n  summarise(mean = mean(rt_lexdec),\n            min = min(rt_lexdec),\n            max = max(rt_lexdec),\n    .by = \"age_subject\"\n  )\n\n  age_subject     mean    min    max\n1       young 629.5473 495.38  971.8\n2         old 786.7200 603.77 1323.2\n\n\nWe see here that the intercept for our model actually corresponds to the mean reaction time for the old group. Why is this? Recall that the intercept corresponds to the \\(y\\) value (reaction time) when \\(x\\) is \\(0\\). In treatment/dummy coding, one factor level is coded as \\(0\\). In our case this was old, and so the intercept corresponds to the mean reaction time for participants in the old group. How does R choose which variable to code as \\(0\\)? It simply takes the first level name alphabetically: old comes before young, so old was automatically taken as the ‘baseline’ to which young was compared.\nAnd if we were to add the slope to the intercept, we would get the mean for the \\(young\\) group. Why is this?\n\ncoef(fit_age)['(Intercept)'] + coef(fit_age)['age_subjectyoung']\n\n(Intercept) \n   629.5473 \n\n\nWhy are the means for the two groups used? The mean is the value closest to all values in a univariate dataset, and regression aims to inimise residuals (recall the line of best fit). So, a line is fit between the means of these two factor levels to achieve minimal residuals. This actually is the same thing as a t-test:\n\nt.test(exp(rt_lexdec) ~ age_subject, data = df_freq_eng)\n\n\n    Welch Two Sample t-test\n\ndata:  exp(rt_lexdec) by age_subject\nt = 63.406, df = 4144.6, p-value &lt; 0.00000000000000022\nalternative hypothesis: true difference in means between group old and group young is not equal to 0\n95 percent confidence interval:\n 152.3128 162.0325\nsample estimates:\n  mean in group old mean in group young \n           786.7200            629.5473 \n\n\nIf we compare this to our model, we see that the t- and p-values are identical (more on these later).\n\ntidy(fit_age)\n\n# A tibble: 2 × 5\n  term             estimate std.error statistic p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)          787.      1.75     449.        0\n2 age_subjectyoung    -157.      2.48     -63.4       0\n\n\n\nfig_nocontrasts &lt;-\ndf_freq_eng |&gt; \n  ggplot() +\n  aes(x = age_subject, y = exp(rt_lexdec)) +\n  labs(title = \"No contrasts\") +\n  # geom_vline(xintercept = 0, linetype=\"dashed\", size = .5) +  \n  geom_point(position = position_dodge(.6)) + \n  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +\n  theme_bw()\n\nfig_treatment &lt;-\ndf_freq_eng |&gt; \n  mutate(age_subject = if_else(age_subject==\"young\",1,0)) |&gt;\n  ggplot() +\n  aes(x = age_subject, y = exp(rt_lexdec)) +\n  labs(title = \"Treatment contrasts\") +\n  geom_vline(xintercept = 0, linetype=\"dashed\", size = .5) +\n  geom_point(position = position_dodge(.6)) + \n  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +\n  theme_bw()\n\nfig_nocontrasts + fig_treatment"
  },
  {
    "objectID": "05-categorical_predictors.html#sum-contrasts",
    "href": "05-categorical_predictors.html#sum-contrasts",
    "title": "5  Categorical predictors",
    "section": "5.2 Sum contrasts",
    "text": "5.2 Sum contrasts\nTreatment/dummy coding is the default contrast coding scheme. Sum coding is another frequently used coding scheme, which is essentially centring categorical variables. Just as with continuous variables, the motivation for sum contrast coding mainly lies in the interpretation of interaction effects. How can we tell R we want to use sum contrast coding, and not dummy coding? There are different ways to do this:\n\n# first, make sure your variable is a factor\ndf_freq_eng$age_subject &lt;- as.factor(df_freq_eng$age_subject)\n# check\nclass(df_freq_eng$age_subject)\n\n[1] \"factor\"\n\n\n\n# next, you could use the contr.sum() function\ncontrasts(df_freq_eng$age_subject) &lt;- contr.sum(2) # where 2 means we have 2 levels\ncontrasts(df_freq_eng$age_subject)\n\n      [,1]\nold      1\nyoung   -1\n\n\nHere we see that old is coded as \\(-1\\) and young as \\(+1\\). I prefer to use +/-0.5 for reasons we don’t need to go into here. I would also prefer to have young coded in the negative value, and old in the positive value. This aids in the way I interpret the slope: a change in reaction times for the older group compared to the younger group.\n\n#or, you could manually control the sum contrasts\n## check the order of the levels\nlevels(df_freq_eng$age_subject)\n\n[1] \"old\"   \"young\"\n\n## code 'old' as +.5 and 'young' as -.5\ncontrasts(df_freq_eng$age_subject) &lt;- c(+0.5, -0.5)\ncontrasts(df_freq_eng$age_subject)\n\n      [,1]\nold    0.5\nyoung -0.5\n\n\nYou could also choose to store the contrast values in their own variable.\n\ndf_freq_eng &lt;- \n  df_freq_eng |&gt; \n  mutate(age_numeric = ifelse(age_subject == \"young\", -0.5, +0.5))\n\n\ndf_freq_eng |&gt; \n  select(age_subject, age_numeric) |&gt; \n  head()\n\n     age_subject age_numeric\n338        young        -0.5\n1790         old         0.5\n3125       young        -0.5\n3957         old         0.5\n3313       young        -0.5\n4145         old         0.5\n\n\nNow, we can run our model using either age_subject or age_numeric.\n\nfit_age_sum &lt;-\n  lm(exp(rt_lexdec) ~ age_subject,\n     data = df_freq_eng)\n\n\nglance(fit_age_sum)$r.squared\n\n[1] 0.4682224\n\nglance(fit_age)$r.squared\n\n[1] 0.4682224\n\n\nNo difference in variance account for by our model.\n\ntidy(fit_age_sum) |&gt; select(term,estimate)\n\n# A tibble: 2 × 2\n  term         estimate\n  &lt;chr&gt;           &lt;dbl&gt;\n1 (Intercept)      708.\n2 age_subject1     157.\n\n\nBut there is a difference in the intercept, and a change in sign in our slope. Why is this?\n\nfig_sum1 &lt;-\ndf_freq_eng |&gt; \n  mutate(age_subject = if_else(age_subject==\"young\",-1,1)) |&gt;\n  ggplot() +\n  aes(x = age_subject, y = exp(rt_lexdec)) +\n  labs(title = \"Sum contrasts\") +\n  geom_vline(xintercept = 0, linetype=\"dashed\", size = .5) +\n  geom_point(position = position_dodge(.6)) + \n  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +\n  theme_bw()\n\nfig_sum5 &lt;-\ndf_freq_eng |&gt; \n  mutate(age_subject = if_else(age_subject==\"young\",-.5,.5)) |&gt;\n  ggplot() +\n  aes(x = age_subject, y = exp(rt_lexdec)) +\n  labs(title = \"Sum contrasts\") +\n  geom_vline(xintercept = 0, linetype=\"dashed\", size = .5) +\n  geom_point(position = position_dodge(.6)) + \n  geom_smooth(method = 'lm', aes(group=1)) + theme_minimal() +\n  theme_bw()\n\nfig_treatment + fig_sum5 + plot_annotation(tag_levels = \"A\")\n\n\n\n\nFigure 5.1: The difference in slope corresponds to which level is coded as 0 (dummy coding) or -5/-1 (sum coding)\n\n\n\n\nAs we see in Figure 5.1, the sign of the slope depends on how we’ve contrast coded our factor levels. In Figure 5.1 A, the old group is coded as \\(0\\) and young as \\(1\\). In Figure 5.1 B, the young group is coded as \\(-.5\\) and the old group as \\(+.5\\).\nThe intercept value is also now the overall mean of all observed reaction times, because now the \\(y\\) value when \\(x\\) equals zero lies in the middle of the two groups. The slope magnitude (i.e., size of the value) hasn’t changed, because the difference betwen the two group means has not changed.\n\nmean(exp(df_freq_eng$rt_lexdec))\n\n[1] 708.1336\n\n\n\n5.2.1 Exploring predicted values\nLet’s also explore the predicted values of our model with a categorical variable.\n\nhead(fitted(fit_age), n = 10)\n\n     338     1790     3125     3957     3313     4145      337     1789 \n629.5473 786.7200 629.5473 786.7200 629.5473 786.7200 629.5473 786.7200 \n    3513     4345 \n629.5473 786.7200 \n\n\nWe see that there are only 2 values, 630 and 787. These correspond to the means for each group that we saw above. They also seem to be in a pattern: young-mean, old-mean, young-mean, old-mean, etc. How does this correspond to the age group of the participant for the first ten observations?\n\nhead(df_freq_eng$age_subject, n = 10)\n\n [1] young old   young old   young old   young old   young old  \nattr(,\"contrasts\")\n      [,1]\nold    0.5\nyoung -0.5\nLevels: old young\n\n\nThe first ten observations in our data are in young-old pairs. What are the first values in the raw data?\n\nhead(exp(df_freq_eng$rt_lexdec), n = 10)\n\n [1] 623.61 775.67 617.10 715.52 575.70 742.19 592.42 748.37 541.67 824.76\n\n\nAnd what is the difference between these reaction times and the fitted values?\n\nhead(exp(df_freq_eng$rt_lexdec), n = 10) - head(fitted(fit_age), n = 10)\n\n       338       1790       3125       3957       3313       4145        337 \n -5.937299 -11.049991 -12.447299 -71.199991 -53.847299 -44.529991 -37.127299 \n      1789       3513       4345 \n-38.349991 -87.877299  38.040009 \n\n\n\nhead(residuals(fit_age))\n\n       338       1790       3125       3957       3313       4145 \n -5.937299 -11.049991 -12.447299 -71.199991 -53.847299 -44.529991"
  },
  {
    "objectID": "05-categorical_predictors.html#summary",
    "href": "05-categorical_predictors.html#summary",
    "title": "5  Categorical predictors",
    "section": "5.3 Summary",
    "text": "5.3 Summary\n\nwe saw that the equation for a straight line boils down to its intercept and slope\nwe fit our first linear model with a categorical predictor\n\n\nImportant terms\n\n\n\n\n\nterm\ndescription/other terms"
  },
  {
    "objectID": "05-categorical_predictors.html#learning-objectives-1",
    "href": "05-categorical_predictors.html#learning-objectives-1",
    "title": "5  Categorical predictors",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we learned…"
  },
  {
    "objectID": "05-categorical_predictors.html#task",
    "href": "05-categorical_predictors.html#task",
    "title": "5  Categorical predictors",
    "section": "5.4 Task",
    "text": "5.4 Task\nWe’ll use a dataset from Biondo et al. (2022), an eye-tracking reading study exploring the processing of adverb-tense concord in Spanish past and future tenses. Participants read sentences that began with a temporal adverb (e.g., yesterday/tomorrow), and had a verb marked with the congruent or incongruent tense (past/future).\nLoad in the data.\n\ndf_tense &lt;-\n  read_csv(here(\"data\", \"Biondo.Soilemezidi.Mancini_dataset_ET.csv\"),\n           locale = locale(encoding = \"Latin1\") # for special characters in Spanish\n           ) |&gt; \n  mutate(gramm = ifelse(gramm == \"0\", \"ungramm\", \"gramm\")) |&gt; \n  clean_names()\n\n\n5.4.1 Treatment contrasts\nWe will look at the measure total reading time (tt) at the verb region (roi == 4). Subset the data to only include the verb region.\n\ndf_verb &lt;-\n  df_tense |&gt; \n  filter(roi == 4)\n\n\nRun a simple linear model with (log-transformed) total reading time (tt) as an independent variable and grammaticality (gramm) as a dependent variable. Use treatment contrasts.\nInspect your coefficients again. What conclusions do you draw?\nRun model diagnostics:\n\ncheck model assumptions where relevant (normality, constant variance, collinearity)\ncheck model fit (\\(R^2\\))\n\n\n\n\n5.4.2 Sum contrasts\n\nRe-run your model with sum contrasts.\nInspect your coefficients again. Do your conclusions change?\nRe-run your model diagnostics. How does it compare to your first model?\n\n\n\n5.4.3 Multiple regression\n\nAdd verb tense (verb_t: past, future) as a predictor, including an interaction term. Use sum contrasts.\nInspect your coefficients again. Do your conclusions change?\nRe-run your model diagnostics. How does it compare to the last models?"
  },
  {
    "objectID": "05-categorical_predictors.html#session-info",
    "href": "05-categorical_predictors.html#session-info",
    "title": "5  Categorical predictors",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.3.4 knitr_1.44       patchwork_1.1.3  languageR_1.5.0 \n [5] janitor_2.2.0    lme4_1.1-33      Matrix_1.5-4     broom_1.0.5     \n [9] here_1.0.1       lubridate_1.9.2  forcats_1.0.0    stringr_1.5.0   \n[13] dplyr_1.1.3      purrr_1.0.2      readr_2.1.4      tidyr_1.3.0     \n[17] tibble_3.2.1     ggplot2_3.4.3    tidyverse_2.0.0 \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      xfun_0.39         htmlwidgets_1.6.2 lattice_0.21-8   \n [5] tzdb_0.4.0        vctrs_0.6.3       tools_4.3.0       generics_0.1.3   \n [9] parallel_4.3.0    fansi_1.0.4       highr_0.10        pacman_0.5.1     \n[13] pkgconfig_2.0.3   webshot_0.5.4     lifecycle_1.0.3   farver_2.1.1     \n[17] compiler_4.3.0    munsell_0.5.0     carData_3.0-5     snakecase_0.11.0 \n[21] htmltools_0.5.5   yaml_2.3.7        crayon_1.5.2      car_3.1-2        \n[25] pillar_1.9.0      nloptr_2.0.3      MASS_7.3-58.4     abind_1.4-5      \n[29] boot_1.3-28.1     nlme_3.1-162      tidyselect_1.2.0  rvest_1.0.3      \n[33] digest_0.6.33     stringi_1.7.12    labeling_0.4.3    splines_4.3.0    \n[37] rprojroot_2.0.3   fastmap_1.1.1     grid_4.3.0        colorspace_2.1-0 \n[41] cli_3.6.1         magrittr_2.0.3    utf8_1.2.3        withr_2.5.0      \n[45] scales_1.2.1      backports_1.4.1   bit64_4.0.5       timechange_0.2.0 \n[49] rmarkdown_2.22    httr_1.4.6        bit_4.0.5         hms_1.1.3        \n[53] evaluate_0.21     viridisLite_0.4.2 mgcv_1.8-42       rlang_1.1.1      \n[57] Rcpp_1.0.11       glue_1.6.2        xml2_1.3.4        vroom_1.6.3      \n[61] svglite_2.1.1     rstudioapi_0.14   minqa_1.2.5       jsonlite_1.8.7   \n[65] R6_2.5.1          systemfonts_1.0.4"
  },
  {
    "objectID": "05-categorical_predictors.html#references",
    "href": "05-categorical_predictors.html#references",
    "title": "5  Categorical predictors",
    "section": "References",
    "text": "References\n\n\nBiondo, N., Soilemezidi, M., & Mancini, S. (2022). Yesterday is history, tomorrow is a mystery: An eye-tracking investigation of the processing of past and future time reference during sentence reading. Journal of Experimental Psychology: Learning, Memory, and Cognition, 48(7), 1001–1018. https://doi.org/10.1037/xlm0001053"
  },
  {
    "objectID": "06-logistic_regression.html#learning-objectives",
    "href": "06-logistic_regression.html#learning-objectives",
    "title": "6  Logistic regression",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we will learn…\n\nhow to model binomial data with logistic regression\nhow to interpret log-odds and odds ratio"
  },
  {
    "objectID": "06-logistic_regression.html#set-up-environment",
    "href": "06-logistic_regression.html#set-up-environment",
    "title": "6  Logistic regression",
    "section": "Set-up environment",
    "text": "Set-up environment\n\n# suppress scientific notation\noptions(scipen=999)\noptions(pillar.sigfig = 5)\n\n\nlibrary(broman)\n# function to format p-values\nformat_pval &lt;- function(x){\n  if (x &lt; .001) return(paste('&lt;', '.001'))\n  if (x &lt; .01) return(paste('&lt;', '.01'))\n  if (x &lt; .05) return(paste('&lt;', '.05'))\n  paste('=', myround(x, 3))  # if above .05, print p-value to 3 decimalp points\n}\n\nWe’ll also need to load in our required packages. Hopefully you’ve already install the required packages (if not, go to Chapter 3).\n\n# load libraries\npacman::p_load(\n               tidyverse,\n               here,\n               broom,\n               lme4,\n               janitor,\n               languageR)\n\n\n# set preferred ggplot2 theme\ntheme_set(theme_bw() + theme(plot.title = element_text(size = 10)))"
  },
  {
    "objectID": "06-logistic_regression.html#generalised-linear-models",
    "href": "06-logistic_regression.html#generalised-linear-models",
    "title": "6  Logistic regression",
    "section": "6.1 Generalised linear models",
    "text": "6.1 Generalised linear models\nLogistic regression is a type of genearlised linear model (GLM), and is used to model binomial response data. Whereas continuous response variables, such as reaction times, assume a normal distribution (a.k.a., a Gaussian distribution), logistic regression assumes a binomial distribution (a.k.a., Bernoulli distribution). These are formalised in equations \\(\\ref{eq-normal}\\), where \\(\\mu\\) and \\(\\sigma\\) correspond to the mean and standard deviation, and \\(\\ref{eq-binomial}\\), where \\(N\\) and \\(p\\) refer to the number of trials and the probability of \\(y\\) being \\(1\\) or \\(0\\).\n\\[\\begin{align}\ny &\\sim Normal(\\mu,\\sigma) \\label{eq-normal} \\\\\ny &\\sim binomial(N = 1, p) \\label{eq-binomial}\n\\end{align}\\]\nDon’t stress about this for now, I find the math behind everything will start to make more sense the more often you see it. However, some math is necessary in order to understand the output of our models, namely the relation between probabilities, odds, and log odds.\n\n6.1.1 Log-odds, odds ratio, and probabilities\nIn logistic regression, we the probability (\\(p\\)) of observing one outcome or another as a function of a predictor variable. In linguistic research, these outcomes could be the absence or presence of some phenomenon (pause, schwa, etc.) or button responses (yes/no, accept/reject). In logistic regression, we describe the probability, odds, or log-odds of a particular outcome over another.\nProbability is quite intuitive, and ranges from 0 (no chance) to 1 (certain). A 50% chance corresponds to a probability of 0.5. You’re also likely familiar with odds, which can range from 0 to infinity. Odds are often used in betting, such as the odds that I’ll win are 2:1, which corresponds to \\(\\frac{2}{1} = 2\\) in favour of my winning. Conversely, the odds that you’ll win are 1:2, corresponding to \\(\\frac{1}{2} = 0.5\\), meaning it’s less likely that you’ll win compared to you losing. If the odds are even, then: \\(\\frac{1}{1} = 1\\). So, odds of 1 correspond to a probability of 0.5. Log-odds are just the logarithmically-transformed odds: \\(log(2) =\\) 0.6931472; \\(log(0.5) =\\) -0.6931472; \\(log(1) =\\) 0. Probability can also be computed using the odds, as shown in \\(\\ref{eq-odds}\\): \\(\\frac{2}{1+2} =\\) 0.6666667; \\(\\frac{1}{1+1} =\\) 0.5; \\(\\frac{0.5}{1+0.5} =\\) 0.3333333.\nWe can get the probability from a log odds value using plogis(), which performs the following calculation:\n\\[\\begin{equation}\np = \\frac{exp(log\\;odds)}{1 + exp(log\\;odds)} = \\frac{odds}{1 + odds} \\label{eq-odds}\n\\end{equation}\\]\nTable 6.1 gives an example of how the three relate to each other. The grey cells are all where chances re 50/50, with increasingly more likely (green) or less likely (red) values/\n\n\n\n\nTable 6.1: Comparison of different values of probabilities/odds/log-odds\n\n\nname\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\nprob\n0.0066929\n0.0229774\n0.0758582\n0.2227001\n0.5\n0.7772999\n0.9241418\n0.9770226\n0.9933071\n\n\nodds\n0.0067379\n0.0235177\n0.0820850\n0.2865048\n1.0\n3.4903430\n12.1824940\n42.5210820\n148.4131591\n\n\nlog_odds\n-5.0000000\n-3.7500000\n-2.5000000\n-1.2500000\n0.0\n1.2500000\n2.5000000\n3.7500000\n5.0000000\n\n\n\n\n\n\n\n\nThis relationship is demonstrated in Figure 6.1. Take your time to really understand these plots, as it will help understand the output of our models.\n\n\n\n\n\nFigure 6.1: Relationship between probability, odds, and log-odds"
  },
  {
    "objectID": "06-logistic_regression.html#logistic-regression",
    "href": "06-logistic_regression.html#logistic-regression",
    "title": "6  Logistic regression",
    "section": "6.2 Logistic regression",
    "text": "6.2 Logistic regression\nI find the more we talk about the math behind the models before even running a model, the more overwhelmed we become. So, let’s run our first logistic regression and then dissect it to understand it. Most relevant to the output of a logistic regression model is Figure 6.1 C, as the model will output log-odds, and we most likely want to interpret them in terms of probabilities.\nWe’ll use a dataset from Biondo et al. (2022), an eye-tracking reading study exploring the processing of adverb-tense concord in Spanish past and future tenses. Participants read sentences that began with a temporal adverb (e.g., yesterday/tomorrow), and had a verb marked with the congruent or incongruent tense (past/future). We will look at the measure regression in at the verb region.\nLet’s start by loading in the data:\n\ndf_tense &lt;-\n  read_csv(here(\"data\", \"Biondo.Soilemezidi.Mancini_dataset_ET.csv\"),\n           locale = locale(encoding = \"Latin1\") # for special characters in Spanish\n           ) |&gt; \n  mutate(gramm = ifelse(gramm == \"0\", \"ungramm\", \"gramm\")) |&gt; \n  clean_names() |&gt; \n  filter(roi == 4,\n         adv_type == \"Deic\")\n\n\n6.2.1 EDA\nAnd conducting a quick EDA: print summaries and plot the response variables.\n\nhead(df_tense)\n\n# A tibble: 6 × 13\n  sj     item adv_type adv_t  verb_t gramm     roi label    fp    gp    tt    ri\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1        54 Deic     Past   Past   gramm       4 enca…  1027  1027  1027     0\n2 1         4 Deic     Future Future gramm       4 cole…   562   562  1337     1\n3 1        62 Deic     Past   Past   gramm       4 esqu…   293  1664  1141     0\n4 1        96 Deic     Future Past   ungramm     4 cons…   713  1963  1868     0\n5 1        52 Deic     Past   Past   gramm       4 desa…   890   890  1707     1\n6 1        90 Deic     Future Past   ungramm     4 dece…   962   962   962     0\n# ℹ 1 more variable: ro &lt;dbl&gt;\n\n\nLet’s look at only our binomial dependent variables, regression in (ri) and regression out (ro). For each variable, 1 indicates a regression in/out, 0 indicates there was no regression in/out.\n\ndf_tense |&gt; \n  select(roi, ri, ro) |&gt; \n  summary()\n\n      roi          ri               ro         \n Min.   :4   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:4   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :4   Median :0.0000   Median :0.00000  \n Mean   :4   Mean   :0.2248   Mean   :0.08169  \n 3rd Qu.:4   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :4   Max.   :1.0000   Max.   :1.00000  \n             NA's   :45       NA's   :45       \n\n\nLet’s plot out our dependent variable of interest: regression in.\n\n# make grammaticality a factor\ndf_tense |&gt; \n  mutate(gramm = as_factor(gramm)) \n\n# A tibble: 3,840 × 13\n   sj     item adv_type adv_t  verb_t gramm    roi label    fp    gp    tt    ri\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 1        54 Deic     Past   Past   gramm      4 enca…  1027  1027  1027     0\n 2 1         4 Deic     Future Future gramm      4 cole…   562   562  1337     1\n 3 1        62 Deic     Past   Past   gramm      4 esqu…   293  1664  1141     0\n 4 1        96 Deic     Future Past   ungra…     4 cons…   713  1963  1868     0\n 5 1        52 Deic     Past   Past   gramm      4 desa…   890   890  1707     1\n 6 1        90 Deic     Future Past   ungra…     4 dece…   962   962   962     0\n 7 1         8 Deic     Future Future gramm      4 evid…   718   718   718     0\n 8 1         9 Deic     Future Future gramm      4 excu…  1453  1453  1453     0\n 9 1        56 Deic     Past   Past   gramm      4 equi…   769   769   769     0\n10 1        11 Deic     Future Future gramm      4 cena…   778   778   778     0\n# ℹ 3,830 more rows\n# ℹ 1 more variable: ro &lt;dbl&gt;\n\n\n\n\n\n\n\nIt looks like there are more regressions in for the grammatical versus ungrammatical conditions in both the future and past tenses. There doesn’t seem to be a large difference between the two tenses in overall regressions in, nor in the effect of grammaticality on the proportion of regressions in. We can also see that it was more likely overall for there to not be a regression in (versus for there to be a regression in).\n\n\n6.2.2 Model\nNow let’s run our model. Verb tense and grammaticality are each two-level factors, so we’ll want to set sum coding for each of them. Let’s set past and grammatical to \\(-0.5\\), and future and ungrammatical to +0.5.\n\ndf_tense$verb_t &lt;- as.factor(df_tense$verb_t)\nlevels(df_tense$verb_t)\n\n[1] \"Future\" \"Past\"  \n\ncontrasts(df_tense$verb_t) &lt;- c(+0.5, -0.5)\ncontrasts(df_tense$verb_t)\n\n       [,1]\nFuture  0.5\nPast   -0.5\n\n\n\ndf_tense$gramm &lt;- as.factor(df_tense$gramm)\nlevels(df_tense$gramm)\n\n[1] \"gramm\"   \"ungramm\"\n\ncontrasts(df_tense$gramm) &lt;- c(-0.5, +0.5)\ncontrasts(df_tense$gramm)\n\n        [,1]\ngramm   -0.5\nungramm  0.5\n\n\nNow that we’ve set our contrasts (if you have continuous predictors, you would centre and potentially standardise them instead), we can fit our model. We use the glm() function to fit a genearlised linear model, and use the argument family = \"binomial\" to indicate our data are binomial.\n\nfit_tense_ri &lt;-\n  glm(ri ~ verb_t*gramm,\n    data = df_tense,\n    family = \"binomial\")\n\nWhat do our coefficients look like?\n\ntidy(fit_tense_ri) %&gt;%\n  mutate(p.value = as.numeric(p.value)) |&gt; \n  mutate(p.value = round(p.value*4,10)\n         ) |&gt; \n  knitr::kable() |&gt; \n  kableExtra::kable_styling()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-1.2472175\n0.0392027\n-31.8146220\n0.0000000\n\n\nverb_t1\n0.0209637\n0.0784053\n0.2673755\n3.1567201\n\n\ngramm1\n0.3668992\n0.0784053\n4.6795205\n0.0000115\n\n\nverb_t1:gramm1\n-0.1197221\n0.1568106\n-0.7634823\n1.7807033\n\n\n\n\n\n\n\nLet’s first consider the estimates. The intercept is negative, meaning it is below 0. Verb tense is positive, meaning that there are more regressions in for the future compared to the past, holding grammaticality constant. Grammaticality is positive, meaning that there were more regressions in for the ungrammatical than grammatical conditions. But what does zero mean here? Logistic regression gives the estimates in log-odds. This means that a value of 0 means there is an equal probability of a regression in or out for both conditions (as in (tab-odds?)), i.e., the slope is flat (or not significantly different from 0). How can we convert our log-odds estimates to something more interpretable, like probabilities? Recall the equation in \\(\\ref{eq-odds}\\), which would require a lot of typing. Luckily, we can just use the plogis() function, which takes a log-odds value and spits out the corresponding probability. We can also just use the exp() function to get the odds ratio from the log-odds.\n\nplogis(-1.23) # intercept prob\n\n[1] 0.2261814\n\nplogis(0.0277) # tense prob\n\n[1] 0.5069246\n\nexp(-1.23) # intercept odds\n\n[1] 0.2922926\n\nexp(0.0277) # tense odds\n\n[1] 1.028087\n\n\nThis is great, but a bit tedious. We can also just feed a tibble column through the plogis() and exp() functions to print a table with the relevant probabilities and odds.\n\ntidy(fit_tense_ri) %&gt;%\n  mutate(p.value = round(p.value*4,10),\n         prob = plogis(estimate),\n         odds = exp(estimate)\n         ) |&gt; \n  mutate_if(is.numeric, round, 4) |&gt; \n  knitr::kable() |&gt; \n  kableExtra::kable_styling()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nprob\nodds\n\n\n\n\n(Intercept)\n-1.2472\n0.0392\n-31.8146\n0.0000\n0.2232\n0.2873\n\n\nverb_t1\n0.0210\n0.0784\n0.2674\n3.1567\n0.5052\n1.0212\n\n\ngramm1\n0.3669\n0.0784\n4.6795\n0.0000\n0.5907\n1.4433\n\n\nverb_t1:gramm1\n-0.1197\n0.1568\n-0.7635\n1.7807\n0.4701\n0.8872\n\n\n\n\n\n\n\nWe see that the odds of the future tense have a regression in versus the past tense is ~1, with the corresponding probability of 0.51. Unsuprisingly, we see this p-value indicates this effect was not significant (p &gt; .05), and the z-value (note: not t-value!) is also low.\n\n\n\n\n\n\nz-values\n\n\n\nz-values correspond to the estimate divided by the standard error. It’s interpretation is similar to that of the t-value: a z-value of ~2 or higher will likely have a p-value below 0.05.\n\n\nThe interaction term is negative, what does this mean? We can interpret this as indicating that the effect of congruence is different in either level of tense. These effects are often more easily interpreted with a visualisation, e.g., using the plot_model() function from the sjPlot package. This effect is not significant, however.\n\nsjPlot::plot_model(fit_tense_ri, \n                   type = \"eff\", \n                   terms = c(\"gramm\", \"verb_t\")) + \n  geom_line(position = position_dodge(0.1))\n\n\n\n\nFigure 6.2: Interaction plot of\n\n\n\n\nWe can also use the predict() function to extract the predicted values for each condition. We could just simply print the predicted values (predict(fit_tense_ri)), append the predicted values to the data frame\n\n# make sure dataset is the same length as the model data\ndf_tense_v &lt;-\n  df_tense |&gt; \n  filter(roi == \"4\") |&gt; \n  drop_na(ri)\n\n# append model estimates\naugment(fit_tense_ri, data = df_tense_v) |&gt; \n  distinct(verb_t, gramm, .keep_all = T) |&gt;\n  arrange(verb_t) |&gt;  \n  select(verb_t, gramm, .fitted)\n\n# A tibble: 4 × 3\n  verb_t gramm   .fitted\n  &lt;fct&gt;  &lt;fct&gt;     &lt;dbl&gt;\n1 Future gramm   -1.3903\n2 Future ungramm -1.0832\n3 Past   gramm   -1.4711\n4 Past   ungramm -1.0443\n\n\nOr we could create a list of the unique conditions.\n\ndf_sim &lt;-\n    tibble(\n    verb_t = rep(c('Past', 'Future'), each = 2),\n    gramm = rep(c('0', '1'), times = 2))\n\n# alternatively, just extract the relevant factor levels from your datafram\ndf_sim &lt;-\n  df_tense |&gt; \n  arrange(verb_t) |&gt; \n  distinct(verb_t, gramm) \n\n# and add predicted values\ndf_sim$fit &lt;- num(predict(fit_tense_ri, df_sim), digits = 5)\n\ndf_sim\n\n# A tibble: 4 × 3\n  verb_t gramm         fit\n  &lt;fct&gt;  &lt;fct&gt;   &lt;num:.5!&gt;\n1 Future gramm    -1.39025\n2 Future ungramm  -1.08322\n3 Past   gramm    -1.47108\n4 Past   ungramm  -1.04432\n\n\nAnd now if we look at the predicted log-odds values for the future and past tenses:\n\ndf_sim |&gt; \n  summarise(\n    mean_tense = mean(fit),\n    .by = verb_t)\n\n# A tibble: 2 × 2\n  verb_t mean_tense\n  &lt;fct&gt;   &lt;num:.5!&gt;\n1 Future   -1.23674\n2 Past     -1.25770\n\n\nWhat is the difference between these two numbers (in our model summary)?\n\ndf_sim |&gt; \n  summarise(\n    mean_tense = mean(fit),\n    .by = gramm)\n\n# A tibble: 2 × 2\n  gramm   mean_tense\n  &lt;fct&gt;    &lt;num:.5!&gt;\n1 gramm     -1.43067\n2 ungramm   -1.06377\n\n\nWhat is the difference between these two numbers (in our model summary)?\nSo, our slopes for verb_t and gramm correspond to the predicted difference between the two levels of each factor."
  },
  {
    "objectID": "06-logistic_regression.html#interpreting-our-coefficients",
    "href": "06-logistic_regression.html#interpreting-our-coefficients",
    "title": "6  Logistic regression",
    "section": "6.3 Interpreting our coefficients",
    "text": "6.3 Interpreting our coefficients\nWhat do our coefficient estimates reflect, though? Let’s remind ourselves of the rate of regressions in at the verb region:\n\ndf_tense |&gt; \n  filter(roi == \"4\") |&gt; \n  drop_na(ri) |&gt; \n  summary()\n\n      sj                 item          adv_type            adv_t          \n Length:3795        Min.   :  1.00   Length:3795        Length:3795       \n Class :character   1st Qu.: 25.00   Class :character   Class :character  \n Mode  :character   Median : 52.00   Mode  :character   Mode  :character  \n                    Mean   : 50.91                                        \n                    3rd Qu.: 78.00                                        \n                    Max.   :101.00                                        \n    verb_t         gramm           roi       label                 fp        \n Future:1897   gramm  :1901   Min.   :4   Length:3795        Min.   :  81.0  \n Past  :1898   ungramm:1894   1st Qu.:4   Class :character   1st Qu.: 266.0  \n                              Median :4   Mode  :character   Median : 371.0  \n                              Mean   :4                      Mean   : 440.5  \n                              3rd Qu.:4                      3rd Qu.: 535.0  \n                              Max.   :4                      Max.   :2833.0  \n       gp             tt               ri               ro         \n Min.   :  87   Min.   :  90.0   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.: 285   1st Qu.: 326.5   1st Qu.:0.0000   1st Qu.:0.00000  \n Median : 405   Median : 493.0   Median :0.0000   Median :0.00000  \n Mean   : 510   Mean   : 607.4   Mean   :0.2248   Mean   :0.08169  \n 3rd Qu.: 606   3rd Qu.: 747.0   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :3877   Max.   :3936.0   Max.   :1.0000   Max.   :1.00000  \n\nptab_gramm &lt;-\n  df_tense |&gt; \n  filter(roi == \"4\") |&gt; \n  drop_na(ri) |&gt; \n  select(gramm, ri) |&gt; \n  table() |&gt; \n  prop.table()\n\nptab_tense &lt;-\n  df_tense |&gt; \n  filter(roi == \"4\") |&gt; \n  drop_na(ri) |&gt; \n  select(verb_t, ri) |&gt; \n  table() |&gt; \n  prop.table()\n\ndf_tense |&gt; \n  filter(roi == \"4\") |&gt; \n  drop_na(ri) |&gt; \n  tabyl(gramm, ri, verb_t) |&gt; \n  adorn_percentages() |&gt; \n  adorn_totals()\n\n$Future\n   gramm         0         1\n   gramm 0.8006329 0.1993671\n ungramm 0.7471022 0.2528978\n   Total 1.5477351 0.4522649\n\n$Past\n   gramm         0         1\n   gramm 0.8132214 0.1867786\n ungramm 0.7396825 0.2603175\n   Total 1.5529039 0.4470961\n\n\nWe want to measure how much more likely a regression in (y = 1) is for ungrammatical conditions (x = 1) than in grammatical conditions (x = 0). Si we want to calculate the odds of a regression in for each case, and take their ratio:\n\n# odds(y = 1 | x = 0)\nodds_ri1_gramm0 &lt;- \n  ptab_gramm[1,2] / ptab_gramm[1,1] # in gramm conditions: ri 0/1\nodds_ri1_gramm1 &lt;- \n  ptab_gramm[2,2] / ptab_gramm[2,1] # in ungramm condiitons: ri 0/1\n\n## odds ratio\nodds_ri1_gramm1 / odds_ri1_gramm0\n\n[1] 1.442756\n\n## log odds\nlog(odds_ri1_gramm1) - log(odds_ri1_gramm0)\n\n[1] 0.3665552\n\n# or\nlog(odds_ri1_gramm1 / odds_ri1_gramm0)\n\n[1] 0.3665552\n\n## probability\nplogis(log(odds_ri1_gramm1 / odds_ri1_gramm0))\n\n[1] 0.5906263\n\n\nSo the odds of a regression into the verb region is 1.4 times more likely in ungrammatical versus grammatical conditions.\n\nintercept &lt;- tidy(fit_tense_ri)$estimate[1]\ntense &lt;- tidy(fit_tense_ri)$estimate[2]\ngramm &lt;- tidy(fit_tense_ri)$estimate[3]\ninteract &lt;- tidy(fit_tense_ri)$estimate[4]\n\nWhat are the log odds for the past (tense = -0.5) grammatical (gramm = -0.5)?\n\nplogis(intercept)\n\n[1] 0.2231822\n\nplogis(tense)\n\n[1] 0.5052407\n\nplogis(gramm)\n\n[1] 0.5907095\n\nplogis(interact)\n\n[1] 0.4701052\n\n\n\ntidy(fit_tense_ri) |&gt; \n  mutate(prob = plogis(estimate))\n\n# A tibble: 4 × 6\n  term            estimate std.error statistic     p.value    prob\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    -1.2472    0.039203 -31.815   4.0637e-222 0.22318\n2 verb_t1         0.020964  0.078405   0.26738 7.8918e-  1 0.50524\n3 gramm1          0.36690   0.078405   4.6795  2.8755e-  6 0.59071\n4 verb_t1:gramm1 -0.11972   0.15681   -0.76348 4.4518e-  1 0.47011\n\n\n\nplogis(intercept + tense*-.5 + gramm*-.5)\n\n[1] 0.1913675\n\n\nAnd past ungrammatical (gramm = +0.5)?\n\nplogis(intercept + tense*-.5 + gramm*.5)\n\n[1] 0.2545957\n\n\nAnd for the future conditions?\n\nplogis(intercept + tense*.5 + gramm*-.5)\n\n[1] 0.1946325\n\n\nAnd past ungrammatical (gramm = +0.5)?\n\nplogis(intercept + tense*.5 + gramm*.5)\n\n[1] 0.2585946\n\n\n\nplogis(-1.22521)\n\n[1] 0.2270209\n\n\n\nplogis(-1.22521)\n\n[1] 0.2270209\n\n\n\\[\\begin{align}\np &= \\frac{odds}{1 + odds} \\label{eq1}\\\\\nodds &= \\frac{p}{1-p} \\label{eq2}\\\\\nlog\\;odds &= exp(odds) \\label{eq3}\n\\end{align}\\]"
  },
  {
    "objectID": "06-logistic_regression.html#visualising-model-predictions",
    "href": "06-logistic_regression.html#visualising-model-predictions",
    "title": "6  Logistic regression",
    "section": "6.4 Visualising model predictions",
    "text": "6.4 Visualising model predictions\nSomething we haven’t really covered is how to visualise our model predictions. So far we’ve only visualised the raw data, but when interpreting model results it helps to see the predictions. This is especially true for logistic regression, because our estimates are given in log odds, which are not very intuitive.\nWe can use the sjPlot package, which is very handy:\n\nlibrary(sjPlot)\n\nplot_model(fit_tense_ri)\n\n\n\n\n\nplot_model(fit_tense_ri, type = \"eff\",\n           terms = \"verb_t\")\n\n\n\n\n\nplot_model(fit_tense_ri, type = \"eff\",\n           terms = \"gramm\")\n\n\n\n\n\nplot_model(fit_tense_ri, type = \"int\")\n\n\n\n\nOr we can use the ggeffects package to extract summaries of effects, and then feed them into ggplot2.\n\nlibrary(ggeffects)\n\n\nggeffect(fit_tense_ri)\n\n$verb_t\n# Predicted probabilities of ri\n\nverb_t | Predicted |       95% CI\n---------------------------------\nFuture |      0.22 | [0.21, 0.24]\nPast   |      0.22 | [0.20, 0.24]\n\n$gramm\n# Predicted probabilities of ri\n\ngramm   | Predicted |       95% CI\n----------------------------------\ngramm   |      0.19 | [0.18, 0.21]\nungramm |      0.26 | [0.24, 0.28]\n\nattr(,\"class\")\n[1] \"ggalleffects\" \"list\"        \nattr(,\"model.name\")\n[1] \"fit_tense_ri\"\n\nggeffect(fit_tense_ri,\n         terms = c(\"gramm\", \"verb_t\"))\n\n# Predicted probabilities of ri\n\n# verb_t = Future\n\ngramm   | Predicted |       95% CI\n----------------------------------\ngramm   |      0.20 | [0.18, 0.23]\nungramm |      0.25 | [0.23, 0.28]\n\n# verb_t = Past\n\ngramm   | Predicted |       95% CI\n----------------------------------\ngramm   |      0.19 | [0.16, 0.21]\nungramm |      0.26 | [0.23, 0.29]"
  },
  {
    "objectID": "06-logistic_regression.html#reporting",
    "href": "06-logistic_regression.html#reporting",
    "title": "6  Logistic regression",
    "section": "6.5 Reporting",
    "text": "6.5 Reporting\nSonderegger (2023) (Section 6.9) says the following:\n\nReporting a logistic regression model in a write-up is generally similar to reporting a linear regression model…Reporting a logistic regression model in a write-up is generally similar to reporting a linear regression model: the guidelines and rationale in section 4.6 for reporting individual coefficients and the whole model hold, with some adjustments.\n\nWe can produce such a table using the papaja package, as in Table 6.2.\n\nlibrary(papaja)\n\nfit_tense_ri |&gt; \n  apa_print() |&gt;\n  apa_table(caption = \"Model summary for regressions in at the verb region. Estimates are given in log odds.\")\n\n\nTable 6.2: ?(caption)\n\n\n\n\n(a) (#tab:tbl-glm-summary) Model summary for regressions in at the verb region. Estimates are given in log odds.\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(z\\)\n\\(p\\)\n\n\n\n\nIntercept\n-1.25\n[-1.32, -1.17]\n-31.81\n&lt; .001\n\n\nVerb t1\n0.02\n[-0.13, 0.17]\n0.27\n.789\n\n\nGramm1\n0.37\n[0.21, 0.52]\n4.68\n&lt; .001\n\n\nVerb t1 \\(\\times\\) Gramm1\n-0.12\n[-0.43, 0.19]\n-0.76\n.445\n\n\n\n\n\n\n\nOr by extracting the model summary with tidy(), and even adding our probabilities, as in Table 6.3.\n\ntidy(fit_tense_ri) |&gt; \n  mutate(prob = plogis(estimate)) |&gt; \n  relocate(prob, .after = std.error) |&gt; \n  apa_table()\n\n\nTable 6.3: ?(caption)\n\n\n\n\n(a) (#tab:tbl-glm-summary2)\n\n\nterm\nestimate\nstd.error\nprob\nstatistic\np.value\n\n\n\n\n(Intercept)\n-1.25\n0.04\n0.22\n-31.81\n0.00\n\n\nverb_t1\n0.02\n0.08\n0.51\n0.27\n0.79\n\n\ngramm1\n0.37\n0.08\n0.59\n4.68\n0.00\n\n\nverb_t1:gramm1\n-0.12\n0.16\n0.47\n-0.76\n0.45"
  },
  {
    "objectID": "06-logistic_regression.html#summary",
    "href": "06-logistic_regression.html#summary",
    "title": "6  Logistic regression",
    "section": "6.6 Summary",
    "text": "6.6 Summary\n\nwe saw that the equation for a straight line boils down to its intercept and slope\nwe fit our first linear model with a categorical predictor\n\n\nImportant terms\n\n\n\n\n\nterm\ndescription/other terms"
  },
  {
    "objectID": "06-logistic_regression.html#important-terms-1",
    "href": "06-logistic_regression.html#important-terms-1",
    "title": "6  Logistic regression",
    "section": "Important terms",
    "text": "Important terms\n\n\n\n\n\n\n  \n    \n    \n      Term\n      Definition\n      Equation/Code\n    \n  \n  \n    Bernoulli distribution\nNA\nNA\n    plogis()\nNA\nNA\n    log odds\nNA\nNA"
  },
  {
    "objectID": "06-logistic_regression.html#learning-objectives-1",
    "href": "06-logistic_regression.html#learning-objectives-1",
    "title": "6  Logistic regression",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we learned…\n\nhow to model binomial data with logistic regression\nhow to interpret log-odds and odds ratio"
  },
  {
    "objectID": "06-logistic_regression.html#task",
    "href": "06-logistic_regression.html#task",
    "title": "6  Logistic regression",
    "section": "Task",
    "text": "Task\n\n6.6.1 Regressions out\nUsing the same dataset, run a logistic model exploring regressions in (ri) at the adverb region (roi = \"2\"). Before you run the model, do you have any predictions? Try plotting the regressions in for this region first, and generate some summary tables to get an idea of the distributions of regressions in across conditions.\n\n\n6.6.2 Dutch verb regularity\nLoad in the regularity data from the languageR package.\n\ndf_reg &lt;-\n  regularity |&gt; \n  clean_names()\n\n\nRegular and irregular Dutch verbs and selected lexical and distributional properties.\n\nOur relevant variables will be:\n\nwritten_frequency: a numeric vector of logarithmically transformed frequencies in written Dutch (as available in the CELEX lexical database).\nregularity: a factor with levels irregular (1) and regular (0).\nverb: a factor with the verbs as levels.\n\n\nFit a logistic regression model to the data which predicts verb regularity by written frequency. Consider: What type of predictor variable do you have, and what steps should you take before fitting your model?\nPrint the model coefficients, e.g., using tidy().\nInterpret the coefficients, either in log-odds or probabilities. Report your findings."
  },
  {
    "objectID": "06-logistic_regression.html#session-info",
    "href": "06-logistic_regression.html#session-info",
    "title": "6  Logistic regression",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] papaja_0.1.1.9001   tinylabels_0.2.3    ggeffects_1.2.2    \n [4] sjPlot_2.8.14       gt_0.9.0            googlesheets4_1.1.0\n [7] kableExtra_1.3.4    knitr_1.44          patchwork_1.1.3    \n[10] languageR_1.5.0     janitor_2.2.0       lme4_1.1-33        \n[13] Matrix_1.5-4        broom_1.0.5         here_1.0.1         \n[16] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0      \n[19] dplyr_1.1.3         purrr_1.0.2         readr_2.1.4        \n[22] tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3      \n[25] tidyverse_2.0.0     broman_0.80        \n\nloaded via a namespace (and not attached):\n [1] DBI_1.1.3          sandwich_3.0-2     rlang_1.1.1        magrittr_2.0.3    \n [5] multcomp_1.4-23    snakecase_0.11.0   compiler_4.3.0     systemfonts_1.0.4 \n [9] vctrs_0.6.3        rvest_1.0.3        pkgconfig_2.0.3    crayon_1.5.2      \n[13] fastmap_1.1.1      backports_1.4.1    labeling_0.4.3     effectsize_0.8.3  \n[17] utf8_1.2.3         rmarkdown_2.22     tzdb_0.4.0         haven_2.5.2       \n[21] nloptr_2.0.3       bit_4.0.5          xfun_0.39          jsonlite_1.8.7    \n[25] highr_0.10         sjmisc_2.8.9       parallel_4.3.0     R6_2.5.1          \n[29] RColorBrewer_1.1-3 stringi_1.7.12     boot_1.3-28.1      cellranger_1.1.0  \n[33] estimability_1.4.1 Rcpp_1.0.11        modelr_0.1.11      zoo_1.8-12        \n[37] parameters_0.21.1  pacman_0.5.1       nnet_7.3-18        splines_4.3.0     \n[41] timechange_0.2.0   tidyselect_1.2.0   effects_4.2-2      rstudioapi_0.14   \n[45] yaml_2.3.7         codetools_0.2-19   sjlabelled_1.2.0   curl_5.0.1        \n[49] lattice_0.21-8     withr_2.5.0        bayestestR_0.13.1  coda_0.19-4       \n[53] evaluate_0.21      survival_3.5-5     survey_4.2-1       xml2_1.3.4        \n[57] pillar_1.9.0       carData_3.0-5      insight_0.19.3     generics_0.1.3    \n[61] vroom_1.6.3        rprojroot_2.0.3    hms_1.1.3          munsell_0.5.0     \n[65] scales_1.2.1       minqa_1.2.5        xtable_1.8-4       glue_1.6.2        \n[69] emmeans_1.8.6      tools_4.3.0        webshot_0.5.4      fs_1.6.2          \n[73] mvtnorm_1.2-3      grid_4.3.0         mitools_2.4        datawizard_0.7.1  \n[77] colorspace_2.1-0   nlme_3.1-162       performance_0.10.4 googledrive_2.1.0 \n[81] cli_3.6.1          fansi_1.0.4        gargle_1.4.0       viridisLite_0.4.2 \n[85] svglite_2.1.1      sjstats_0.18.2     gtable_0.3.4       sass_0.4.6        \n[89] digest_0.6.33      TH.data_1.1-2      htmlwidgets_1.6.2  farver_2.1.1      \n[93] htmltools_0.5.5    lifecycle_1.0.3    httr_1.4.6         bit64_4.0.5       \n[97] MASS_7.3-58.4"
  },
  {
    "objectID": "06-logistic_regression.html#references",
    "href": "06-logistic_regression.html#references",
    "title": "6  Logistic regression",
    "section": "References",
    "text": "References\n\n\nBiondo, N., Soilemezidi, M., & Mancini, S. (2022). Yesterday is history, tomorrow is a mystery: An eye-tracking investigation of the processing of past and future time reference during sentence reading. Journal of Experimental Psychology: Learning, Memory, and Cognition, 48(7), 1001–1018. https://doi.org/10.1037/xlm0001053\n\n\nSonderegger, M. (2023). Regression Modeling for Linguistic Data.\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "reports/report1.html#dataset",
    "href": "reports/report1.html#dataset",
    "title": "7  Report 1",
    "section": "7.1 Dataset",
    "text": "7.1 Dataset\nFor this report you will continue using the data from Biondo et al. (2022), an eye-tracking reading study on adverb-tense congruence effects on reading time measures. Participants’ eye movements were recorded as they read Spanish sentences where temporal adverbs and verb tense were either congruent or incongruent. For both sentence regions, the time reference was either past (e.g., yesterda, bought) or future (e.g., tomorrow, will buy). Example stimuli from this experiment are given in Table 7.1. You will be fitting models to different eye-tracking reading measures from this experiment, with the predictors verb tense and grammaticality.\n\n\n\n\nTable 7.1: Example stimuli\n\n\n\n\n\n\n\n\nsentence\nadverb\nverb\ngramm\n\n\n\n\nA la salida del trabajo, ayer las chicas compraron pan en la tienda. After leaving work yesterday the girls bought bread at the shop\npast\npast\ngramm\n\n\nA la salida del trabajo, ayer las chicas *comprarán pan en la tienda. After leaving work yesterday the girls *will buy bread at the shop\npast\nfuture\nungramm\n\n\nA la salida del trabajo, mañana las chicas comprarán pan en la tienda. After leaving work tomorrow the girls will buy bread at the shop\nfuture\nfuture\ngramm\n\n\nA la salida del trabajo, mañana las chicas *compraron pan en la tienda. After leaving work tomorrow the girls *bought bread at the shop\nfuture\npast\nungramm"
  },
  {
    "objectID": "reports/report1.html#set-up",
    "href": "reports/report1.html#set-up",
    "title": "7  Report 1",
    "section": "7.2 Set-up",
    "text": "7.2 Set-up\nMake sure you begin with a clear working environment. To achieve this, you can go to Session &gt; Restart R. Your Environment should have no objects in it, and you should not have any packages loaded.\n\n7.2.1 Packages\nLoad the packages below. Give a short description of why we load in each package, i.e., what these packages help us do (1-2 sentences each). Tip: remember you can type ?tidyverse into the Console to get an overview of a package or function.\n\npacman::p_load(\n  tidyverse,\n  janitor,\n  here,\n  broom\n)\n\n\ntidyverse:\njanitor:\nhere:\n\n\n\n7.2.2 Data\nRun the code below. Give a short description of what each line of code does (you can skip the locale line). Tip: roi == 2 corresponds to the temporal adverb condiiton.\n\ndf_tense &lt;-\n  read_csv(here(\"data\", \"Biondo.Soilemezidi.Mancini_dataset_ET.csv\"),\n           locale = locale(encoding = \"Latin1\") ## for special characters in Spanish\n           ) |&gt; \n  clean_names() |&gt; \n  mutate(gramm = ifelse(gramm == \"0\", \"ungramm\", \"gramm\"))  |&gt; \n  filter(roi == 2,\n         adv_type == \"Deic\") |&gt; \n  mutate(length = nchar(label))\n\nYou can write your answer like this, for example:\n\ndf_tense &lt;- :\nread_csv:\nclean_names:\nmutate:\nfilter:"
  },
  {
    "objectID": "reports/report1.html#how-to-report-your-models",
    "href": "reports/report1.html#how-to-report-your-models",
    "title": "7  Report 1",
    "section": "7.3 How to report your models",
    "text": "7.3 How to report your models\nYou will be running linear and logisitc regression models. Our variables of interest will be:\n\n\n\n\n\n\n\n\n\n\n\nvariable\ndescription\ntype\nclass\n\n\n\n\nfp\nfirst-pass reading time (summation of fixations from when a reader first fixates on a region to when they first leave that region)\ndependent\ncontinuous\n\n\ntt\ntotal reading time (summation of all fixations within a region during a trial)\ndependent\ncontinuous\n\n\nri\nregressions in (whether there was at least one regression into a region)\ndependent\nbinomial\n\n\nro\nregressions out (whether there was at least one regression out of a region)\ndependent\nbinomial\n\n\nverb_t\nverb tense: past or future\nindependent\ncategorical\n\n\ngramm\ngrammaticality: grammatical or ungrammatical\nindependent\ncategorical\n\n\nlength\nregion length in letters\nindependent\ncontinuous\n\n\n\n\n\n\n7.3.1 Example model report\nImagine we fit a linear model, called fit_verb_tt, to log-tranformed total reading times at the verb region. Our fixed effects (i.e., predictors) are verb tense, grammaticality, and their interaction. Below I report the findings of the model, which is what you should aim to do with the models you run.\n\nThe model summary is given in ?tbl-fit_verb_tt, with back-transformed model predictions visualised in Figure 7.1. A main effect of grammaticality was found in total reading times at the verb region, with ungrammatical conditions eliciting longer total reading times than grammatical conditions (Est = -0.06, t = -2.4, p &lt; 0.05). A main effect of tense was also found, with the future condition eliciting longer total reading times than the past condition (Est = 0.07, t = 2.48, p &lt; .05). An interaction of tense and grammaticality was not significant (Est = 0.04, t = 1).\n\n\nlibrary(papaja)\n\nfit_verb_tt |&gt; \n  apa_print() |&gt;\n  apa_table(label = \"tbl-fit_verb_tt\",\n            caption = \"Model summary for (log-transformed) total reading times at the verb region.\")\n\n\n(#tab:unnamed-chunk-12) Model summary for (log-transformed) total reading times at the verb region.\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n6.22\n[6.19, 6.26]\n332.72\n3791\n&lt; .001\n\n\nVerb tPast\n-0.06\n[-0.11, -0.01]\n-2.38\n3791\n.017\n\n\nGrammungramm\n0.07\n[0.01, 0.12]\n2.47\n3791\n.013\n\n\nVerb tPast \\(\\times\\) Grammungramm\n0.04\n[-0.04, 0.11]\n1.01\n3791\n.312\n\n\n\n\n\n\nlibrary(sjPlot)\nplot_model(fit_verb_tt, type = \"int\") + \n  geom_line(position = position_dodge(0.1)) +\n  labs(title = \"Predicted total reading times at the verb region\",\n       x = \"Verb tense\",\n       y = \"Reading time (ms)\") +\n  theme_bw()\n\n\n\n\nFigure 7.1: Back-transformed model predictions for total reading time at the verb region (with 95% confidence intervals)."
  },
  {
    "objectID": "reports/report1.html#variable-prep",
    "href": "reports/report1.html#variable-prep",
    "title": "7  Report 1",
    "section": "7.4 Variable prep",
    "text": "7.4 Variable prep\nWe need to prepare our predictors: centering continuous variables and sum contrast coding categorical variables.\n\n7.4.1 Centring continuous variables\nCreate a new variable length_c which contains the centred values of length (just centre, you don’t need to standardise). Centre using the median rather than the mean (hint: there is a function median()).\n\n\n7.4.2 Contrast coding\nSet sum contrast coding for tense and gramm. You might need to first use the as.factor() function to save the variables as factors. Your contrasts should look like this:\n\ncontrasts(df_tense$gramm)\n\n        [,1]\ngramm   -0.5\nungramm  0.5\n\ncontrasts(df_tense$verb_t)\n\n       [,1]\nFuture  0.5\nPast   -0.5"
  },
  {
    "objectID": "reports/report1.html#linear-regression",
    "href": "reports/report1.html#linear-regression",
    "title": "7  Report 1",
    "section": "7.5 Linear regression",
    "text": "7.5 Linear regression\nWe run linear regression when we have a continuous dependent variable. You will be fitting a. model to first-pass reading time.\n\n7.5.1 Fitting our model\nFit a model of log-transformed first-pass reading times with verb tense, grammaticality, and their interaction as fixed effects (hint: you might want to use * in your model).\n\n\n7.5.2 Assessing assumptions\nVisually assess the model assumptions of normality and homoscedasticity and write 1-2 sentences about each assumption, referring to the figures you produced.\n\n\n7.5.3 Extracting predictions\n\nCreate objects intercept, b1 (verb_t), and b2 (gramm) that contain the corresponding model coefficient estimate for each term (hint: each object should contain a single value, which corresponds to the estimate for this term in your model summary output).\nGenerate the fitted values for each of our four conditions. We covered a number of ways to do this in class:\n\nUsing our model formula (\\(\\ref{eq-fp}\\)) and the sum contrast values for each level of verb_t and gramm (i.e., +/-0.5, given in Table 7.2), compute the back-transformed predicted total reading time for each condition. Recall: \\(b_0\\) is our intercept, \\(b_1\\) is our slope for verb_t (i.e., the value of the object you just named verb_t), and \\(b_2\\) is our slope (estimate) for gramm (i.e., the value of the object you just named gramm).\nThe ggeffects package: we used the ggeffect() function, but the ggpredict() function back-transforms the estimates for us.\n\n\n\\[\\begin{equation}\nfp = exp(b_0 + b_1*verb\\_t + b_2*gramm) \\label{eq-fp}\n\\end{equation}\\]\n\n\n\n\nTable 7.2: Corresponding value of factor levels to be plugged into equation ef{eq-fp}\n\n\n\n-0.5\n+0.5\n\n\n\n\nverb_t\npast\nfuture\n\n\ngramm\ngramm\nungramm\n\n\n\n\n\n\n\n\n7.5.4 Report model\nWrite a short report of the model findings. Produce a table and plot like in the example above to supplement your report."
  },
  {
    "objectID": "reports/report1.html#logistic-regression",
    "href": "reports/report1.html#logistic-regression",
    "title": "7  Report 1",
    "section": "7.6 Logistic regression",
    "text": "7.6 Logistic regression\nWe run logistic regression when we have a binimial dependent variable. You will be fitting a logistic regression model to regression in.\n\n7.6.1 Fit model\nFit a generalied linear model (logistic regression) to the regression in data, with the same fixed effects as your linear model above (verb_t, gramm, and their interaction). Remember, you will need a different function (not lm), and to add another argument (family = ...).\n\n\n7.6.2 Interpretation\nWrite a short report of the model findings. Produce a table and plot like in the example above to supplement yor report. Recall that our coefficient estimates are in log odds).\n\n\n\n\nBiondo, N., Soilemezidi, M., & Mancini, S. (2022). Yesterday is history, tomorrow is a mystery: An eye-tracking investigation of the processing of past and future time reference during sentence reading. Journal of Experimental Psychology: Learning, Memory, and Cognition, 48(7), 1001–1018. https://doi.org/10.1037/xlm0001053"
  },
  {
    "objectID": "07-independence_assumption.html#learning-objectives",
    "href": "07-independence_assumption.html#learning-objectives",
    "title": "8  Independence",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nIn this chapter we will learn…\n\nabout the assumption of independence\nabout sources of dependence in linguistic data"
  },
  {
    "objectID": "07-independence_assumption.html#independence-assumption",
    "href": "07-independence_assumption.html#independence-assumption",
    "title": "8  Independence",
    "section": "8.1 Independence assumption",
    "text": "8.1 Independence assumption\nLanguage research very often involves data points that are linked to each other in one way or another, for example because they come from the same participant or the same text. However, regression models assume that data points are independent, and not taking into account the dependence between data points (e.g., data points from the same participant) violate this assumption. The assumption of independence (or independence assumption)\n\n8.1.1 Review: Model assumptions\n\n\n8.1.2 Sources of dependence"
  },
  {
    "objectID": "07-independence_assumption.html#language-as-fixed-effect-fallacy",
    "href": "07-independence_assumption.html#language-as-fixed-effect-fallacy",
    "title": "8  Independence",
    "section": "8.2 Language-as-fixed-effect-fallacy",
    "text": "8.2 Language-as-fixed-effect-fallacy\nlanguage-as-fixed-effect-fallacy (clark_1973?) coined the term language-as-fixed-effect-fallacy."
  },
  {
    "objectID": "07-independence_assumption.html#mixed-models-a-short-history",
    "href": "07-independence_assumption.html#mixed-models-a-short-history",
    "title": "8  Independence",
    "section": "8.3 Mixed models: A short history",
    "text": "8.3 Mixed models: A short history\nWhat do you think of when you think of the year 2008? It might be the inauguration of Barack Obama, the release of Beyoncé’s ‘Single Ladies’, or perhaps it’s the special issue on Emerging Data Analysis from the Journal of Memory and Language. It’s probably not the latter, but this JML special issue was just as big a deal in the linguistic community. There were two articles in particular that are often credited as the turning point for linguistic data analysis, turning from statistical tests to statistical models: Jaeger (2008) and Baayen et al. (2008). Importantly, Baayen et al. (2008) introduced the lme4 R-package for linear mixed models.1. After this point, many language researchers began using mixed models in their analyses, tending to use what’s called the random-intercepts only model. These models include a term for varying intercepts per some grouping factor (most typically participants and/or items), thereby taking into account some variation due to the non-independence of data points from each group level. This is what we will implement in the next chapter."
  },
  {
    "objectID": "07-independence_assumption.html#learning-objectives-1",
    "href": "07-independence_assumption.html#learning-objectives-1",
    "title": "8  Independence",
    "section": "Learning Objectives 🏁",
    "text": "Learning Objectives 🏁\nIn this chapter we learned…\n\nabout the assumption of independence ✅\nabout sources of dependence in linguistic data ✅\nthe history of mixed models in linguistics ✅"
  },
  {
    "objectID": "07-independence_assumption.html#session-info",
    "href": "07-independence_assumption.html#session-info",
    "title": "8  Independence",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.0    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.0       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.44        jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "07-independence_assumption.html#references",
    "href": "07-independence_assumption.html#references",
    "title": "8  Independence",
    "section": "References",
    "text": "References\n\n\nBaayen, R. H., Davidson, D. J., & Bates, D. M. (2008). Mixed-effects modeling with crossed random effects for subjects and items. Journal of Memory and Language, 59(4), 390–412. https://doi.org/10.1016/j.jml.2007.12.005\n\n\nJaeger, T. F. (2008). Categorical data analysis: Away from ANOVAs (transformation or not) and towards logit mixed models. Journal of Memory and Language, 59(4), 434–446. https://doi.org/10.1016/j.jml.2007.11.007\n\n\nWinter, B. (2014). A very basic tutorial for performing linear mixed effects analyses (Tutorial 2).\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547\n\n\nWinter, B., & Grice, M. (2021). Independence and generalizability in linguistics. Linguistics, 59(5), 1251–1277. https://doi.org/10.1515/ling-2019-0049"
  },
  {
    "objectID": "07-independence_assumption.html#footnotes",
    "href": "07-independence_assumption.html#footnotes",
    "title": "8  Independence",
    "section": "",
    "text": "This wasn’t the first introduction of mixed models for language sciences, but was the first to introduce lme4↩︎"
  },
  {
    "objectID": "08-mixed_models1.html#learning-objectives",
    "href": "08-mixed_models1.html#learning-objectives",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nToday we will learn…\n\nhow to run our fixed mixed effects model with random intercepts\nhow to interpret random intercepts"
  },
  {
    "objectID": "08-mixed_models1.html#set-up-environment",
    "href": "08-mixed_models1.html#set-up-environment",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "Set-up environment",
    "text": "Set-up environment\nOur first steps are to set-up our environment. The next two chunks are not necessary, but I use them to set some preferences, such as supressing scientific notation, and establishing a function to nicely format p-values.\n\n# suppress scientific notation\noptions(scipen=999)\noptions(pillar.sigfig = 5)\n\n\n\nCode for a function to format p-values\nlibrary(broman)\n# function to format p-values\nformat_pval &lt;- function(pval){\n    dplyr::case_when(\n        pval &lt; .001 ~ \"&lt; .001\",\n        pval &lt; .01 ~ \"&lt; .01\",\n        pval &lt; .05 ~ \"&lt; .05\",\n        TRUE ~ broman::myround(pval, 3)\n    )\n}\n\n\n\nLoad packages\nWe’ll also need to load in our required packages. Hopefully you’ve already install the required packages (if not, go to Chapter 3).\n\n# load libraries\npacman::p_load(\n               tidyverse,\n               here,\n               broom,\n               janitor,\n               ggeffects,\n               sjPlot,\n               # new packages:\n               lme4,\n               lmerTest,\n               broom.mixed,\n               lattice)\n\nHere I also globally set my preferred ggplot2 theme so that all of my plots are formatted how I like them, without have to repeat the code for each plot. This is completely optional.\n\n# set preferred ggplot2 theme\ntheme_set(theme_bw() + theme(plot.title = element_text(size = 10)))\n\n\nResolve conflicts\nSometimes different packages have functions with the same name. In these cases, when you call such a function the package that was last loaded will be used. Both lme4 and lmerTest have a function lmer(), but for now we want to use the lme4 version. We’ll discuss the differences later, but for now let’s make sure that lme4 is used. We could also do this each time we call the function by using lme4::lmer(), but this can become cumbersome. Instead, let’s explicitly define lme4::lmer() as the function version that should be used.\n\nlmer &lt;- lme4::lmer\n\n\n\n\nLoad data\nNow let’s load in our dataset from Biondo et al. (2022).\n\ndf_biondo &lt;-\n  read_csv(here(\"data\", \"Biondo.Soilemezidi.Mancini_dataset_ET.csv\"),\n           locale = locale(encoding = \"Latin1\") ## for special characters in Spanish\n           ) |&gt; \n  clean_names() |&gt; \n  mutate(gramm = ifelse(gramm == \"0\", \"ungramm\", \"gramm\"))\n\nAnd take a look at the data:\n\nhead(df_biondo)\n\n# A tibble: 6 × 13\n  sj     item adv_type adv_t verb_t gramm   roi label       fp    gp    tt    ri\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1        54 Deic     Past  Past   gramm     1 En la c…  1173  1173  1173     0\n2 1        54 Deic     Past  Past   gramm     2 ayer te…   474   474   474     0\n3 1        54 Deic     Past  Past   gramm     3 los car…   910   910   910     0\n4 1        54 Deic     Past  Past   gramm     4 encarga…  1027  1027  1027     0\n5 1        54 Deic     Past  Past   gramm     5 muchas …   521   521   521     0\n6 1        54 Deic     Past  Past   gramm     6 al prov…  1029  1029  1029     0\n# ℹ 1 more variable: ro &lt;dbl&gt;\n\n\n?tbl-data_dictionary gives an overview of the variables in the dataset. Relevant for this chapter are the variables fp, verb_t, gramm, and roi. For the tasks at the end of the chapter, you’ll also be working with tt and adv_t.\n\n\n\n\n\n\n\n\n\n\n\nvariable\ndescription\ntype\nclass\n\n\n\n\nsj\nparticipant ID\ngrouping\nfactor\n\n\nitem\nitem ID\ngrouping\nfactor\n\n\nadv_type\nadverb type: Deictic (e.g., on Monday), Non-deictic (e.g., last Monday)\nindependent\nfactor\n\n\nadv_t\nadverb tense: Past, Future\nindependent\nfactor\n\n\nverb_t\nverb tense: Past, Future\nindependent\nfactor\n\n\ngramm\ngrammaticality: gramatical or ungramatical\nindependent\ncategorical\n\n\nroi\nsentence region (Region Of Interest); 2 = adverb, 4 = verb\nindependent\nordered factor\n\n\nlabel\nsentence region text\nindependent\nstring\n\n\nfp\nfirst-pass reading time (summation of fixations from when a reader first fixates on a region to when they first leave that region)\ndependent\ncontinuous\n\n\ngp\nregression path duration/go-past time\ndependent\ncontinuous\n\n\ntt\ntotal reading time (summation of all fixations within a region during a trial)\ndependent\ncontinuous\n\n\nri\nregressions in (whether there was at least one regression into a region)\ndependent\nbinomial\n\n\nro\nregressions out (whether there was at least one regression out of a region)\ndependent\nbinomial"
  },
  {
    "objectID": "08-mixed_models1.html#review",
    "href": "08-mixed_models1.html#review",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.1 Review",
    "text": "9.1 Review\nUp until now, we’ve learned about the equation of a line (Section 1.3), simple (?sec-simple-regression) and multiple linear regression (?sec-multiple-regression), and logisitic regression (?sec-logistic-regression). We’ve also learned about centering and standardizing continuous predictors (?sec-continuous-predictors), and contrast coding categorical predictors (?sec-contrast-coding). We discussed non-linear transformations for dependent variables in linear regression, such as log-transforming data with a positive skew (?sec-log-transformation), and how to interpret the coefficients of logistic regressions in log-odds, odds, and probabilities (?sec-log-odds). If any of these topics don’t sound familiar to you, I suggest going back and reviewing the relevant chapter. If you feel you have a somewhat good handle on these topics, then proceed.\n\n9.1.1 Model equation\nRecall the equation of multiple linear regression model, given in Equation \\(\\ref{eq-mult_reg}\\).\n\\[\\begin{equation}\ny_i = b_0 + b_1x_i + b_2x_1 + ... +e_i \\label{eq-mult_reg}\n\\end{equation}\\]\nWhere the value of some value \\(y\\) (indexed by \\(i\\)) equals the intercept (\\(b_0\\)) plus the corresponding value \\(x\\) (indexed by \\(i\\)) of our first predictor (\\(b_1\\)) plus that of our second predictor (\\(b_2\\)), plus the corresponding error \\(e\\) (indexed by \\(i\\)), which is simply the difference between the predicted value and the observed value (i.e., residual). Here, \\(i\\) indicates values corresponding to the same observation \\(i\\). Such a model assumes that all possible groups within our data have the same intercept and the same slope.\nThe estimated parameters, i.e., our coefficients (\\(b_0\\), \\(b_1\\), \\(b_2\\)), are our fixed effects. The estimated values model the mean/population-level effects in our data. Mixed models try to model some of the variance, i.e., residual error (\\(e_i\\)), by including random effects. Though we will never completely get rid of the unexplained variance in our model (\\(e\\)), we can try to minimise it by including some expected variation present in our data. When, why, and how we can do that is the topic of this chapter."
  },
  {
    "objectID": "08-mixed_models1.html#mixed-models-why-when-and-how",
    "href": "08-mixed_models1.html#mixed-models-why-when-and-how",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.2 Mixed models: why, when, and how?",
    "text": "9.2 Mixed models: why, when, and how?\nMixed models are ‘mixed’ in that they have both fixed and random effects. Fixed effects are our predictors (i.e., independent variables), the variance in the data we are trying to explain and generalise beyond our data. We would expect the model estimates of our fixed effects to be similar if we were to re-run our experiment with different participants, and even with different linguistic items that contain the same manipulation.\nRandom effects take into account the random variance, i.e., the variance in our data we are not trying to explain and that we would not expect to replicate across experiments. This is because they are dependent on e.g., the participants or specific linguistic items we collected our data from. Whether or not we have non-independence in our data depends on how/from where we collected our data. It’s common for experiments to involve multiple observations per participant and for the same stimuli (i.e., items) to be presented across participants. In production studies for example, participants may be asked to read the same sentences or words out loud. In corpus studies, data may be collected from several sources with multiple data points collected from the same text and/or author.\nTake participants for example: different people will tend to have different reading speeds, fundamental frequencies, and even different effects of our critical manipulations. That is to say, data points from a certain participant will tend to be grouped together since one participant might tend to be a faster reader than another participant, or have a higher fundamental frequency than another. The same can be said for experimental items: one item (e.g., Yesterday/Tomorrow, the workers went/will go to the bakery) might tend to have longer reading times or a larger effect of grammaticality than another item for one reason or another.\nOf course, participant and item are not the only sources of non-independence in linguistic data. Winter & Grice (2021) provides a description of other possible sources of non-independence in language research, such as phonetic production studies (speaker, exact repetitions), and corpora (author, text, register). In essence, random effects are grouping factors in our data across beyond which we want to generalise our observed effects.\n\n9.2.1 Why?\nSimply put, because of the independence assumption and Type I (alpha) error! The “sexy” answer: Not accounting for non-independence in our data can lead to unreliable p-values.\n\n\n9.2.2 When?\nWhenever you have observations (i.e., data points) that are somehow linked. One such case is when you have a repeated measures design, as is often the case in linguistic experiments: each participant sees the same experimental items. Therefore, we have multiple (non-independent) observations per participant, and also multiple (non-independent) observations per item. See Section 3 in Winter & Grice (2021) for a discussion of sources of dependence beyond participant and item in different subfields of language research.\nLet’s look at an example. We perviously used the data from from Biondo et al. (2022), which contains data from an eye-tracking during reading experiment with a repeated measures design. We’re interested in whether reading times were affected by adverb-tense congruence (grammaticality) and tense (past vs. future). Let’s review your model from Report 1.\n\n9.2.2.1 An example: report 1 model\nIn the first report for this class, you fit a model of first-pass reading times from Biondo et al. (2022) with the predictors (i.e., fixed effects) grammaticality, tense, and their interaction. The resulting coefficients should look something like Table 9.1.\n\n\nCode for data prep\n# prep data for model\ndf_deic_verb &lt;-\n  df_biondo |&gt; \n  # filter for verb region (roi = 4) and Deictic adverbs\n  filter(roi == 4,\n         adv_type == \"Deic\") |&gt; \n  # set predictors as factors for contrast coding\n  mutate(gramm = as_factor(gramm),\n         verb_t = as_factor(verb_t))\n\n# sum contrast coding: gramm and Past = -0.5\ncontrasts(df_deic_verb$gramm) &lt;- c(-0.5, 0.5)\ncontrasts(df_deic_verb$verb_t) &lt;- c(-0.5, 0.5)\n\n# check contrasts\n# contrasts(df_deic_verb$gramm)\n# contrasts(df_deic_verb$verb_t)\n\n\n\nfit_lm_fp &lt;-\n  lm(log(fp) ~ gramm*verb_t,\n     data = df_deic_verb)\n\n\n\nCode for table\n# model\n# print model coefficients only\ntidy(fit_lm_fp) |&gt; \n  kable(digits = 3) |&gt; \n  kable_styling()\n\n\n\n\nTable 9.1: Output from report 1 model of first-pass reading times\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n5.957\n0.008\n741.568\n0.000\n\n\ngramm1\n0.003\n0.016\n0.193\n0.847\n\n\nverb_t1\n0.061\n0.016\n3.809\n0.000\n\n\ngramm1:verb_t1\n-0.015\n0.032\n-0.474\n0.635\n\n\n\n\n\n\n\n\nWe see there is a significant effect of verb tense (Est = 0.06, t = 3.9, p &lt; .001), where the slope (and therefore the t-value) is positive. Since we coded Past as -0.5 and Future as +0.5, a positive slope means there were longer first-pass reading times for the Future condition, which we also saw when we plotted the raw data. So, this means that future-tensed verbs elicited longer first-pass reading times, and that the congruence of the verb with a preceding temporal adverb did not affect first-pass reading times. When we back-transform the log-transformed predicted values per condition into milliseconds we get Table 9.2.\n\n\nClick here to see code for the table\nggpredict(fit_lm_fp, terms = c(\"verb_t\", \"gramm\")) |&gt; \n  as_tibble() |&gt; \n  rename(\n    tense = x,\n    gramm = group\n  ) |&gt; \n  relocate(tense, gramm) |&gt; \n  knitr::kable(digits = 3) |&gt; \n  kableExtra::kable_styling()\n\n\n\n\nTable 9.2: Predicted values from our lm() model back-transformed into milliseconds\n\n\ntense\ngramm\npredicted\nstd.error\nconf.low\nconf.high\n\n\n\n\nPast\ngramm\n372.892\n0.016\n361.354\n384.798\n\n\nPast\nungramm\n376.912\n0.016\n365.202\n388.998\n\n\nFuture\ngramm\n399.460\n0.016\n387.069\n412.249\n\n\nFuture\nungramm\n397.658\n0.016\n385.329\n410.382\n\n\n\n\n\n\n\n\nBut if we look at each participants observations, e.g., their first-pass reading times for past versus future tensed verbs, we see there is quite some variation in their means and in the effect of tense. Figure 9.1 shows by-participant variation in first-pass reading times for past and future tenses from seven example participants, in raw milliseconds (A) and log-transformed first-pass reading times (B). In each plot, the vertical grey dotted line indicates \\(x = 0\\) (because we used sum contrast coding \\(x = 0\\) is smack dab in the middle between past and future), the blue line represents the by-participant intercept and slope, while the black line represents the intercept and slope from our model. The black line therefore represents the population-level values, i.e., the mean of all first-pass reading times and the mean effect of tense.\n\n\nCode for plots\nfig_biondo_sj_ms &lt;-\n  df_biondo |&gt; \n  filter(sj %in% c(1,10,2,35,46,57,63)) |&gt; \n  mutate(verb_t = factor(verb_t, levels = c(\"Past\", \"Future\"))) |&gt; \nggplot() + \n  aes(x = verb_t, y = fp,\n      colour = verb_t,\n      shape = verb_t) + \n  facet_wrap(\"sj\", nrow = 1) +\n  # Put the points on top of lines\n  geom_point(position = position_jitter(0.2),\n             alpha = .2) +\n  stat_smooth(aes(group = 1), method = \"lm\") +\n  # geom_boxplot(colour = \"black\", alpha = 0) +\n  labs(y = \"First-pass RT (ms)\", \n       x = \"Tense\") +\n  geom_vline(xintercept = 1.5, colour = \"grey\", linetype = \"dashed\")+\n  theme(legend.position = \"none\")  +\n  geom_abline(\n    intercept = exp(coef(fit_lm_fp)[1]-(coef(fit_lm_fp)[3]*1.5)) , \n    slope = (exp(coef(fit_lm_fp)[1]+(coef(fit_lm_fp)[3]*0.5)) - exp(coef(fit_lm_fp)[1]+(coef(fit_lm_fp)[3]*-0.5)))\n                )\n\nfig_biondo_sj_log &lt;-\ndf_biondo |&gt; \n  mutate(verb_t = factor(verb_t, levels = c(\"Past\", \"Future\"))) |&gt; \n  filter(sj %in% c(1,10,2,35,46,57,63)) |&gt; \nggplot() + \n  aes(x = verb_t, y = log(fp),\n      colour = verb_t,\n      shape = verb_t) + \n  facet_wrap(\"sj\", nrow = 1) +\n  # Put the points on top of lines\n  geom_point(position = position_jitter(0.2),\n             alpha = .2) +\n  stat_smooth(aes(group = 1), method = \"lm\") +\n  labs(y = \"First-pass RT (log)\", x = \"Tense\") +\n  geom_vline(xintercept = 1.5, colour = \"grey\", linetype = \"dashed\") +\n  theme(legend.position = \"none\")  +\n  geom_abline(\n    intercept = coef(fit_lm_fp)[1]-(coef(fit_lm_fp)[3]*1.5),\n    slope = coef(fit_lm_fp)[3])\n\n# print\nfig_biondo_sj_ms / fig_biondo_sj_log + theme(legend.position = \"none\") +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nFigure 9.1: Demonstration of by-participant variation in intercept and slope (blue line) versus fixed-effects-only model intercept and slope (black line) for seven example participants. Grey dashed line indicates \\(x = 0\\). Points represent single observations.\n\n\n\n\nNote in Figure 9.1 that there is variation in the central tendency of observations per participant. For example, Participant 10 had overall longer first-pass reading times than the other participants, as did Participant 1. Conversely, some participants had overall faster first-pass reading times, such as Participants 46 and 63. Meanwhile, some participants were pretty near the grand mean, like Participants 2 and 57. This is not to mention the differences in the slopes: some participants have a flatter slope than the model’s fitted slope (e.g., Participants 35 and 46), while some even have a slope in the opposite direction (e.g., Participants 1 and 63).\nFigure 9.2 shows the same trend across a sample of seven experimental items. Some by-item intercepts were similar to the model intercept (e.g., items 1 and 85), while some deviated (e.g., item 10 and 26).\n\n\nCode for plots\nfig_biondo_item_ms &lt;-\n  df_biondo |&gt; \n  filter(item %in% c(1,10,26,33,58,101,85)) |&gt;\n  mutate(verb_t = factor(verb_t, levels = c(\"Past\", \"Future\"))) |&gt; \nggplot() + \n  aes(x = verb_t, y = fp,\n      colour = verb_t,\n      shape = verb_t) + \n  facet_wrap(\"item\", nrow = 1) +\n  # Put the points on top of lines\n  geom_point(position = position_jitter(0.2),\n             alpha = .2) +\n  stat_smooth(aes(group = 1), method = \"lm\") +\n  # geom_boxplot(colour = \"black\", alpha = 0) +\n  labs(y = \"First-pass RT (ms)\", \n       x = \"Tense\") +\n  geom_vline(xintercept = 1.5, colour = \"grey\", linetype = \"dashed\")+\n  theme(legend.position = \"none\")  +\n  geom_abline(\n    intercept = exp(coef(fit_lm_fp)[1]-(coef(fit_lm_fp)[3]*1.5)) , \n    slope = (exp(coef(fit_lm_fp)[1]+(coef(fit_lm_fp)[3]*0.5)) - exp(coef(fit_lm_fp)[1]+(coef(fit_lm_fp)[3]*-0.5)))\n                )\n\nfig_biondo_item_log &lt;-\ndf_biondo |&gt; \n  mutate(verb_t = factor(verb_t, levels = c(\"Past\", \"Future\"))) |&gt; \n  filter(item %in% c(1,10,26,33,58,101,85)) |&gt;\nggplot() + \n  aes(x = verb_t, y = log(fp),\n      colour = verb_t,\n      shape = verb_t) + \n  facet_wrap(\"item\", nrow = 1) +\n  # Put the points on top of lines\n  geom_point(position = position_jitter(0.2),\n             alpha = .2) +\n  stat_smooth(aes(group = 1), method = \"lm\") +\n  labs(y = \"First-pass RT (log)\", x = \"Tense\") +\n  geom_vline(xintercept = 1.5, colour = \"grey\", linetype = \"dashed\") +\n  theme(legend.position = \"none\")  +\n  geom_abline(\n    intercept = coef(fit_lm_fp)[1]-(coef(fit_lm_fp)[3]*1.5),\n    slope = coef(fit_lm_fp)[3])\n\n# print\nfig_biondo_item_ms / fig_biondo_item_log + theme(legend.position = \"none\") +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nFigure 9.2: Demonstration of by-item variation in intercept and slope (blue line) versus fixed-effects-only model intercept and slope (black line) for seven example items. Grey dashed line indicates \\(x = 0\\). Points represent single observations.\n\n\n\n\nIf we were to gather by-participant and by-item slopes from all participants and items and plotted them together, we would get Figure 9.3 (where colour indicates direction of slope: positive or negative).\n\nfig_item_sj_fp_means\n\n\n\n\nFigure 9.3: Means per condition per item (left) and subject (right) with overall mean in black\n\n\n\n\nWe see saw in seven examples in Figure 9.1 and (fit-pooling_item?), and across all participants and items in Figure 9.3, that there is a lot of variability in terms of the overall mean (intercept, which would correspond to the grey dotted line) across items and participants, as well and in the differences between past and future verbs. Firstly, focusing on the intercept (values crossing the vertical grey dotted line), there is a range of approximately 300 to 675 ms between items, and a range of 250 and 875 between participants. Compared to the overall mean of 440.5ms, this is quite some variation. Looking now at the effect of tense, i.e. the slope, we see not only differences in the magnitude of effects between items and participants (i.e., how steep the slope is), but also in the direction of the effect: There are quite a few items and participants that have a slope in the opposite direction of the overall mean in black, which is positive.\nSo why does it matter that there’s variability by item and by participant? All of this data was already included in our model, and so it was taken into consideration when calculating standard error and confidence intervals, so why should this matter? The answer is simply: dependence of data points affects the number of observations, which in turn affects our degrees of freedom and measures like standard error and confidence intervals. In essence, it alters our measures of uncertainty in the presence or absence of a reliable effect.\nTo drive this point home, let’s look at an ordered plot of by-item and -participant intercepts with 95% confidence intervals (Figure 9.4) and boxplots of the raw observations of first-pass reading times at the verb region (Figure 9.5). In Figure 9.4, we see the intercept value on the x-axis, again highlighting the range of varying intercept values for across items and participants. In Figure 9.5, we see the range in the spread of values, with wider inter-quartile ranges especially for particpants with higher a median first-pass reading time. This was also represented in Figure 9.4 by wider 95% confidence intervals for both items and participants with higher intercepts.\n\n\n\n\n\nFigure 9.4: By-item (left) and -participant (right) varying intercepts (x-axis) per grouping factor level (i.e., per item and per participant). Errorbars indicate 95% confidence intervals.\n\n\n\n\n\n\nCode for plots\nfig_sj_boxplot &lt;-\n  df_deic_verb |&gt;\n  mutate(sj_median = median(fp, na.rm = T), .by=sj) |&gt; \n  ggplot() +\n  aes(x = reorder(sj, sj_median), y = fp) +\n  labs(title = \"By-participant boxplot of first-pass reading times at the verb\",\n       y = \"First-pass RT (ms)\") +\n  geom_boxplot() +\n  theme(\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank()\n      )\n\nfig_item_boxplot &lt;-\ndf_deic_verb |&gt; \n  mutate(item_median = median(fp, na.rm = T), .by=item) |&gt; \n  ggplot() +\n  aes(x = as_factor(reorder(item, item_median)), y = fp) +\n  labs(title = \"By-item boxplot of first-pass reading times at the verb\",\n       y = \"First-pass RT (ms)\") +\n  geom_boxplot() +\n  theme(\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank()\n      )\n\nfig_sj_boxplot / fig_item_boxplot +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nFigure 9.5: Boxplots of first-pass reading times per participant (A) and item (B)\n\n\n\n\nIn order for our model to take this by-participant and by-item variance into account, we can add by-participant and by-item random terms in a mixed model.\n\n\n\n9.2.3 How?\nWe can add random intercepts and random slopes per grouping factor. Random intercepts would correspond to the average \\(y\\)-value (if we’re using sum contrast coding) per level of a grouping factor, e.g., per participant. Random slopes would give us the fitted effect per level of a grouping factor, e.g., per participant. So, if we fit a model with by-participant random intercepts and slopes, our model will also fit an intercept and slope per participant, thereby taking the by-participant variance into account. Importantly, each grouping factor must be a factor (i.e., categorical), and each level of this grouping factor must have sufficient observations. In this chapter we’ll focus on random intercepts, and we will be running what’s called random-intercept-only or intercept-only random effects models. A word of warning: such models can lead to inflated Type I (alpha) error, i.e., a false positive result (Barr et al., 2013). Mixed models with intercept-only random effects are often the final model reported because of something called convergence issues, meaning the model cannot be fit because of a lack of computational power or too few observations “per cell”.\nThe lme4 (lme4-package?) or lmerTest (lmerTest-package?) packages are commonly used to produced mixed models in R. The main difference between the two is that lmerTest produces p-values while lme4 does not. The coefficients from the two packages should be otherwise identical. For a more in-depth discussion on p-values in mixed models, see for example Section 8.5.1.3 (t/F-tests with approximate df) in Sonderegger (2023). We’ll be using the lme4 package to start off with to fit mixed models with the lmer() function, which uses similar sytax to the lm() function:\n\\[\\begin{align}\ndv &\\sim 1 + iv, data = data\\_name \\label{eq-lm}\\\\\ndv &\\sim 1 + iv + (1 + iv|gf), data = data\\_name \\label{eq-lmer}\n\\end{align}\\]\nWhere dv is our dependent variable (measure, outcome variable), iv is our independent variable(s) (predictor variable), and gf refers to a grouping factor. The 1s stand-in for intercept, so 1 + iv means fit an intercept (1) and slope (iv). Recall that the 1 is optional, and we often don’t write it in our models. We see a 1 in the random effects structure, however: (1 + iv|gf). This represents random effects for a grouping factor (gf): We are fitting an intercept and slope per level of this grouping factor. Basically, this model is a mixed model fit to some dependent variable with an independent variable(s) as fixed effect, and by-grouping factor random intercepts and slopes for our fixed effect iv. You could replace the highlighted terms in the last sentence with the names of your own variables in a model to describe your formula.\nThis might all sound abstract at the moment, but it helps to see it in action. For the rest of the chapter we’ll focus on random intercepts, and we will get to random slopes in the next chapter. Let’s now fit and explore some mixed models."
  },
  {
    "objectID": "08-mixed_models1.html#by-participant-random-intercepts",
    "href": "08-mixed_models1.html#by-participant-random-intercepts",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.3 By-participant random intercepts",
    "text": "9.3 By-participant random intercepts\nRecall the equation in Equation \\(\\ref{eq-mult_reg}\\). To model first-pass reading times as a function of verb tense and grammaticality, we would get Equation \\(\\ref{eq-mixed_model}\\). Adding random intercepts for a single grouping factor would give us Equation \\(\\ref{eq-mixed_model}\\).\n\\[\\begin{align}\nfp &= \\beta_0 + \\beta_{verb\\_t}x + \\beta_{gramm}x \\label{eq-biondo_average} \\\\\nfp_i &= \\beta_0 + \\alpha_{j[i]} + \\beta_{verb\\_t}x + \\beta_{gramm}x + e_i\n\\label{eq-mixed_model}\n\\end{align}\\]\nWhere \\(\\alpha\\) represents the deviation of some level \\([i]\\) in some group \\(j\\) from the population-level intercept (\\(b_0\\)). In other words, we assume here that there is some grouping factor within our data structure and that each level of this grouping factor will have an intercept value that deviates somewhat from the population-level intercept. As we saw above, the data from Biondo et al. (2022) contains non-independent observations from 60 participants. If we wanted to take that into considerat\nA simplified version in is the model for the average participant in our data, where the intercept is the average first-pass reading time across all participants, and the slopes for tense and grammaticality are also the average effect of each across all participants. models the first-pass reading time with varying intercepts for participant (sj), where \\(\\beta_0 + \\alpha_{sj[i]}\\) represents the intercept for participants. models the first-pass reading time for participant (sj) 60, where \\(\\beta_0 + \\alpha_{sj[60]}\\) represents the intercept for participant 60.\n\\[\\begin{align}\nfp &= \\beta_0 + \\alpha_{sj[i]} + \\beta_1x + \\beta_2x  \\label{eq-biondo-sj} \\\\\nfp &= \\beta_0 + \\alpha_{sj[60]} + \\beta_1x + \\beta_2x \\label{eq-biondo-sj60}\n\\end{align}\\]\nLet’s continue with our model from Report 1, with log-transformed first-pass reading times (fp) as dependent variable, grammaticality (gramm), verb tense (verb_t), and their interaction as fixed effects, and by-participant (sj) random intercepts:\n\nfit_lmm_fp_sj &lt;-\n  lmer(log(fp) ~ gramm*verb_t +\n         (1|sj),\n       data = df_deic_verb)\n\nWe see the only difference between this code and that above is that we are using lmer() instead of lm(), and that we have added + (1|sj) to the model equation.\nWhat happens if we try to run this model without + (1|sj)?\n\nfit_lmm_fp_sj &lt;-\n  lmer(log(fp) ~ gramm*verb_t,\n       data = df_deic_verb)\n\nError: No random effects terms specified in formula\n\n\nWe get an informative error message: Error: No random effects terms specified in formula. The lmer() function requires a random effects structure, so if it is missing a model will not be fit.\n\n9.3.1 Inspecting your model output\nThe summary() function also worth lmer() models, but there are some differences in the output.\n\nsummary(fit_lmm_fp_sj)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: log(fp) ~ gramm * verb_t + (1 | sj)\n   Data: df_deic_verb\n\nREML criterion at convergence: 4479.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0560 -0.6427 -0.0419  0.6168  4.0901 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n sj       (Intercept) 0.06573  0.2564  \n Residual             0.18030  0.4246  \nNumber of obs: 3795, groups:  sj, 60\n\nFixed effects:\n                Estimate Std. Error t value\n(Intercept)     5.957102   0.033809 176.199\ngramm1          0.003466   0.013787   0.251\nverb_t1         0.062209   0.013787   4.512\ngramm1:verb_t1 -0.015741   0.027573  -0.571\n\nCorrelation of Fixed Effects:\n            (Intr) gramm1 vrb_t1\ngramm1       0.000              \nverb_t1      0.000 -0.002       \ngrmm1:vrb_1  0.000  0.000  0.002\n\n\nSimilar to the model output from a lm() model, we have the model formula at the top. We also have have the distribution of the residuals, which look quite normally distributed. Our fixed effects are under Fixed Effects (instead of Coefficients in lm() output). Here you might notice we don’t have any p-values, we’ll talk about why below. Lastly, instead of information about model fit (e.g., \\(R^2\\)), we have Correlation of Fixed Effects, which is exactly what the title suggests: the correlation between fixed effects. This corresponds to the assumption of multicollinearity, and should have small values.\nThere are two other main differences near the top: REML criterion at convergence: ..., and our Random effects. We won’t be getting into REML in this course, but know that it is important when doing model comparisons.\n\n\n\n\n\n\nREML: restricted maximum likelihood\n\n\n\nSonderegger (2023), Section 8.5 and Box 8.4\n\n\nWe can use the broom.mixed package to extract tidy coefficient summaries from lmer() models, similar to the broom package for lm() models. The broom.mixed package also has a function tidy() for this purpose. This function also has an optional argument effects which can be used to control what information you extract from your model:\n\neffects = fixed: fixed-effect parameters\neffects = ran_pars: random effects of our model (standard deviations of our random effect terms)\n\n\n\nClick to see code for table\ntidy(fit_lmm_fp_sj, effects = \"fixed\") |&gt; \n  kable() |&gt; \n  kable_styling()\n\n\n\n\nTable 9.3: broom.mixed::tidy(fit_lmm_fp_sj)\n\n\neffect\nterm\nestimate\nstd.error\nstatistic\n\n\n\n\nfixed\n(Intercept)\n5.9571020\n0.0338089\n176.1991812\n\n\nfixed\ngramm1\n0.0034662\n0.0137866\n0.2514208\n\n\nfixed\nverb_t1\n0.0622091\n0.0137873\n4.5120666\n\n\nfixed\ngramm1:verb_t1\n-0.0157409\n0.0275733\n-0.5708757\n\n\n\n\n\n\n\n\n\n\nClick to see code for table\ntidy(fit_lmm_fp_sj, effects = \"ran_pars\") |&gt; \n  kable() |&gt; \n  kable_styling()\n\n\n\n\nTable 9.4: broom.mixed::tidy(fit_lmm_fp_sj)\n\n\neffect\ngroup\nterm\nestimate\n\n\n\n\nran_pars\nsj\nsd__(Intercept)\n0.2563809\n\n\nran_pars\nResidual\nsd__Observation\n0.4246230\n\n\n\n\n\n\n\n\nWe can also use the VarCorr() function from lme4 to extract the variance components (i.e., random effects) from our model summary:\n\nprint(VarCorr(fit_lmm_fp_sj),comp=c(\"Variance\",\"Std.Dev.\"))\n\n Groups   Name        Variance Std.Dev.\n sj       (Intercept) 0.065731 0.25638 \n Residual             0.180305 0.42462 \n\n\nBut what exactly do these random effect parameters mean? We see the estimated degree of by-participant intercept variability is approximately 0.07 has a standard deviation of approximately 0.26.\n\n\n9.3.2 lmerTest\n\nfit_lmm_fp_sj &lt;-\n  lmerTest::lmer(log(fp) ~ gramm*verb_t +\n         (1|sj),\n       data = df_deic_verb)\n\n\n\n9.3.3 Comparing to simple regression\nVisualise both models’ coefficents\n\nfig_lmer &lt;- plot_model(fit_lmm_fp_sj, type = \"int\") + \n  geom_line(position = position_dodge(0.1)) +\n  labs(title = \"Mixed model\",\n       x = \"Grammaticality\",\n       y = \"First-pass (ms)\") +\n  theme_bw() +\n  ylim(340, 440)\n\nfig_lm &lt;- plot_model(fit_lm_fp, type = \"int\") + \n  geom_line(position = position_dodge(0.1)) +\n  labs(title = \"Fixed effects only\",\n       x = \"Grammaticality\",\n       y = \"First-pass (ms)\") +\n  theme_bw() +\n  ylim(340, 440)\n\nfig_lmer + fig_lm + plot_annotation(tag_levels = \"A\") +\n  plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "08-mixed_models1.html#adding-another-grouping-factor",
    "href": "08-mixed_models1.html#adding-another-grouping-factor",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.4 Adding another grouping factor",
    "text": "9.4 Adding another grouping factor\nSo far we’ve fit the data using one grouping factor: participant. The experimental design in (biondo_tomorrow_2022?) used repeated measures, however. This means that each participant was presented items from multiple items. In other words, each item (item) was presented to multiple participants (sj). This is a crossed-design, also called a factorial design, where both participant and item are grouping factors. We should be using crossed random effects, i.e., two grouping factors. We can do this by simply adding another + (1|gf) to our model syntax.\n\nfit_lmm_fp_sj_item &lt;-\n  lmer(log(fp) ~ gramm*verb_t +\n         (1|sj) +\n         (1|item),\n       data = df_deic_verb)\n\nThis is now a model with by-participant and by-item random intercepts. Let’s inspect this model as we did with our model with by-participant random intercepts. This amounts to Equation \\(\\ref{eq-mixed_model_k}\\), where we have varying intercepts (\\(\\alpha\\)) for two grouping variables, \\(j\\) and \\(k\\).\n\\[\\begin{align}\nfp_i &= \\beta_0 + \\alpha_{j[i]} + \\alpha_{k[i]}+ \\beta_{verb\\_t}x + \\beta_{gramm}x + e_i \\label{eq-mixed_model_k}\n\\end{align}\\]\nIf we take \\(j\\) to represent participants and \\(k\\) to represent items, then the \\(j\\) in \\(\\alpha_{j[i]}\\) has 60 levels (1-60, because we have 60 participants), and \\(k\\) in \\(\\alpha_{j[i]}\\) has 96 levels (1-96, because we have 96 items). And \\(i\\) has 3795 levels, because there are 3795 observations in our model (which we will see in a moment)."
  },
  {
    "objectID": "08-mixed_models1.html#exploring-our-random-effects-estimates",
    "href": "08-mixed_models1.html#exploring-our-random-effects-estimates",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.5 Exploring our random effects estimates",
    "text": "9.5 Exploring our random effects estimates\n\nwhat we saw in our model summary were the variance components\n\na description of the variance of our by-item and by-participant random intercepts\n\nour model also contains intercept estimates for each level of item and participant\n\nwe can extract the intercept estimates\nor we extract their deviance from the model intercept\n\n\n\n9.5.1 Extracting fixed effects\n\nwe’ve already used coef() to extract fixed effect estimates from lm objects\n\n\ncoef(fit_lm_fp)\n\n   (Intercept)         gramm1        verb_t1 gramm1:verb_t1 \n   5.957251870    0.003101061    0.061204153   -0.015245374 \n\n\n\nto extract our fixed effect estimates from lmer objects we need fixef()\n\n\nfixef(fit_lmm_fp_sj_item)\n\n   (Intercept)         gramm1        verb_t1 gramm1:verb_t1 \n    5.95640363     0.00321152     0.06189237    -0.01431578 \n\n\n\nor we can append $coefficients to the model summary\n\n\nsummary(fit_lmm_fp_sj_item)$coefficients |&gt; \n  as_tibble()\n\n# A tibble: 4 × 3\n    Estimate `Std. Error` `t value`\n       &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1  5.9564        0.036790 161.90   \n2  0.0032115     0.013025   0.24657\n3  0.061892      0.013025   4.7517 \n4 -0.014316      0.026049  -0.54956\n\n\n\n9.5.1.1 Extract random intercept estimates\n\ncoef() behaves very differently with lmer objects, extracting the random effects estimates per level\n\n\ncoef(fit_lmm_fp_sj_item) |&gt; pluck(\"item\") |&gt; head()\n\n  (Intercept)     gramm1    verb_t1 gramm1:verb_t1\n1    6.022184 0.00321152 0.06189237    -0.01431578\n2    5.761268 0.00321152 0.06189237    -0.01431578\n3    5.854873 0.00321152 0.06189237    -0.01431578\n4    6.056862 0.00321152 0.06189237    -0.01431578\n5    6.138213 0.00321152 0.06189237    -0.01431578\n6    6.331058 0.00321152 0.06189237    -0.01431578\n\n\n\nwhich outputs a list object, with one data frame for item and one for sj\nwe can extract just one or the other (head() is for presentation purposes):\n\n\ncoef(fit_lmm_fp_sj_item) |&gt; pluck(\"item\") |&gt; \n  rownames_to_column(var = \"item\") |&gt; head()\n\n  item (Intercept)     gramm1    verb_t1 gramm1:verb_t1\n1    1    6.022184 0.00321152 0.06189237    -0.01431578\n2    2    5.761268 0.00321152 0.06189237    -0.01431578\n3    3    5.854873 0.00321152 0.06189237    -0.01431578\n4    4    6.056862 0.00321152 0.06189237    -0.01431578\n5    5    6.138213 0.00321152 0.06189237    -0.01431578\n6    6    6.331058 0.00321152 0.06189237    -0.01431578\n\n\n\ncoef(fit_lmm_fp_sj_item) |&gt; pluck(\"sj\") |&gt; \n  rownames_to_column(var = \"sj\") |&gt; head()\n\n  sj (Intercept)     gramm1    verb_t1 gramm1:verb_t1\n1 07    5.869627 0.00321152 0.06189237    -0.01431578\n2 09    5.782527 0.00321152 0.06189237    -0.01431578\n3  1    6.401777 0.00321152 0.06189237    -0.01431578\n4 10    6.621081 0.00321152 0.06189237    -0.01431578\n5 11    5.913712 0.00321152 0.06189237    -0.01431578\n6 12    6.153031 0.00321152 0.06189237    -0.01431578\n\n\n\nwhy do our intercepts vary by participant, but not verb_t1, gramm1, or verb_t1:gramm1?\n\n\n\n9.5.1.2 Extract deviations from the intercept\n\nthe ranef() function provides the deviance from the model intercept and each random intercept estimate\n\nthe output is a list with a one element per grouping factor\n\n\n\nranef(fit_lmm_fp_sj_item) |&gt;  pluck(\"item\") |&gt; \n  rownames_to_column(var = \"item\") |&gt; head(10)\n\n   item (Intercept)\n1     1  0.06578061\n2     2 -0.19513572\n3     3 -0.10153080\n4     4  0.10045812\n5     5  0.18180978\n6     6  0.37465425\n7     7  0.09281920\n8     8  0.13695475\n9     9  0.05810287\n10   10 -0.05426568\n\n\n\n\n\nranef()$grouping_factor or pluck(\"grouping_factor\") selects the relevant grouping factor\n\n\n\nranef(fit_lmm_fp_sj_item)$sj |&gt; \n  head()\n\n   (Intercept)\n07 -0.08677692\n09 -0.17387701\n1   0.44537367\n10  0.66467739\n11 -0.04269124\n12  0.19662767\n\n\n\n\nranef(fit_lmm_fp_sj_item) |&gt; \n  pluck(\"sj\") |&gt; head()\n\n   (Intercept)\n07 -0.08677692\n09 -0.17387701\n1   0.44537367\n10  0.66467739\n11 -0.04269124\n12  0.19662767\n\n\n\n\n\n\n9.5.1.3 Compare estimates and deviances\n\nthe values extracted by ranef() (sj_dev in Table 9.5) equal the difference (difference) between the model intercept (model_intercept) and the by-participant random intercept estimates (sj_est)\nso we can either look at each participant’s (or item’s) estimate, or look at how much it deviates from the model intercept\n\n\n\n\n\nTable 9.5: Random intercept estimates versus deviance\n\n\nsj\nsj_est\nsj_dev\nest_minus_dev\nmodel_intercept\nest_minus_intercept\n\n\n\n\n07\n5.870\n-0.087\n5.956\n5.956\n-0.087\n\n\n09\n5.783\n-0.174\n5.956\n5.956\n-0.174\n\n\n1\n6.402\n0.445\n5.956\n5.956\n0.445\n\n\n10\n6.621\n0.665\n5.956\n5.956\n0.665\n\n\n11\n5.914\n-0.043\n5.956\n5.956\n-0.043\n\n\n12\n6.153\n0.197\n5.956\n5.956\n0.197"
  },
  {
    "objectID": "08-mixed_models1.html#visualising-your-random-effects",
    "href": "08-mixed_models1.html#visualising-your-random-effects",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.6 Visualising your random effects",
    "text": "9.6 Visualising your random effects\nThe simplest method to visualise your random effects is to use the dotplot() function from the lattice package. This prints out a caterpillar plot with a dot indicating the deviance of the intercept value per grouping factor level (here: per participant) from the model intercept, with 95% confidence intervals.\n\ndotplot(ranef(fit_lmm_fp_sj))\n\n$sj\n\n\n\n\n\nWe can also produce this plot ourselves by extracting our random effects per participant by using the broom.mixed::tidy() function with the argument effects = \"ran_vals and conf.int = TRUE. This will give us the intercept value, rather than the deviance from the model intercept. However, you can easily calculate the deviance by subtracting the model intercept value from each participant’s intercept value (Figure 9.6 A). If we want the actual by-partiipant intercept values, we can simply add the model intercept to get each by-participant estimate, i.e., the values we get with coef() (Figure 9.6 B). Notice that in comparison to Figure 9.6, nothing has changed except the values along the x-axis. This is because we’ve performed a linear transformation: adding the model intercept value to the by-participant deviance. The x-axis ticks in Figure 9.6 B equal values as those in Figure 9.6 A (-0.5, 0, 0.5), but with the model intercept value (5.957102) added.\n\n\nCode for plots\nfig_res_dev &lt;-\n  broom.mixed::tidy(fit_lmm_fp_sj, effects = \"ran_vals\", conf.int = TRUE) |&gt; \n  filter(group == \"sj\") |&gt; \n  ggplot() +\n  aes(x = estimate, y = reorder(level, estimate))  +\n  labs(title = \"By-participant intercept deviance (log)\",\n       y = \"Participant ID\",\n       x = \"Deviance (log)\") +\n  geom_vline(xintercept = 0, colour = \"red\", linetype = \"dashed\") +\n  geom_point(colour = \"blue\") +\n  geom_errorbar(\n    aes(xmin = conf.low,\n        xmax = conf.high)\n  ) +\n  scale_x_continuous(breaks = c(-0.5,0,0.5)) +\n  facet_grid(~term)\n\nfig_res_est &lt;-\n  broom.mixed::tidy(fit_lmm_fp_sj, effects = \"ran_vals\", conf.int = TRUE) |&gt; \n  filter(group == \"sj\") |&gt; \n  # back-transform to ms\n  mutate(across(c(estimate,conf.low,conf.high),~.+fixef(fit_lmm_fp_sj)[1])) |&gt; \n  # mutate(across(c(estimate,conf.low,conf.high),exp)) |&gt; \n  # plot\n  ggplot() +\n  aes(x = estimate, y = reorder(level, estimate))  +\n  labs(title = \"By-participant intercept estimates (ms)\",\n       y = \"Participant ID\",\n       x = \"Estimate (log)\") +\n  geom_vline(xintercept = fixef(fit_lmm_fp_sj)[1], colour = \"red\", linetype = \"dashed\") +\n  geom_point(colour = \"blue\") +\n  geom_errorbar(\n    aes(xmin = conf.low,\n        xmax = conf.high)\n  ) +\n  scale_x_continuous(breaks = c(5.457102,5.957102 ,6.457102)) +\n  facet_grid(~term)\n\nfig_res_dev + fig_res_est + \n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nFigure 9.6: By-participant intercept deviances (A) and estimates (B) in log scale\n\n\n\n\nIf we wanted to back-transform these values to milliseconds to facilitate interpretation, we simply exponentiate these estimates (Figure 9.7 A). Lastly, we can back-transform the deviances by subtracting the exponentiating model estimate from the back-transformed estimates (Figure 9.7 B).\n\n\nCode for plot\nfig_res_est_ms &lt;-\n  broom.mixed::tidy(fit_lmm_fp_sj, effects = \"ran_vals\", conf.int = TRUE) |&gt; \n  filter(group == \"sj\") |&gt; \n  # back-transform to ms\n  mutate(across(c(estimate,conf.low,conf.high),~.+fixef(fit_lmm_fp_sj)[1])) |&gt; \n  mutate(across(c(estimate,conf.low,conf.high),exp)) |&gt;\n  # plot\n  ggplot() +\n  aes(x = estimate, y = reorder(level, estimate))  +\n  labs(title = \"By-participant intercept estimates (ms)\",\n       y = \"Participant ID\",\n       x = \"Estimate (ms)\") +\n  geom_vline(xintercept = exp(fixef(fit_lmm_fp_sj)[1]), colour = \"red\", linetype = \"dashed\") +\n  geom_point(colour = \"blue\") +\n  geom_errorbar(\n    aes(xmin = conf.low,\n        xmax = conf.high)\n  ) +\n  scale_x_continuous(breaks = c(186.4884,386.4884, 586.4884, 786.4884)) +\n  facet_grid(~term)\n\nfig_res_dev_ms &lt;-\nbroom.mixed::tidy(fit_lmm_fp_sj, effects = \"ran_vals\", conf.int = TRUE) |&gt; \n  filter(group == \"sj\") |&gt; \n  # back-transform to ms\n  mutate(across(c(estimate,conf.low,conf.high),~.+fixef(fit_lmm_fp_sj)[1])) |&gt; \n  mutate(across(c(estimate,conf.low,conf.high),exp)) |&gt;\n  mutate(across(c(estimate,conf.low,conf.high),~.-exp(fixef(fit_lmm_fp_sj)[1]))) |&gt;\n  # plot\n  ggplot() +\n  aes(x = estimate, y = reorder(level, estimate))  +\n  labs(title = \"By-participant intercept deviance (ms)\",\n       y = \"Participant ID\",\n       x = \"Deviance (ms)\") +\n  geom_vline(xintercept = 0, colour = \"red\", linetype = \"dashed\") +\n  geom_point(colour = \"blue\") +\n  geom_errorbar(\n    aes(xmin = conf.low,\n        xmax = conf.high)\n  ) +\n  # scale_x_continuous(breaks = c(-0.5,0,0.5)) +\n  facet_grid(~term)\n\nfig_res_est_ms + fig_res_dev_ms +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nFigure 9.7: By-participant estimates back-transformed to milliseconds\n\n\n\n\nThese plots should seem somewhat familiar given our exploration of the by-participant variance in the dataset above. Now we see how this variance is modelled and including in our model, but what does including it actually change? Let’s take a look at the difference between our mixed model with by-participant varying intercepts and our fixed-effects only model."
  },
  {
    "objectID": "08-mixed_models1.html#reporting-your-model",
    "href": "08-mixed_models1.html#reporting-your-model",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.7 Reporting your model",
    "text": "9.7 Reporting your model\n\naccording to Sonderegger (2023) (p. 297), we should report:\n\nmodel definition (sometimes in ‘Data Analysis’ section)\nFixed effects\nRandom effects\nSample size (number of observations, number of levels for each grouping factor)\none or more quantitative summaries of the model, e.g., AIC, BIC, or logLik (although they’re only informative in comparison to another model fit to the same data)\n\n\n\n9.7.1 Model definition\nBelow is an example of a write-up of a model definition from Biondo et al. (2022) (p. 9). Note that I’ve highlighted some aspects that we’ve already covered, which you should remember to define in write ups.\n\nWe conducted the analysis by fitting linear mixed-effect models to our data, using the R package lme4 (Bates et al., 2014). We included Time Reference (past, future), and Verb Match (match, mismatch) as fixed-effect factors […] by adopting sum contrast coding (Schad et al., 2020): past and match conditions were coded as –.5. while future and mismatch conditions were coded as .5. […] Moreover, we included crossed random intercepts and random slopes for all fixed-effect parameters for subject and item grouping factors (Barr et al., 2013) in all models. […] Logit mixed-effect models were employed (Jaeger, 2008) for the analysis of the probability of regression measure. […] P-values were derived by using the lmerTest package (Kuznetsova et al., 2017).\n\nBut this is missing the explicit mention of the method used to compute the p-values. For example, Troyer & Kutas (2020) (p. 9) included the following:\n\nP-values for individual predictors were computed using lmerTest, with the Satterthwaite option for denominator degrees of freedom for F statistics.\n\nBut here they don’t cite the package. So you see, there’s always something you miss! The aim is to be as descriptive as you can be. The aim in describing your model is to enable reproducibility. If you don’t fully describe your analysis steps it can be difficult (or impossible) to reproduce your analyses. Ideally, your analysis scripts should also be shared alongside your data (laurinavichyute_share_2022?), but your analysis steps should still be explicitly and unambiguously described to the best of your ability in your data analysis/results section.\n\n\n\n\n\n\nCiting packages\n\n\n\nTo get a package’s citation, run citation(\"package\") in the Console with the name of the relevant package in quotes. This will produce the APA-style formatted citation, as well as the BibTex citation (in case you’re writing using Quarto or LaTeX, for example).\n\n\n\n\n9.7.2 Results\nWhen reporting your results a combination of tables, figures, and in-text coefficient estimates is always key. In-line descriptions of your results should include the t- and p-values at minimum. The estimate and standard error (Est = …, SE = …,) could also be included in-line, but must at the very least be included in a table. Figures will typically only show the distribution of raw observations and model predictions for fixed effects, and so don’t differ much from what we saw in previous chapter.\n\n9.7.2.1 In-line text\nAn example of what we could write:\n\nA main effect of tense was found in first-pass reading times at the verb region (Est = 0.062, t = 4.8, p &lt; .001), with the future tense (M = 449ms, SD = 266ms) eliciting longer first-pass reading times than the past tense.\n\n\n\n9.7.2.2 Tables\nWe should include tables of all fixed effects, as we saw in previous chapters. In addition, a description of random effects is a good idea, but isn’t often done in practice.\n\n9.7.2.2.1 Fixed effects\n\n\nCode for table\ntidy(fit_lmm_fp_sj,\n     effects = \"fixed\") |&gt; \n  as_tibble() |&gt; \n  select(-effect) |&gt; \n  mutate(p.value = format_pval(p.value),\n         across(c(estimate,std.error, statistic), round, 3),\n         df = round(df,1)) |&gt; \n  mutate(term = fct_recode(term,\n    \"Intercept\" = \"(Intercept)\",\n    \"Tense\" = \"verb_t1\",\n    \"Grammticality\" = \"gramm1\",\n    \"Tense x Gramm\" = \"verb_t1:gramm1\"\n  )) |&gt; \n  kable(\n        col.names = c(\"Coefficient\", \"$\\\\hat{\\\\beta}$\", \"SE\", \"t\", \"df\", \"p\")) |&gt; \n  kable_styling()\n\n\n\n\nTable 9.6: Table of fixed effects from fit_lmm_fp_sj\n\n\nCoefficient\n$\\hat{\\beta}$\nSE\nt\ndf\np\n\n\n\n\nIntercept\n5.957\n0.034\n176.199\n59.0\n&lt; .001\n\n\nGrammticality\n0.003\n0.014\n0.251\n3732.0\n0.802\n\n\nTense\n0.062\n0.014\n4.512\n3732.1\n&lt; .001\n\n\ngramm1:verb_t1\n-0.016\n0.028\n-0.571\n3732.0\n0.568\n\n\n\n\n\n\n\n\n\n\n9.7.2.2.2 Random effects\n\n\nCode for table\nas.data.frame(VarCorr(fit_lmm_fp_sj),comp=c(\"Variance\",\"Std.Dev.\")) |&gt; \n  as_tibble() |&gt; \n  select(-var2) |&gt; \n  # mutate(var1 = ifelse(var1 == \"NA\", \" \", var1)) |&gt;\n  kable(digits = 3,\n        col.names = c(\"Group\", \"Term\", \"Variance\", \"SD\")) |&gt; \n  kable_styling()\n\n\n\n\nTable 9.7: Table of random effects from fit_lmm_fp_sj\n\n\nGroup\nTerm\nVariance\nSD\n\n\n\n\nsj\n(Intercept)\n0.066\n0.256\n\n\nResidual\nNA\n0.180\n0.425\n\n\n\n\n\n\n\n\n\n\n\n9.7.2.3 Figures\nRandom effect visualisations aren’t typically included in publications, but these can be useful for model exploration and can be included in supplementary materials. When individual differences are of interest, these can also be useful. You can use either the lattice::dotplot() function or a combination of broom.mixed::tidy() and ggplot() that we saw above. I would suggest always starting with dotplot() though to make sure that the visualisations you produce have the same values."
  },
  {
    "objectID": "08-mixed_models1.html#summary",
    "href": "08-mixed_models1.html#summary",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "9.8 Summary",
    "text": "9.8 Summary\n\nwe saw that the equation for a straight line boils down to its intercept and slope\nwe fit our first linear model with a categorical predictor"
  },
  {
    "objectID": "08-mixed_models1.html#learning-objectives-1",
    "href": "08-mixed_models1.html#learning-objectives-1",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "Learning Objectives 🏁",
    "text": "Learning Objectives 🏁\nToday we learned…\n\nhow to model binomial data with logistic regression ✅\nhow to interpret log-odds and odds ratio ✅"
  },
  {
    "objectID": "08-mixed_models1.html#important-terms",
    "href": "08-mixed_models1.html#important-terms",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "Important terms",
    "text": "Important terms\n\n\n\n\n\n\n  \n    \n    \n      Term\n      Definition\n      Equation/Code\n    \n  \n  \n    linear mixed (effects) model\nNA\nNA"
  },
  {
    "objectID": "08-mixed_models1.html#task",
    "href": "08-mixed_models1.html#task",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "Task",
    "text": "Task\nRepeat the steps we took here, but onÖ\n\nregression path duration at the verb region, and\nregressions in at the adverb region (roi == 2)\n\n\n9.8.1 Random-intercepts\nUsing the same dataset,\n\n\n9.8.2 Dutch verb regularity"
  },
  {
    "objectID": "08-mixed_models1.html#session-info",
    "href": "08-mixed_models1.html#session-info",
    "title": "9  Mixed models 1: Random intercepts",
    "section": "Session Info",
    "text": "Session Info\nDeveloped with Quarto using R version 4.3.0 (2023-04-21) (Already Tomorrow) and RStudio version 2023.9.0.463 (Desert Sunflower), and the following packages:\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] gt_0.9.0            googlesheets4_1.1.0 kableExtra_1.3.4   \n [4] knitr_1.44          patchwork_1.1.3     lattice_0.21-8     \n [7] broom.mixed_0.2.9.4 lmerTest_3.1-3      lme4_1.1-33        \n[10] Matrix_1.5-4        sjPlot_2.8.14       ggeffects_1.2.2    \n[13] janitor_2.2.0       broom_1.0.5         here_1.0.1         \n[16] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0      \n[19] dplyr_1.1.3         purrr_1.0.2         readr_2.1.4        \n[22] tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3      \n[25] tidyverse_2.0.0     broman_0.80        \n\nloaded via a namespace (and not attached):\n [1] sandwich_3.0-2      rlang_1.1.1         magrittr_2.0.3     \n [4] multcomp_1.4-23     snakecase_0.11.0    furrr_0.3.1        \n [7] compiler_4.3.0      mgcv_1.8-42         systemfonts_1.0.4  \n[10] vctrs_0.6.3         rvest_1.0.3         crayon_1.5.2       \n[13] pkgconfig_2.0.3     fastmap_1.1.1       backports_1.4.1    \n[16] labeling_0.4.3      utf8_1.2.3          rmarkdown_2.22     \n[19] tzdb_0.4.0          haven_2.5.2         nloptr_2.0.3       \n[22] bit_4.0.5           xfun_0.39           jsonlite_1.8.7     \n[25] highr_0.10          sjmisc_2.8.9        parallel_4.3.0     \n[28] R6_2.5.1            RColorBrewer_1.1-3  stringi_1.7.12     \n[31] parallelly_1.36.0   boot_1.3-28.1       cellranger_1.1.0   \n[34] numDeriv_2016.8-1.1 estimability_1.4.1  Rcpp_1.0.11        \n[37] modelr_0.1.11       zoo_1.8-12          pacman_0.5.1       \n[40] splines_4.3.0       timechange_0.2.0    tidyselect_1.2.0   \n[43] rstudioapi_0.14     yaml_2.3.7          codetools_0.2-19   \n[46] sjlabelled_1.2.0    curl_5.0.1          listenv_0.9.0      \n[49] plyr_1.8.8          withr_2.5.0         bayestestR_0.13.1  \n[52] coda_0.19-4         evaluate_0.21       future_1.32.0      \n[55] survival_3.5-5      xml2_1.3.4          pillar_1.9.0       \n[58] insight_0.19.3      generics_0.1.3      vroom_1.6.3        \n[61] rprojroot_2.0.3     hms_1.1.3           munsell_0.5.0      \n[64] scales_1.2.1        minqa_1.2.5         globals_0.16.2     \n[67] xtable_1.8-4        glue_1.6.2          emmeans_1.8.6      \n[70] tools_4.3.0         webshot_0.5.4       fs_1.6.2           \n[73] mvtnorm_1.2-3       grid_4.3.0          colorspace_2.1-0   \n[76] nlme_3.1-162        Rmisc_1.5.1         performance_0.10.4 \n[79] googledrive_2.1.0   cli_3.6.1           fansi_1.0.4        \n[82] gargle_1.4.0        viridisLite_0.4.2   svglite_2.1.1      \n[85] sjstats_0.18.2      gtable_0.3.4        sass_0.4.6         \n[88] digest_0.6.33       TH.data_1.1-2       farver_2.1.1       \n[91] htmlwidgets_1.6.2   htmltools_0.5.5     lifecycle_1.0.3    \n[94] httr_1.4.6          bit64_4.0.5         MASS_7.3-58.4      \n\n\n\n\n\n\n\n\nBarr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of Memory and Language, 68(3), 255–278. https://doi.org/10.1016/j.jml.2012.11.001\n\n\nBiondo, N., Soilemezidi, M., & Mancini, S. (2022). Yesterday is history, tomorrow is a mystery: An eye-tracking investigation of the processing of past and future time reference during sentence reading. Journal of Experimental Psychology: Learning, Memory, and Cognition, 48(7), 1001–1018. https://doi.org/10.1037/xlm0001053\n\n\nKuznetsova, A., Brockhoff, P. B., & Christensen, R. H. B. (2017). lmerTest package: Tests in linear mixed effects models. Journal of Statistical Software, 82(13), 1–26. https://doi.org/10.18637/jss.v082.i13\n\n\nSonderegger, M. (2023). Regression Modeling for Linguistic Data.\n\n\nTroyer, M., & Kutas, M. (2020). To catch a Snitch: Brain potentials reveal variability in the functional organization of (fictional) world knowledge during reading. Journal of Memory and Language, 113(August 2019), 104111. https://doi.org/10.1016/j.jml.2020.104111\n\n\nWinter, B. (2014). A very basic tutorial for performing linear mixed effects analyses (Tutorial 2).\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547\n\n\nWinter, B., & Grice, M. (2021). Independence and generalizability in linguistics. Linguistics, 59(5), 1251–1277. https://doi.org/10.1515/ling-2019-0049"
  }
]